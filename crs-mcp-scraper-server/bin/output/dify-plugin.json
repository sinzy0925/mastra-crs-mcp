[
  {
    "source_page": "https://docs.dify.ai/ja-jp/plugins/quick-start/develop-plugins/model-plugin/README",
    "mode": "loop-links",
    "link_selector": "a",
    "target_index_requested": -1,
    "extract_target": "body",
    "item_selector_for_links": "",
    "processed_links": [
      {
        "link_index": 0,
        "link_text": "Dify Docs home page",
        "target_url": "https://docs.dify.ai/",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nGetting Started\nWelcome to Dify\nIntroduction\nFeatures and Specifications\nList of Model Providers\nDify Community\nDify Cloud\nDify Premium on AWS\nDify for Education\nGuide\nModel Configuration\nApplication Orchestration\nWorkflow\nKnowledge\nPublishing\nAnnotation\nMonitoring\nExtensions\nCollaboration\nManagement\nWorkshop\nWorkshop\nBasic\nIntermediate\nCommunity\nSeek Support\nBecome a Contributor\nContributing to Dify Documentation\nPlugins\nIntroduction\nQuick Start\nManage Plugins\nSchema Specification\nBest Practice\nPublish Plugins\nFAQ\nDevelopment\nBackend\nModels Integration\nMigration\nLearn More\nUse Cases\nExtended Reading\nFAQ\nPolicies\nLicense\nUser Agreement\nWelcome to Dify\nIntroduction\nCopy page\n\nDify is an open-source platform for building AI applications. We combine Backend-as-a-Service and LLMOps to streamline the development of generative AI solutions, making it accessible to both developers and non-technical innovators.\n\nOur platform integrates:\n\nSupport for mainstream LLMs\nAn intuitive Prompt orchestration interface\nHigh-quality RAG engines\nA flexible AI Agent framework\nAn Intuitive Low-code Workflow\nEasy-to-use interfaces and APIs\n\nWith Dify, you can skip the complexity and focus on what matters most - creating innovative AI applications that solve real-world problems.\n\n​\nThe Advantage of Dify\n\nWhile many AI development tools offer individual components, Dify provides a comprehensive, production-ready solution. Think of Dify as a well-designed scaffolding system, not just a toolbox.\n\nAs an open-source platform, Dify is co-created by a dedicated professional team and a vibrant community. This collaboration ensures rapid iteration, robust features, and a user-friendly interface.\n\nWith Dify, you can:\n\nDeploy capabilities similar to Assistants API and GPTs using any model\nMaintain full control over your data with flexible security options\nLeverage an intuitive interface for easy management and deployment\n​\nDify\n\nThe name Dify comes from “Define + Modify”, referring to defining and continuously improving your AI applications. It’s made for you.\n\nHere’s how various groups are leveraging Dify:\n\nStartups: Rapidly prototype and iterate on AI ideas, accelerating both successes and failures. Numerous teams have used Dify to build MVPs, secure funding, and win customer contracts.\nEstablished Businesses: Enhance existing applications with LLM capabilities. Use Dify’s RESTful APIs to separate prompts from business logic, while utilizing our management interface to track data, costs, and usage.\nEnterprise AI infrastructure: Banks and tech companies are deploying Dify as an internal LLM gateway, facilitating GenAI adoption with centralized governance.\nAI Enthusiasts and Learners: Practice prompt engineering and explore agent technologies with ease. Over 60,000 developers built their first AI app on Dify even before GPTs were introduced. Since then, our community has grown significantly, now boasting over 180,000 developers and supporting 59,000+ end users.\n\nWhether you’re a startup founder, an enterprise developer, or an AI enthusiast, Dify is designed to meet your needs and accelerate your AI journey!\n\n​\nNext Steps\nRead Quick Start for an overview of Dify’s application building workflow.\nLearn how to self-deploy Dify to your servers and integrate open source models.\nUnderstand Dify’s specifications and roadmap.\nStar us on GitHub and read our Contributor Guidelines.\nEdit this page\n\nHelp improve our documentation by contributing directly\n\nReport an issue\n\nFound an error or have suggestions? Let us know\n\nWas this page helpful?\n\nYes\nNo\nFeatures and Specifications\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nThe Advantage of Dify\nDify\nNext Steps",
        "error": null
      },
      {
        "link_index": 1,
        "link_text": "Blog",
        "target_url": "https://dify.ai/blog",
        "extract_target": "body",
        "extracted_data": "Dify.ai\n\nInsights\n\nProduct\n\nProduct\n\nProduct\n\nPricing\n\nPricing\n\nPricing\n\nMarketplace\n\nMarketplace\n\nMarketplace\n\nDocs\n\nDocs\n\nDocs\n\nBlog\n\nBlog\n\nBlog\n\n95.8k\n95.8k\n95.8k\n\nGet Started\n\nGet Started\n\nGet Started\n\nRELEASE\n\nDify v1.0.0: Building a Vibrant Plugin Ecosystem\n\nDify v1.0.0 sets the foundation for a thriving, open plugin ecosystem, enabling developers and enterprises to build, scale, and innovate with ease.\n\nGRACE\n\n·\n\nFEB 17, 2025\n\nRELEASE\n\nDify v0.15.0: Introducing Parent-child Retrieval for Enhanced Knowledge\n\nDify v0.15.0 introduces Parent-child Retrieval to refine RAG by matching queries with small child chunks and enhancing context with larger parent chunks, to provide more precise and context-rich AI responses.\n\nYAWEN\n\n·\n\nDEC 26, 2024\n\nRELEASE\n\nDify v0.14.0: Boost AI Workflow Resilience with Error Handling\n\nDify’s new error management provides greater control and flexibility, enabling workflows to gracefully handle exceptions, prevent disruptions, and ensure reliable AI applications.\n\nLEILEI\n\n·\n\nDEC 16, 2024\n\nAll\nProduct\nRelease\nHow to\nDeveloper\nCompany\n\nPRODUCT\n\nDify Integrates Palo Alto Networks Plugin for Enhanced AI Application Security\n\nThe addition of the PANW AI Security plugin enriches the Dify Marketplace ecosystem and provides Dify users with a crucial layer of enterprise-grade security. \n\nLEILEI\n\n·\n\nAPR 30, 2025\n\nHOW TO\n\nLevel Up Your Dify Chatbot: Integrating InfraNodus for Advanced Q&A and Idea Generation\n\nInfraNodus analyzes knowledge graphs to generate questions from structural gaps, enhancing Dify apps for insightful Q&A and idea generation.\n\nDMITRY PARANYUSHKIN\n\n&\n\nLEILEI\n\n·\n\nAPR 17, 2025\n\nHOW TO\n\nTurn Your Dify App into an MCP Server\n\nWith the mcp-server plugin, any Dify app can be turned into an MCP-compliant server endpoint, directly accessible by external MCP clients.\n\nLEILEI\n\n·\n\nAPR 14, 2025\n\nPRODUCT\n\nDify MCP Plugin Hands-On Guide: Integrating Zapier for Effortless Agent Tool Calls\n\nIntegrate Zapier's thousands of apps into Dify AI agents using the Model Context Protocol (MCP). \n\nLEILEI\n\n·\n\nAPR 1, 2025\n\nCOMPANY\n\nMeet Dify for Education\n\nMake AI accessible and affordable to every campus worldwide.\n\nDIFY.AI\n\n·\n\nAPR 2, 2025\n\nPRODUCT\n\nDupDub Plugins Land on Dify Marketplace with Advanced Audio AI Capabilities\n\nThe DupDub AI audio plug-in is now available in the Dify Marketplace, providing voice translation, voice cloning, speaker recognition, and text-to-speech capabilities to help users build more engaging AI applications.\n\nDIFY.AI\n\n&\n\nDUPDUB\n\n·\n\nMAR 27, 2025\n\nPRODUCT\n\nEnhance Dify RAG with InfraNodus: Expand Your LLM’s Context\n\nIntegrating InfraNodus with Dify RAG enhances AI responses by providing contextual insights, improving retrieval accuracy, and enabling better handling of broad queries through topic mapping and metadata enrichment.\n\nDMITRY PARANYUSHKIN\n\n&\n\nLEILEI\n\n·\n\nMAR 26, 2025\n\nHOW TO\n\nBuilding SSH Plugin with Cursor: A Codeless Approach to Server Management\n\nThe new SSH plugin enables AI-driven server management, automating deployments, file handling, script execution, and troubleshooting via secure remote access.\n\nSTEVEN\n\n·\n\nMAR 26, 2025\n\nPRODUCT\n\nDify x Open Audio: Expand Your AI with the Fish Audio Plugin — TTS and Voice Cloning Made Easy\n\nDify integrates Fish Audio from Open Audio, enabling AI apps with text-to-speech and voice cloning. \n\nEVAN CHEN\n\n&\n\nLEILEI\n\n·\n\nMAR 26, 2025\n\nPRODUCT\n\nReal-Time Interactive Voice AI Made Simple: Agora’s Conversational AI Extension Lands on Dify Marketplace\n\nAgora’s Conversational AI Extension is now on Dify Marketplace, enabling developers to easily build real-time, low-latency voice AI agents. \n\nGRACE\n\n·\n\nMAR 24, 2025\n\nRELEASE\n\nDify v1.1.0: Filtering Knowledge Retrieval with Customized Metadata\n\nToday, we’re launching Dify v1.1.0 featuring Metadata as a Knowledge Filter, which enhances accuracy, security, and efficiency by allowing precise filtering and access control of data, crucial for effective retrieval-augmented generation (RAG) management.\n\n\nYAWEN\n\n·\n\nMAR 18, 2025\n\nCOMPANY\n\nDify.AI Showcases AI Innovation at NVIDIA GTC 2025\n\nDify will be at NVIDIA GTC 2025 from March 17th to March 21st at booth 3226 to showcase our latest innovations. \n\nDIFY.AI\n\n·\n\nMAR 13, 2025\n\nRELEASE\n\nDify Agent Node Introduction – When Workflows Learn “Autonomous Reasoning”\n\nDify's Agent Node acts like a brain within workflows, letting LLMs make decisions and handle tasks autonomously. Customizable \"Agent Strategies\" are plug-in logic modules that dictate how the LLM thinks and uses tools. This setup offers both flexibility and control.\n\nEVAN CHEN\n\n·\n\nMAR 12, 2025\n\nHOW TO\n\nBeyond Translation: An AI Workflow for High-Quality Chinese Technical Content\n\nTraditional translation struggles with technical articles, often producing unnatural \"translationese.\" This article introduces an AI-driven workflow using multi-round reviews and rewriting techniques. It uses multiple LLMs to create high-quality, accessible Chinese technical content.\n\nGINO\n\n·\n\nMAR 12, 2025\n\nRELEASE\n\nExtension Plugin Endpoint: Bringing Serverless Flexibility to Dify\n\nIntroducing Dify’s new Endpoint, which lets Extension plugins handle custom HTTP requests and leverage reverse calls for greater flexibility. It enables features like custom web interfaces, OpenAI-compatible APIs, and asynchronous event triggers, expanding what’s possible within the Dify ecosystem.\n\nYEUOLY\n\n·\n\nMAR 10, 2025\n\nHOW TO\n\nDify x Brave Search: Supercharging AI Apps with Real-Time Search\n\nLearn how to effortlessly integrate real-time search into your AI apps using the new Brave Search API plugin. Build intelligent agents, sophisticated workflows, and autonomous search capabilities—making your applications smarter and more responsive with Dify v1.0.0.\n\nLEILEI\n\n·\n\nMAR 6, 2025\n\nCOMPANY\n\nDify to Showcase at 2025 AWS Summit Japan!\n\nDify will sponsor AWS Summit Japan 2025 at Makuhari Messe, demonstrating our latest features, including plugin system, Workflow Agent Node, and seamless AWS integration. \n\nDIFY.AI\n\n·\n\nMAR 5, 2025\n\nPRODUCT\n\nDify Plugin System: Design and Implementation\n\nDify's new plugin system enhances flexibility and customization by decoupling modules, enabling independent operation and external integrations. It addresses prior limitations with features like a plugin marketplace, \"Endpoint\" plugins, reverse calls, diverse runtimes (local, SaaS, enterprise), and robust security, improving both user and developer experiences.\n\nYEUOLY\n\n·\n\nMAR 4, 2025\n\nHOW TO\n\nDeepResearch: Building a Research Automation App with Dify \n\nDeepResearch automates multi-step searches and summarizes findings using LLMs. Built within Dify, \"DeepResearch\" uses nodes for iteration, search, and summarization, creating a workflow for efficient information gathering and report generation, saving time and effort.\n\nTAKASHI KISHIDA\n\n·\n\nFEB 19, 2025\n\nHOW TO\n\nBuilding a Multilingual Document Translation Tool with  Dify\n\nThis article will leverage DeepSeek R1, combined with Dify, an open-source low-code development platform, to demonstrate how to quickly build an enterprise-level multilingual document translation tool. \n\nSTEVEN\n\n·\n\nFEB 13, 2025\n\nHOW TO\n\nAdding MultiModal Capabilities to Deepseek R1 using Dify\n\nOn Dify, you can quickly build a bidirectional collaborative system based on DeepSeek R1 and multi-modal models through visual workflow design.\n\nSTEVEN\n\n·\n\nFEB 8, 2025\n\nHOW TO\n\nDeepSeek API Issues? Dify Keeps Your R1 Apps Running\n\nDify provides robust access to DeepSeek-R1, even with API instability. Integrate via the official API, multiple MaaS options, or local deployment for reliable, flexible LLM application development and consistent performance.\n\nLEILEI\n\n·\n\nFEB 7, 2025\n\nHOW TO\n\nDify x DeepSeek: Deploy a Private AI Assistant & Build a Local DeepSeek R1 + Web Search App\n\nIn this guide, we’ll show you how to deploy a private AI assistant using Dify and DeepSeek, and build a local DeepSeek R1 + Web Search AI app on your own infrastructure.\n\nALLEN\n\n·\n\nFEB 6, 2025\n\nHOW TO\n\nDify work with Microsoft AI Search\n\nDify’s custom tool makes it easy to add Azure’s fast, AI-driven search via REST API.\n\nXINYU WEI\n\n·\n\nJAN 22, 2025\n\nCOMPANY\n\nDify Official Statement: Clarification Regarding Recent Misinformation\n\nWe have detected impersonators engaging in illegal activities unrelated to us; please rely on official channels and stay vigilant.\n\nDIFY.AI\n\n·\n\nJAN 21, 2025\n\nRELEASE\n\nIntroducing Dify Plugins\n\nWe're excited to announce the beta release of Dify Plugins - modular components that seamlessly extend your AI applications.\n\nGRACE\n\n·\n\nJAN 9, 2025\n\nRELEASE\n\nBuilding a Twitter MBTI Analyzer: A No-Code Journey with Dify and Windsurf\n\nThis article explores how to build an AI-powered product, “Twitter MBTI Receipt,” using Dify and Windsurf to analyze Twitter profiles and generate MBTI personality reports.\n\nSTEVEN\n\n·\n\nDEC 10, 2024\n\nHOW TO\n\nEnhancing GPT-Researcher with Parallel and Advanced Iterative Features\n\nBy automating research tasks through problem decomposition, parallel processing, and error handling, we can create faster, more reliable, and structured research reports. \n\nEVAN CHEN\n\n·\n\nNOV 5, 2024\n\nCOMPANY\n\nDify.AI x TechCrunch Disrupt 2024 Recap\n\nWe were selected for TechCrunch Disrupt 2024's Startup Battlefield 200 in SF. Our team showcased our enterprise AI development platform for three days, presented on the Builder Stage, and engaged with global developers to share our vision of simplifying LLM integration.\n\nDIFY.AI\n\n·\n\nNOV 1, 2024\n\nCOMPANY\n\nHow Dify.AI powers the company that's powering the world\n\nA leading consumer electronics company leverages Dify.AI to bridge technical and non-technical teams, streamlining AI integration. With Dify.AI, employees across all levels can create AI applications, boosting efficiency, enhancing customer insights, and driving real-world impact.\n\nGU\n\n·\n\nOCT 29, 2024\n\nRELEASE\n\nIntroducing Workflow File Upload: Google NotebookLM Podcast Demo\n\nWe’re launching the file upload feature today, with a demo on using it in an AI podcast application.\n\nLEILEI\n\n&\n\nEVAN CHEN\n\n·\n\nOCT 21, 2024\n\nHOW TO\n\nCross-Platform Copywriting with Dify\n\nIn Dify, not all nodes have a low entry threshold. Some nodes may be overlooked during the process of orchestrating flows, but combining them will unlock more possibilities for Dify in complex tasks. This blog will use the scenario of Cross-Platform Copywriting to demonstrate how to use template conversion nodes for type conversion, write session variables during iterations, accelerate flow processing in parallel, optimize streaming output experiences with multiple answer nodes, and explore more uses of code nodes.\n\nEVAN CHEN\n\n&\n\nLYSON\n\n·\n\nSEP 14, 2024\n\nHOW TO\n\nHow to configure and use OpenAI o1 models in Dify.AI? \n\nOpenAI launches the o1 series models, excelling in complex reasoning. Dify.AI enables seamless integration of these models within an hour, offering developers efficient solutions. Check our documentation for detailed integration steps.\n\n·\n\nSEP 13, 2024\n\nRELEASE\n\nDify v0.8.0: Accelerating Workflow Processing with Parallel Branch\n\nWe’ve enhanced Workflow with parallel processing capabilities in Dify v0.8.0. It can now run multiple branches simultaneously, enabling the parallel execution of various tasks. This new model significantly improves execution efficiency, helping LLM applications handle complex tasks more quickly and flexibly.\n\nLEILEI\n\n·\n\nSEP 10, 2024\n\nCOMPANY\n\nDify.AI Selected for Startup Battlefield 200 at TechCrunch Disrupt 2024\n\nWe’re thrilled to share that Dify.AI has been selected to showcase at TechCrunch Disrupt 2024 as part of the Startup Battlefield 200, a preeminent competition for startups worldwide.\n\nDIFY.AI\n\n·\n\nSEP 6, 2024\n\nCOMPANY\n\nPartners with Takin.ai to Deliver Easier GenAI Education\n\nWe're excited to welcome Takin.ai, an innovative GenAI education startup, to be our education partner.\n\nDIFY.AI\n\n·\n\nAUG 20, 2024\n\nHOW TO\n\nDify Conversation Variables: Building a Simplified OpenAI Memory\n\nConversation Variables are short-term memory units employed by Dify to provide temporary storage in multi-turn conversations within chatflows. These variables enable us to retain important details between chat interactions, resulting in more contextually relevant responses. In the following section, I will demonstrate how to utilize Conversation Variables to emulate OpenAI's Memory Features.\n\nEVAN CHEN\n\n·\n\nAUG 16, 2024\n\nRELEASE\n\nDify v0.7.0: Enhancing LLM Memory with Conversation Variables and Variable Assigners\n\nDify v0.7.0 tackles LLM memory limitations with Conversation Variables and Variable Assigner nodes. These features give Chatflow-built apps precise memory control, boosting LLMs' ability to handle complex scenarios in production.\n\nLEILEI\n\n·\n\nAUG 14, 2024\n\nRELEASE\n\nPhasing Out N-to-1: Upgrading Multi-path Knowledge Retrieval\n\nWe're phasing out the N-to-1 retrieval strategy on September 1, 2024, and introducing a more flexible Multi-path retrieval strategy. We recommend switching to this new approach to boost your application's retrieval efficiency.\n\nPAN\n\n&\n\nLEILEI\n\n·\n\nAUG 1, 2024\n\nRELEASE\n\nDifySandbox Goes Open Source: Secure Execution of Code\n\nToday, we're proud to announce that we've made DifySandbox open source for greater code transparency.\n\nLEILEI\n\n·\n\nJUL 10, 2024\n\nPRODUCT\n\nIntroduction to DifySandbox\n\nThis blog thoroughly outlines the rationale, design principles, and implementation mechanisms that guided the development of DifySandbox.\n\nYEUOLY\n\n·\n\nJUL 10, 2024\n\nRELEASE\n\nEnhance LLM Application observability on Dify with LangSmith and Langfuse\n\nWith simple configuration, you can now access detailed application data, making it easier to evaluate the cost, latency, and quality of LLM applications created on Dify. \n\nLEILEI\n\n·\n\nJUL 2, 2024\n\nRELEASE\n\nDify.AI x Firecrawl: A Top-Notch Solution for Web Data Knowledge Base\n\nDify v0.6.11 has just been released! We've integrated Firecrawl as our web data source solution, which greatly enhances the knowledge base of Dify. \n\nLEILEI\n\n·\n\nJUN 17, 2024\n\nPRODUCT\n\nDify vs. LangChain\n\nCompare Dify.AI and LangChain for enterprise AI application development. Learn about their scalability, flexibility, and efficiency to choose the best platform for your needs. \n\n·\n\nJUN 5, 2024\n\nRELEASE\n\nWorkflow Major Update: Iteration, Parameter Extractor and Publish Workflow as a Tool\n\nSince launching workflow v0.6.0, it has been popular among our users, with over 90% needing it for AI applications in business scenarios. Dify v0.6.9 introduces publishing workflows as tools, iteration nodes, parameter extractors, and enhanced node capabilities. We also offer a showcase to demonstrate their use, automating batch processing of your emails.\n\nXIAOYI\n\n·\n\nMAY 31, 2024\n\nRELEASE\n\nIntroducing Dify Workflow\n\nWe’re thrilled to launch our new feature: AI Workflow. It enables predictable outputs with multi-step logic through an intuitive, drag-and-drop interface.\n\nGU\n\n·\n\nAPR 8, 2024\n\nRELEASE\n\nDify.AI is now available on the AWS Marketplace\n\nPerfect for small teams & service providers needing custom branding & flexible deployment.\n\nGU\n\n·\n\nMAR 12, 2024\n\nDEVELOPER\n\nHow to run open source model Gemma on Dify? \n\nExplore how to leverage Google's Gemma, an open-source LLM, for integration with Dify. Discover tips for enhancing AI applications responsibly. \n\nXIAOYI\n\n·\n\nFEB 22, 2024\n\nHOW TO\n\nYour Guide to Building an AI Travel Consultant \n\nEver wondered how to leverage the latest AI technology for travel planning? This comprehensive guide on Dify.AI showcases how to build an AI travel consultant, making your trip planning effortless and efficient.\n\nXIAOYI\n\n·\n\nFEB 4, 2024\n\nHOW TO\n\nUnleashing AI in Finance: Building an AI Investment Analysis Assistant with Dify\n\nDiscover the step-by-step guide on constructing a sophisticated AI investment analysis assistant with Dify. Master the art of integrating AI into your financial analysis for smarter, data-driven decisions.\n\nXIAOYI\n\n·\n\nJAN 26, 2024\n\nRELEASE\n\nDify.AI Unveils AI Agent: Creating GPTs and Assistants with Various LLMs\n\nWith Dify, you can create an AI Agent using any LLMs. Simply use instructions and combine various tools with additional knowledge bases to create a custom Assistant that's just right for you.\n\nPAN\n\n·\n\nJAN 24, 2024\n\nRELEASE\n\nDify Rolls Out New Architecture, Enhancing Flexibility and Scalability\n\nWe've totally revamped Dify's core architecture, moving to a more modular approach. Our latest Beehive architecture allows each module to stand on its own, enabling developers to adjust parts without affecting the overall structure.\n\nLEVI TIAN\n\n·\n\nJAN 10, 2024\n\nRELEASE\n\nDify.AI v0.4.1 Release: The Model Runtime Restructure\n\nWe're rolling out a brand new Model Runtime architecture, replacing the pre-existing model interface built on LangChain.\n\nGU\n\n·\n\nJAN 3, 2024\n\nHOW TO\n\nBoosting Chatbot Quality & Cutting Costs with Dify.AI's Annotation Reply\n\nThis article introduces how to use Dify.AI's Annotation Reply feature to improve Chatbot reply quality and Reduce LLM token Costs. \n\n·\n\nDEC 26, 2023\n\nRELEASE\n\nDify.AI Update v0.3.34 \n\nDify.AI‘s v0.3.34 introduces features such as Annotation Reply, providing enhanced Q&A capabilities and more.\n\nLEILEI\n\n·\n\nDEC 20, 2023\n\nCOMPANY\n\nDify.AI x Jina AI：Dify now Integrates Jina Embedding Model\n\nJina AI's jina-embeddings-v2, with a unique 8,192 token context, enhances RAG applications in Dify.AI's platform. It outperforms standard 512-token models, enabling richer, context-aware AI solutions and simplified development.\n\nDIFY.AI\n\n&\n\nJINA\n\n·\n\nDEC 5, 2023\n\nDEVELOPER\n\nDify.AI: Open-source Assistants API based on any LLM\n\nOpenAI's Assistants API marks a shift in application engineering towards advanced AI use, emphasizing orchestration services. Dify, an open-source leader in this field, offers self-hosting for data security, multi-model support, and a flexible RAG engine. It enables privacy, compliance, customizable data processing, and team collaboration, enhancing AI application development and integration.\n\nDIFY.AI\n\n·\n\nNOV 25, 2023\n\nRELEASE\n\nDify.AI v0.3.31: Surpassing the Assistants API – Dify's RAG Demonstrates an Impressive 20% Improvement\n\nDify.AI's latest update enhances its RAG technology, boosting QA efficiency in LLMs. It introduces hybrid search, a semantic rerank model, and multi-path retrieval, demonstrating significant performance improvements and a notable edge over OpenAI's Assistants API.\n\nLEILEI\n\n·\n\nNOV 21, 2023\n\nDEVELOPER\n\nIntroducing Hybrid Search and Rerank to Improve the Retrieval Accuracy of the RAG System\n\nThis article discusses enhancing RAG systems with Hybrid Search and Rerank technologies, focusing on improving retrieval accuracy and efficiency using LLMs for more comprehensive and precise search results.\n\nVINCE\n\n·\n\nNOV 21, 2023\n\nRELEASE\n\nDify.AI v0.3.30 is here! Explore the Exciting GPT4-Vision Multimodal Model\n\nThis update officially supports the multimodal capabilities of the GPT4-Vision model, integrating images into conversations to create a unique interactive experience, making conversations more engaging.\n\nDIFY.AI\n\n·\n\nNOV 13, 2023\n\nRELEASE\n\nDify.AI v0.3.29: Support for GPT-4 Turbo & Vision - The Gateway to Multimodal Interactions\n\nv0.3.29 Feature Highlights:\n- GPT-4 Turbo & Vision model support\n- External data API tools\n- Moderation for sensitive content\n\nDIFY.AI\n\n·\n\nNOV 8, 2023\n\nRELEASE\n\nFrom Basic to Expert: Mastering the New Prompt Orchestration in Dify.AI\n\nDify.AI introduces a new \"Expert Mode\" in its prompt orchestration page, offering advanced customization and control for professional developers and prompt engineers over prompt orchestration. While \"Basic Mode\" simplifies application creation, \"Expert Mode\" provides a wide range of tools and options for designing complex prompt orchestrations, enabling users to fine-tune AI applications for optimal performance. It includes features like customized prompts, different models (CHAT and COMPLETE) for various requirements, and a 'Log View' feature for debugging.\n\nDIFY.AI\n\n·\n\nOCT 23, 2023\n\nRELEASE\n\nDify.AI's New Dataset Feature Enhancements\n\nThe recent updates to Dify.AI's dataset management tools introduce a \"Citations and Attributions\" feature for easier documentation referencing, and a new Dataset API for efficient data management. Support for multiple file formats and document segmentation enhances data handling. Additionally, integration with GPT-3.5-turbo-instruct and various Hugging Face embedding models provides users with more model options for specific applications, improving overall user experience.\n\nDIFY.AI\n\n·\n\nOCT 12, 2023\n\nRELEASE\n\nDify.AI v0.3.13 Release: Effortlessly Leverage Top Open-Source LLMs like Llama2 and ChatGLM\n\nDify now supports popular open-sourced large language models like Llama2 and Qwen. Users can easily access these cutting-edge models by entering API keys on Dify, and build high-performance AI applications within minutes. Dify opens the gateway to the latest innovations in natural language processing. Try out top-notch models like Llama2 for free on Dify today, and unleash their power to enhance your AI solutions.\n\nDIFY.AI\n\n·\n\nAUG 15, 2023\n\nDEVELOPER\n\nText Embedding: Basic Concepts and Implementation Principles\n\nEmbedding is a vital technique in AI applications, representing concepts as numerical sequences to enable better comprehension of relationships.\n\nVINCE\n\n·\n\nAUG 1, 2023\n\nRELEASE\n\nMajor Update: AI Online Search Capability Now Available, Significantly Enhancing Dataset Hit Rate!\n\nDify.AI V0.3.12 introduces improved data retrieval with Q2Q matching and 'Chat' capability for online interactions with AI. Chat supports web browsing, Google search, and Wikipedia queries, enhancing productivity. Join our collaborative exploration of large model capabilities.\n\nDIFY.AI\n\n·\n\nAUG 1, 2023\n\nRELEASE\n\nDify.AI Integrates Claude2 Model: Supports 100K Token Context, Get 1000 Free Message Credits upon Sign-up\n\nDify V0.3.9 Release: Integration of Antropic's Claude2 and Claude-instant models, supporting ultra-long conversations with up to 100K tokens. Now, you can embed AI applications on your web pages, swiftly creating personalized AI customer support for your official website. Additional features include bulk result exporting for text-based applications and the community version supporting member invitations through invitation links. Moreover, the Service API now includes conversation deletion functionality. Experience the superpowers of Dify today!\n\nDIFY.AI\n\n·\n\nJUL 17, 2023\n\nCOMPANY\n\nDify.AI: 46,558 Lines of Code, Fully Open Source\n\nSince the official launch of the Cloud version on May 9th, Dify.AI has been well-received and widely shared by developers. In less than a week, over 4,000 applications have been created, and even before we went open source, our GitHub Star count had exceeded 700+. This makes us deeply feel the power of the community! At the same time, we are extremely honored and excited that Dify can bring such powerful creativity to developers.\n\nDIFY.AI\n\n·\n\nMAY 15, 2023\n\nRELEASE\n\nDify.AI: Easy-to-Use LLMOps Platform for Visually Creating and Operating Your AI Native Applications\n\nWith the emergence of various capabilities of large language models (LLMs), the scenarios for AI applications have become much broader. However, for most developers, developing AI applications based on large language models such as GPT and technology frameworks like Langchain is still a challenging task. Developers must spend a lot of time learning various obscure concepts and technical research, and they cannot carry out continuous operations of AI applications.\n\nDIFY.AI\n\n·\n\nMAY 10, 2023\n\nRELEASE\n\nBuilding Effective GPT-based Applications: A Step-by-Step Guide\n\nDevelopers utilizing OpenAI's GPT API may often find that the AI doesn't produce the desired output or seems \"uncooperative.\" To address these challenges and improve GPT's performance, there are three crucial steps to follow：\n\nDIFY.AI\n\n·\n\nAPR 12, 2023\n\nHOW TO\n\nWhat is Ops in LLMOps?\n\nLLMOps is a specialized area within the broader MLOps landscape, focusing on the deployment, management, and improvement of AI applications built on top of Large Language Models (LLMs) like GPT-4. In this article, we will explore the concept of \"Ops\" in LLMOps and how Dify caters to this space.\n\nDIFY.AI\n\n·\n\nAPR 11, 2023\n\nDEVELOPER\n\nIntroducing Dify WebApp: Unlocking AI-Native Applications with Ease\n\nAt Dify, we are dedicated to providing our users with seamless and flexible solutions for creating and deploying AI-native applications. We understand the importance of a user-friendly and open platform to foster innovation, and that's where Dify WebApp and Dify WebApp Template come into play.\n\n\nDIFY.AI\n\n·\n\nAPR 10, 2023\n\nCOMPANY\n\nWhy Did We Create Dify?\n\nAt Dify, we are passionate about making AI technology more accessible and user-friendly. As we began our journey, we identified several key challenges that developers and users face when working with AI-native applications, especially with the advanced large language models provided by OpenAI. In this blog post, we will discuss the reasons behind the creation of Dify and our mission to simplify the AI development process.\n\nDIFY.AI\n\n·\n\nAPR 9, 2023\n\nPRODUCT\n\nUnleashing the Power of LLM Embeddings with Datasets: Revolutionizing MLOps\n\nThe combination of LLM embeddings and datasets has dramatically transformed the MLOps landscape, unlocking new capabilities and driving innovation in AI applications. Dify's dataset functionality simplifies the process of integrating proprietary data with LLMs, empowering developers to build more intelligent, domain-specific AI solutions. As LLMs continue to evolve, we can expect even more exciting possibilities and advancements in the world of AI and MLOps.\n\nDIFY.AI\n\n·\n\nAPR 12, 2022\n\nHOW TO\n\nDeveloping a ChatGPT Plugin: A Comprehensive Guide\n\nChatGPT plugins provide a powerful way to extend the capabilities of AI clients by integrating additional functionalities through APIs. In this blog post, we'll guide you through the process of creating a ChatGPT plugin and discuss some potential business use cases. Finally, we'll touch upon how Dify supports the integration of both in-house and third-party plugins for seamless AI application orchestration.\n\nDIFY.AI\n\n·\n\nMAR 15, 2022\n\nThe Innovation Engine for Generative AI Applications\n\nGet Started\n\nGet Started\n\nGet Started\n\nGitHub\n\nGitHub\n\nGitHub\n\nDify.ai\n\nDify.AI aims to become a leading \n\ngenerative AI application development platform.\n\nEN\n中文\n日本語\n© 2025 LangGenius, Inc.\n\nProducts\n\nLLM Agent\n\nAI Workflow\n\nPrompt IDE\n\nRAG Pipeline\n\nEnterprise LLMOps\n\nResource\n\nMarketplace\n\nDocs\n\nBlog\n\nEducation\n\nSupport\n\nFeedback\n\nRoadmap\n\nCompany\n\nTalk to Us\n\nTerms of Service\n\nPrivacy Policy\n\nCookie Settings\n\nSecurity\n\nSOC2 Type I &  Type II Certified\nISO 27001:2022 Certified\n\nData Protection Agreement",
        "error": null
      },
      {
        "link_index": 3,
        "link_text": "Dify.AI",
        "target_url": "https://cloud.dify.ai",
        "extract_target": "body",
        "extracted_data": "",
        "error": null
      },
      {
        "link_index": 4,
        "link_text": "ドキュメント",
        "target_url": "https://docs.dify.ai/ja-jp/introduction",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nDifyエンタプライス版へようこそ\n特徴と技術仕様\nモデルプロバイダーリスト\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nDifyへようこそ\nDifyエンタプライス版へようこそ\nCopy page\n\nDify エンタープライズ版は、大規模な組織やチーム向けのプライベートデプロイメントAIミドルウェアソリューションであり、企業内でのAI+時代への移行を促進することを目的としています。\n\nDify はノーコード設計理念を採用しており、ビジネス担当者が深いプログラミング知識を必要とせずに直接AIアプリケーションを構築およびデプロイできるようにします。 エンタープライズ版サービスには強力な管理バックエンドが装備されており、詳細な権限管理とワークスペース管理をサポートし、チームの協力効率とデータセキュリティを確保します。また、包括的なデータ監視サービスも提供しており、管理人がAIアプリケーションのパフォーマンスとデータ使用状況をリアルタイムで把握し、意思決定のためのデータサポートを提供します。\n\nプライベートデプロイメントオプションと企業レベルのセキュリティ標準に準拠した設計により、Dify エンタープライズ版はデータセキュリティを確保しながら、組織に安定した信頼性のある拡張可能なAIインフラストラクチャを提供し、AI時代において競争優位性を維持するのに役立ちます。\n\n​\n製品の利点\n\n私たちの企業向けソリューションには以下の利点があります：\n\n高度なチーム管理: 企業のDifyプラットフォーム内の「ワークスペース」と「チームメンバー」を柔軟に管理し、管理人はアクセス権とチーム構造を簡単に制御できます。\n企業レベルのアクセスセキュリティ: 企業内のSSO（シングルサインオン）システムと統合し、安全で信頼性のある認証を確保し、潜在的なデータリスクを回避します。\nブランド変更が可能です：製品のロゴやブランド情報を自由に変更し、あなた専用のプラットフォームとして利用できます。\n複数テナントの作成が可能です：複数のワークスペースを作成・所有でき、異なる部署やアクショングループのニーズを効果的にサポートします。\nモデルの負荷分散機能を提供します：適切なモデルに対して負荷分散を行い、モデルのQPS制限を超えて、より広範囲なシーンにサービスを提供します。\n​\n適用シナリオ\n高データセキュリティ要件: 金融、医療部門など、データセキュリティに非常に高い要件を持つ業界や企業向け。Dify エンタープライズ版は以下を提供します：\nエンドツーエンドの暗号化伝送\n厳格なデータアクセス制御\nローカルデプロイメントオプション、機密データが企業内ネットワークを離れないことを確保\n大規模なAIアプリケーションのデプロイメントと管理: 企業内で大規模にAIアプリケーションをデプロイおよび管理する必要がある組織向け。\n中央集権的なAI資産管理、モデル、データセット、アプリケーションを含む。管理人は企業内の複数のAIアプリケーションの運用状況を簡単に確認および監視できます。\nモデルニュートラル、管理人がオープンソース/クローズドソースのAI大規模モデルを自分で接続し、ビジネスシナリオに迅速に適用できる\n使いやすく、ビジネス担当者が迅速に製品プロトタイプの開発とテストを行うことをサポート\n権限管理システム、リソース共有を確保しながら機密情報を保護\n広範なAI能力統合シナリオ: AI能力を既存のビジネスプロセスやシステムにシームレスに統合する必要がある企業向け。\n豊富なAPIポートを提供し、企業システムとの統合をサポート\nカスタムワークフローエンジン、複雑なビジネスロジックを実現\n多言語サポート、国際化ニーズを満たす\n高並列性、高可用性の要件: システムの安定性とパフォーマンスに高い要求がある大規模企業やインターネット企業向け。\n分散アーキテクチャ、水平スケーリングをサポート\n負荷分散とフェイルオーバーメカニズム、サービスの高可用性を確保\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\n特徴と技術仕様\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\n製品の利点\n適用シナリオ",
        "error": null
      },
      {
        "link_index": 5,
        "link_text": "用語ベース",
        "target_url": "https://docs.dify.ai/ja-jp/termbase/termbase",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n用語集\n用語集\nCopy page\n​\nA\n​\nエージェント (Agent)\n\n環境情報に基づいて意思決定やタスク実行ができる自律型AIシステムです。Difyプラットフォームでは、エージェントは大規模言語モデルの理解能力と外部ツールとの対話能力を組み合わせ、情報検索、API呼び出し、コンテンツ生成など、単純なものから複雑なものまでの一連の操作を自動的に完了します。\n\n​\nエージェンティックワークフロー (Agentic Workflow)\n\nAIシステムが複数のステップを通じて自律的に複雑な問題を解決できるタスク編成方法です。例えば、エージェンティックワークフローは、まずユーザーの質問を理解し、次に知識ベースを照会し、計算ツールを呼び出し、最後に情報を統合して完全な回答を生成します。これらはすべて人間の介入なしに行われます。\n\n​\n自動音声認識 (ASR, Automatic Speech Recognition)\n\n人間の音声をテキストに変換する技術で、音声対話アプリケーションの基盤となります。この技術により、ユーザーはタイピングではなく話すことでAIシステムと対話でき、音声アシスタント、会議の文字起こし、アクセシビリティサービスなどのシナリオで広く使用されています。\n\n​\nB\n​\n思考の骨格 (BoT, Backbone of Thought)\n\n大規模言語モデルの推論に主要な構造を提供する構造化された思考フレームワークです。学術論文の概要や決定木の骨格のように、複雑な問題に対処する際にモデルが明確な思考経路を維持するのに役立ちます。\n\n​\nC\n​\nチャンキング (Chunking)\n\n長いテキストを小さなコンテンツブロックに分割する処理技術で、検索システムがより正確に関連情報を見つけることを可能にします。優れたチャンキング戦略は、コンテンツの意味的整合性と言語モデルのコンテキストウィンドウの制限の両方を考慮し、検索と生成の品質を向上させます。\n\n​\n引用と帰属 (Citation and Attribution)\n\nAIシステムが情報源を明確に示すことができる機能で、レスポンスの信頼性と透明性を高めます。システムが知識ベースのコンテンツに基づいて回答を生成する場合、参照されたドキュメント名、ページ番号、URLを自動的に注釈し、ユーザーが情報の出所を理解できるようにします。\n\n​\n思考の連鎖 (CoT, Chain of Thought)\n\n大規模言語モデルがステップバイステップの思考プロセスを表示するように導くプロンプト技術です。例えば、数学の問題を解く場合、モデルははじめに既知の条件をリストアップし、次に推論ステップに従って一つずつ解き、最後に結論に到達します。このプロセス全体が人間の思考に似ています。\n\n​\nD\n​\nドメイン固有言語 (DSL, Domain-Specific Language)\n\n特定のアプリケーションドメイン用に設計されたプログラミング言語または構成形式です。Dify DSLは、YAML形式に基づくアプリケーションエンジニアリングファイル標準で、モデルパラメータ、プロンプト設計、ワークフロー編成など、AIアプリケーションのさまざまな構成を定義するために使用され、非専門的な開発者でも複雑なAIアプリケーションを構築できるようにします。\n\n​\nE\n​\n抽出・変換・読み込み (ETL, Extract, Transform, Load)\n\nデータ処理の古典的なワークフロー：生データを抽出し、分析に適した形式に変換し、ターゲットシステムに読み込みます。AIドキュメント処理では、ETLはPDFからのテキスト抽出、フォーマットのクリーニング、コンテンツの分割、埋め込みベクトルの計算、最終的にベクトルデータベースへの読み込みを含む場合があり、RAGシステムの準備を整えます。\n\n​\nF\n​\n頻度ペナルティ (Frequency Penalty)\n\n頻繁に出現する語彙の生成確率を下げることで出力の多様性を高めるテキスト生成制御パラメータです。値が高いほど、モデルは多様な語彙と表現を使用する傾向があります。値が0の場合、モデルは同じ語彙を再利用することを特に避けません。\n\n​\n関数呼び出し (Function Calling)\n\n大規模言語モデルが特定の関数をいつ呼び出す必要があるかを認識し、必要なパラメータを提供する能力です。例えば、ユーザーが天気について尋ねると、モデルは自動的に天気APIを呼び出し、正しいパラメータ形式（都市、日付）を構築し、APIの返す結果に基づいて応答を生成することができます。\n\n​\nG\n​\n一般的なチャンキングパターン (General Chunking Pattern)\n\n文書を相互に独立したコンテンツブロックに分割するシンプルなテキスト分割戦略です。このパターンは、製品マニュアルや百科事典のエントリなど、構造が明確で段落が比較的独立している文書に適しており、各チャンクはコンテキストに大きく依存することなく独立して理解できます。\n\n​\n思考のグラフ (GoT, Graph of Thought)\n\n思考プロセスをネットワーク構造として表現し、概念間の複雑な関係を捉える方法です。線形の思考の連鎖とは異なり、思考のグラフは分岐、循環、複数経路の思考パターンを表現でき、複数の相互関連する要因を持つ複雑な問題の処理に適しています。\n\n​\nH\n​\nハイブリッド検索 (Hybrid Search)\n\nキーワードマッチングと意味検索の利点を組み合わせ、より包括的な検索結果を提供する検索方法です。例えば、「リンゴの栄養成分」を検索する場合、ハイブリッド検索は「リンゴ」と「栄養」のキーワードを含む文書だけでなく、「果物の健康価値」などの関連する意味概念を議論するコンテンツも見つけることができ、重み付け調整または再ランク付けを通じて最適な結果を選択します。\n\n​\nI\n​\n転置インデックス (Inverted Index)\n\n各単語がどの文書に出現するかを記録する検索エンジンのコアデータ構造です。文書からコンテンツを見つける従来のインデックスとは異なり、転置インデックスは語彙から文書を見つけ、全文検索速度を大幅に向上させます。例えば、「人工知能」という用語のインデックスエントリは、この用語を含むすべての文書IDと位置をリストアップします。\n\n​\nK\n​\nキーワード検索 (Keyword Search)\n\n特定の語彙を含む文書を見つける正確なマッチングに基づく検索方法です。この方法は計算効率が高く、製品モデル、固有名詞、特定のコマンドなど、ユーザーが見つけたい用語を明確に知っているシナリオに適していますが、同義語や関連する概念を使用して表現されたコンテンツを見逃す可能性があります。\n\n​\n知識ベース (Knowledge Base)\n\nAIアプリケーションで構造化された情報を保存し、モデルに専門知識の源を提供するデータベースです。Difyプラットフォームでは、知識ベースはさまざまな文書（PDF、Word、ウェブページなど）を含むことができ、処理されてAI検索に使用され、正確で根拠のある回答を生成するために使用されます。特にドメインエキスパートアプリケーションの構築に適しています。\n\n​\n知識検索 (Knowledge Retrieval)\n\nユーザーの質問に最も関連する情報を知識ベースから見つけるプロセスであり、RAGシステムの重要な構成要素です。効果的な知識検索は、関連するコンテンツを見つけるだけでなく、返される情報量を制御し、モデルを妨げる可能性のある無関係なコンテンツを避けながら、正確で完全な回答を確保するのに十分な背景を提供します。\n\n​\nL\n​\n大規模言語モデル (LLM, Large Language Model)\n\n大量のテキストで訓練され、人間の言語を理解し生成できるAIモデルです。現代のLLM（GPTシリーズ、Claudeなど）は、記事の作成、質問への回答、コードの作成、さらには推論も行うことができます。これらは様々なAIアプリケーションのコアエンジンであり、特に言語理解と生成を必要とするシナリオに適しています。\n\n​\nローカルモデル推論 (Local Model Inference)\n\nクラウドサービスに依存せずに、ユーザー自身のデバイス上でAIモデルを実行するプロセスです。このアプローチは、より良いプライバシー保護（データがローカル環境を離れない）と低いレイテンシー（ネットワーク転送不要）を提供し、機密データの処理やオフライン作業を必要とするシナリオに適していますが、通常はローカルデバイスの計算能力によって制限されます。\n\n​\nM\n​\nサービスとしてのモデル (MaaS, Model-as-a-Service)\n\nプロバイダーがAPIを通じて事前トレーニング済みモデルへのアクセスを提供するクラウドサービスモデルです。ユーザーはモデルのトレーニング、デプロイ、または保守について心配する必要はなく、単にAPIを呼び出して使用料を支払うだけで、AIアプリケーションの開発閾値とインフラコストを大幅に下げます。アイデアの迅速な検証やプロトタイプの構築に適しています。\n\n​\n最大トークン数 (Max_tokens)\n\nモデルが単一の応答で生成する最大文字数を制御するパラメータです。1つのトークンは約4文字または英単語の3/4に相当します。適切な最大トークン数を設定することで、回答の長さを制御し、過度に冗長な出力を避け、必要な情報の完全な表現を確保できます。例えば、簡単な要約は200トークンに設定される場合がありますが、詳細なレポートでは2000トークンが必要になる場合があります。\n\n​\nメモリ (Memory)\n\nAIシステムが過去のインタラクション情報を保存して使用し、複数ターンの会話を一貫して保つ能力です。効果的なメモリメカニズムにより、AIはコンテキスト参照を理解し、ユーザーの好みを記憶し、長期的な目標を追跡できるようになり、これによりパーソナライズされた継続的なユーザーエクスペリエンスを提供し、すでに提供された情報を繰り返し尋ねることを避けます。\n\n​\nメタデータフィルタリング (Metadata Filtering)\n\nドキュメント属性情報（タイトル、作者、日付、分類タグなど）を利用してコンテンツをフィルタリングする技術です。例えば、ユーザーは特定の日付範囲内の技術文書に検索を制限したり、特定の部署のレポートのみを照会したりして、検索前に範囲を絞り込み、検索効率と結果の関連性を向上させることができます。\n\n​\nマルチモーダルモデル (Multimodal Model)\n\nテキスト、画像、音声などの複数種類の入力データを処理できるモデルです。これらのモデルは従来のAIの単一知覚限界を打破し、画像内容の理解、ビデオシーンの分析、音声感情の認識が可能で、より包括的な情報理解の可能性を創出し、クロスメディア理解を必要とする複雑なアプリケーションシナリオに適しています。\n\n​\nマルチツール呼び出し (Multi-tool-call)\n\nモデルが単一のレスポンスで複数の異なるツールを呼び出す能力です。例えば、「北京と上海の明日の天気を比較し、適切な服装を推奨する」というリクエストを処理する場合、モデルは両都市の天気APIを同時に呼び出し、返された結果に基づいて合理的な提案を提供し、複雑なタスクを処理する効率を向上させます。\n\n​\nマルチパス検索 (Multi-path Retrieval)\n\n複数の検索方法を通じて並行して情報を取得する戦略です。例えば、システムはキーワード検索、セマンティックマッチング、知識グラフクエリを同時に使用し、結果をマージしてフィルタリングすることで、情報検索のカバレッジと精度を向上させ、特に複雑または曖昧なユーザークエリの処理に適しています。\n\n​\nP\n​\n親子チャンキング (Parent-Child Chunking)\n\n2レベルのコンテンツブロックを作成する高度なテキスト分割戦略：親ブロックは完全なコンテキストを保持し、子ブロックは正確なマッチングポイントを提供します。システムはまず子ブロックを使用して関連コンテンツの位置を特定し、次に対応する親ブロックを取得して完全な背景を提供し、検索精度とコンテキストの完全性のバランスを取り、研究論文や技術マニュアルなどの複雑な文書の処理に適しています。\n\n​\n存在ペナルティ (Presence Penalty)\n\n言語モデルがコンテンツを繰り返すことを防ぐパラメータ設定です。すでに出現した語彙の生成確率を下げることにより、モデルが新しい表現を探索することを奨励します。パラメータ値が高いほど、モデルが以前に生成したコンテンツを繰り返す可能性が低くなり、AI応答でよく見られる循環的な議論や問題の繰り返し説明を避けるのに役立ちます。\n\n​\n事前定義モデル (Predefined Model)\n\nAIベンダーによってトレーニングされ提供される既製モデルで、ユーザーは自分でトレーニングすることなく直接呼び出すことができます。これらのクローズドソースモデル（GPT-4、Claudeなど）は通常、大規模にトレーニングおよび最適化され、強力で使いやすく、迅速なアプリケーション開発や独立したトレーニングリソースを欠くチームに適しています。\n\n​\nプロンプト (Prompt)\n\nAIモデルに特定の応答を生成するよう導く入力テキストです。よく設計されたプロンプトは出力品質を大幅に向上させ、明確な指示、例の提供、フォーマット要件の設定などの要素を含みます。例えば、異なるプロンプトは同じモデルに学術記事、創造的なストーリー、または技術分析を生成するよう導くことができ、AI出力に影響を与える最も重要な要因の一つとなっています。\n\n​\nQ\n​\nQ&Aモード (Q&A Mode)\n\nドキュメントコンテンツに対して質問-回答のペアを自動生成する特殊なインデックス作成戦略で、「質問から質問」へのマッチングを実現します。ユーザーが質問すると、システムは意味的に類似した事前生成された質問を探し、対応する回答を返します。このモードは特にFAQコンテンツや構造化された知識ポイントに適しており、より正確な質問応答体験を提供します。\n\n​\nR\n​\n検索拡張生成 (RAG, Retrieval-Augmented Generation)\n\n外部知識検索と言語生成を組み合わせた技術アーキテクチャです。システムはまず知識ベースからユーザーの質問に関連する情報を検索し、次にこの情報をコンテキストとして言語モデルに提供し、根拠のある正確な回答を生成します。RAGは言語モデルの限られた知識と幻覚問題を克服し、特に最新または専門的な知識を必要とするアプリケーションシナリオに適しています。\n\n​\n推論と行動 (ReAct, Reasoning and Acting)\n\nモデルが思考と操作の実行を交互に行うことができるAIエージェントフレームワークです。問題解決のプロセスでは、モデルはまず現在の状態を分析し、計画を立て、次に適切なツール（検索エンジン、計算機など）を呼び出し、ツールの返す結果に基づいて次のステップを考え、問題が解決されるまで思考-行動-思考のサイクルを形成します。これは複数のステップと外部ツールを必要とする複雑なタスクに適しています。\n\n​\n再ランキング (ReRank)\n\n予備検索結果に対して二次ソートを行い、最終結果の関連性を向上させる技術です。例えば、システムはまず効率的なアルゴリズムを通じて大量の候補コンテンツを迅速に検索し、次により複雑だが精密なモデルを使用してこれらの結果を再評価し並べ替え、最も関連性の高いコンテンツを前に配置することで、検索効率と結果品質のバランスを取ります。\n\n​\n再ランキングモデル (Rerank Model)\n\n検索結果とクエリの関連性を評価し再順序付けするために特別に設計されたモデルです。予備検索とは異なり、これらのモデルは通常より複雑なアルゴリズムを使用し、より多くの意味要素を考慮し、コンテンツがユーザーの意図にどれだけよく一致するかをより正確に判断できます。例えば、Cohere RerankやBGE Rerankerなどのモデルは検索や推薦システムの結果品質を大幅に向上させることができます。\n\n​\nレスポンス形式 (Response_format)\n\nプレーンテキスト、JSON、HTMLなど、モデル出力の構造タイプの指定です。特定のレスポンス形式を設定することで、AI出力がプログラムで処理しやすくなったり、他のシステムに統合しやすくなったりします。例えば、モデルにJSON形式で回答するよう要求すると、出力が一貫した構造を持つことが保証され、フロントエンドアプリケーションが直接解析して表示しやすくなります。\n\n​\nリバースコーリング (Reverse Calling)\n\nプラグインがプラットフォームと対話するための双方向メカニズムで、プラグインがプラットフォーム機能を積極的に呼び出すことを可能にします。Difyでは、これはサードパーティプラグインがAIから呼び出されるだけでなく、ワークフローのトリガーや他のプラグインの呼び出しなど、Difyのコア機能を返りに使用することもできることを意味し、システムの拡張性と柔軟性を大きく向上させます。\n\n​\n検索テスト (Retrieval Test)\n\n知識ベースの検索効果を検証する機能で、開発者がユーザークエリをシミュレートしシステムの返す結果を評価することを可能にします。このテストは開発者がシステムの検索能力の境界を理解し、見逃し検出、誤検出、関連性の低さなどの潜在的な問題を発見して修正するのに役立ち、RAGシステムを最適化するために不可欠なツールです。\n\n​\nS\n​\nスコア閾値 (Score Threshold)\n\n検索結果をフィルタリングするための類似度閾値で、設定値を超えるスコアのコンテンツのみが返されます。適切な閾値を設定することで、無関係な情報がモデル生成を妨げることを避け、回答の正確性を向上させることができます。例えば、閾値が0.8（1.0満点中）に設定されている場合、高度に関連性の高いコンテンツのみが採用されますが、情報が不完全になる可能性があります。閾値を下げるとより多くのコンテンツが含まれますがノイズが入る可能性があります。\n\n​\nセマンティック検索 (Semantic Search)\n\n単純なキーワードマッチングではなく、テキストの意味の理解とマッチングに基づく検索方法です。ベクトル埋め込み技術を使用してテキストを数学的表現に変換し、クエリとドキュメント間の意味的類似性を計算します。この方法は、表現方法は異なるが意味が似ているコンテンツを見つけ、同義語やコンテキスト関係を理解し、さらには言語横断検索をサポートし、特に複雑または自然言語形式のクエリに適しています。\n\n​\nセッション変数 (Session Variables)\n\n複数ターンの対話コンテキスト情報を保存するメカニズムで、AIがコヒーレントな対話を維持することを可能にします。例えば、システムはユーザーの好み（「簡潔な回答」など）、アイデンティティ情報、または対話履歴状態を記憶し、繰り返しの問い合わせを避け、パーソナライズされた体験を提供します。Difyでは、開発者はこれらの変数を定義および管理し、ユーザーを本当に記憶するアプリケーションを構築することができます。\n\n​\n音声からテキスト変換 (STT, Speech-to-Text)\n\nユーザーの音声入力をテキストデータに変換する技術です。この技術により、ユーザーはタイピングではなく話すことでAIシステムと対話でき、対話の自然さと利便性が向上し、特にモバイルデバイス、運転シナリオ、またはアクセシビリティアプリケーションに適しており、音声アシスタントやリアルタイム文字起こしアプリケーションの基盤となります。\n\n​\nストリームツール呼び出し (Stream-tool-call)\n\nAIシステムが完全な回答が生成されるのを待たずに、応答を生成しながら外部ツールを呼び出すことができるリアルタイム処理モードです。このアプローチは複雑なタスクの応答速度を大幅に向上させ、ユーザー体験をよりスムーズにし、複数のツール呼び出しを必要とする対話シナリオに適しています。\n\n​\nストリーミングレスポンス (Streaming Response)\n\nAIシステムがコンテンツをすべて生成し終わるのを待ってから一度に表示するのではなく、生成されたコンテンツをユーザーにリアルタイムで返す応答メカニズムです。このアプローチは特に長い回答に対するユーザーの待機体験を大幅に改善し、ユーザーは部分的なコンテンツをすぐに見て読み始めることができ、人間の会話における即時フィードバックに似たより自然な対話体験を提供します。\n\n​\nT\n​\n温度 (Temperature)\n\n通常0-1の間で、言語モデル出力のランダム性を制御するパラメータです。温度が低い（0に近い）ほど、モデル出力はより確定的で保守的になり、高確率の語彙を好み、事実に基づく回答に適しています。温度が高い（1に近い）ほど、出力はより多様で創造的になり、創造的な執筆に適しています。例えば、天気予報では0.1の低温度を使用し、物語創作では0.8の高温度を使用する場合があります。\n\n​\nテキスト埋め込み (Text Embedding)\n\nテキストを数値ベクトルに変換するプロセスで、AIシステムが言語を理解し処理することを可能にします。これらのベクトルは語彙と文の意味特徴を捉え、コンピュータがテキスト間の類似性を測定し、関連コンテンツをクラスタリングし、マッチング情報を検索することを可能にします。異なる埋め込みモデル（OpenAIのtext-embedding-ada-002やCohereのembed-multilingualなど）は異なる言語やアプリケーションシナリオ向けに最適化されています。\n\n​\nツール呼び出し (Tool Calling)\n\nAIシステムが外部機能を識別し使用する能力で、モデルの能力境界を大幅に拡張します。例えば、言語モデル自体はリアルタイムデータにアクセスできませんが、天気APIを呼び出すことで現在の天気情報を提供できます。データベース照会ツールを呼び出すことで最新の製品在庫を取得でき、計算機を呼び出すことで複雑な計算を実行でき、AIがトレーニングデータ範囲を超える問題を解決できるようになります。\n\n​\nTopK\n\n検索で返される結果の数を制御するパラメータで、類似度が最も高い上位K個のテキストフラグメントを保持するよう指定します。適切なTopK値の設定はRAGシステムのパフォーマンスに不可欠です：値が小さすぎると重要な情報を失う可能性があり、値が大きすぎるとノイズを招き言語モデルの処理負担を増やす可能性があります。例えば、簡単な質問ではTopK=3で十分かもしれませんが、複雑な質問では十分な背景を得るためにTopK=10が必要かもしれません。\n\n​\n核サンプリング (TopP, Nucleus Sampling)\n\n累積確率が閾値Pに達する最も可能性の高い語彙からのみ次の単語を選択するテキスト生成制御方法です。最高確率の単語を固定選択することや完全にランダムな選択とは異なり、TopPは確定性と創造性のバランスを取ります。例えば、TopP=0.9は、モデルが確率の合計が90%を占める語彙のみを考慮し、低確率のオプションを無視することを意味し、完全に予測可能な出力と過度にランダムなコンテンツの両方を避けます。\n\n​\n思考の木 (ToT, Tree of Thought)\n\n複数の推論経路を探索する思考方法で、モデルが異なる視点から問題を分析することを可能にします。人間の「もし…ならば…」という思考パターンに似ており、思考の木はモデルに複数の可能な思考分岐を生成させ、各分岐の実現可能性を評価し、最適な経路を選択して継続することを可能にします。これは試行錯誤や複数の可能性を考慮する必要がある複雑な問題を解決するのに特に適しています。\n\n​\nテキスト音声変換 (TTS, Text-to-Speech)\n\n書かれたテキストを自然な音声に変換する技術で、AIシステムが音声でユーザーとコミュニケーションすることを可能にします。現代のTTSシステムは人間の品質に近い自然な音声を生成でき、複数の言語、音調、感情表現をサポートし、オーディオブック、ナビゲーションシステム、音声アシスタント、アクセシビリティサービスで広く使用され、異なるシナリオやユーザーにより自然な対話体験を提供します。\n\n​\nV\n​\nベクトルデータベース (Vector Database)\n\nベクトル埋め込みの保存と検索に特化したデータベースシステムで、効率的な意味検索のインフラストラクチャとして機能します。従来のデータベースとは異なり、ベクトルデータベースは高次元ベクトル類似度検索に最適化され、数百万のドキュメントから意味的に類似したコンテンツを迅速に見つけることができます。Pinecone、Milvus、Qdrantなどの一般的なベクトルデータベースは、RAGシステム、推薦エンジン、コンテンツ分析で重要な役割を果たしています。\n\n​\nベクトル検索 (Vector Retrieval)\n\nテキストベクトル埋め込みの類似性に基づく検索方法で、セマンティック検索の技術的中核を形成します。システムはまずユーザークエリをベクトルに変換し、次に事前計算されたドキュメントベクトルで最も類似したコンテンツを見つけます。この方法は深い意味的関係を捉え、表現方法は異なるが意味が似ているコンテンツを見つけ、キーワード検索の限界を克服し、自然言語クエリや概念的な問題の処理に特に適しています。\n\n​\nビジョン機能 (Vision)\n\nマルチモーダルLLMが画像を理解し処理する機能で、モデルがユーザーがアップロードした画像を分析し、テキストと組み合わせた応答を生成できるようにします。例えば、ユーザーは製品写真をアップロードして使用方法を問い合わせたり、メニュー写真をアップロードして翻訳を要求したり、グラフをアップロードしてデータトレンドの分析を依頼したりできます。この機能はAIアプリケーションシナリオを大幅に拡張し、対話をより直感的で多様化します。\n\n​\nW\n​\nワークフロー (Workflow)\n\n複雑なAIアプリケーションを複数の独立したノードに分解し、特定の順序で実行するタスク編成方法です。Difyプラットフォームでは、開発者は視覚的にワークフローを設計し、複数の処理ステップ（ユーザー入力処理、知識検索、マルチモデル連携、条件分岐など）を組み合わせて、複雑なビジネスロジックを処理できるAIアプリケーションを構築し、アプリケーション開発を柔軟かつ直感的にします。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nA\nエージェント (Agent)\nエージェンティックワークフロー (Agentic Workflow)\n自動音声認識 (ASR, Automatic Speech Recognition)\nB\n思考の骨格 (BoT, Backbone of Thought)\nC\nチャンキング (Chunking)\n引用と帰属 (Citation and Attribution)\n思考の連鎖 (CoT, Chain of Thought)\nD\nドメイン固有言語 (DSL, Domain-Specific Language)\nE\n抽出・変換・読み込み (ETL, Extract, Transform, Load)\nF\n頻度ペナルティ (Frequency Penalty)\n関数呼び出し (Function Calling)\nG\n一般的なチャンキングパターン (General Chunking Pattern)\n思考のグラフ (GoT, Graph of Thought)\nH\nハイブリッド検索 (Hybrid Search)\nI\n転置インデックス (Inverted Index)\nK\nキーワード検索 (Keyword Search)\n知識ベース (Knowledge Base)\n知識検索 (Knowledge Retrieval)\nL\n大規模言語モデル (LLM, Large Language Model)\nローカルモデル推論 (Local Model Inference)\nM\nサービスとしてのモデル (MaaS, Model-as-a-Service)\n最大トークン数 (Max_tokens)\nメモリ (Memory)\nメタデータフィルタリング (Metadata Filtering)\nマルチモーダルモデル (Multimodal Model)\nマルチツール呼び出し (Multi-tool-call)\nマルチパス検索 (Multi-path Retrieval)\nP\n親子チャンキング (Parent-Child Chunking)\n存在ペナルティ (Presence Penalty)\n事前定義モデル (Predefined Model)\nプロンプト (Prompt)\nQ\nQ&Aモード (Q&A Mode)\nR\n検索拡張生成 (RAG, Retrieval-Augmented Generation)\n推論と行動 (ReAct, Reasoning and Acting)\n再ランキング (ReRank)\n再ランキングモデル (Rerank Model)\nレスポンス形式 (Response_format)\nリバースコーリング (Reverse Calling)\n検索テスト (Retrieval Test)\nS\nスコア閾値 (Score Threshold)\nセマンティック検索 (Semantic Search)\nセッション変数 (Session Variables)\n音声からテキスト変換 (STT, Speech-to-Text)\nストリームツール呼び出し (Stream-tool-call)\nストリーミングレスポンス (Streaming Response)\nT\n温度 (Temperature)\nテキスト埋め込み (Text Embedding)\nツール呼び出し (Tool Calling)\nTopK\n核サンプリング (TopP, Nucleus Sampling)\n思考の木 (ToT, Tree of Thought)\nテキスト音声変換 (TTS, Text-to-Speech)\nV\nベクトルデータベース (Vector Database)\nベクトル検索 (Vector Retrieval)\nビジョン機能 (Vision)\nW\nワークフロー (Workflow)",
        "error": null
      },
      {
        "link_index": 6,
        "link_text": "クラウドサービス",
        "target_url": "https://docs.dify.ai/ja-jp/getting-started/cloud",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\n入門\nクラウドサービス\nCopy page\n\n注意：Difyは現在ベータテスト段階にあります。ドキュメントと製品に不一致がある場合は、実際の製品体験をご参照ください。\n\nDifyは誰でも手軽にご利用いただけるクラウドサービスです。プランと価格をご確認の上、お客様の要求に最適なプランをお選びください。\n\nまずはSandboxプランからお試しいただけます。クレジットカード不要で200回のOpenAI APIコールを無料で試すことができます。クラウド版のSandboxプランのご利用には、GitHubまたはGoogleアカウント、および有効なOpenAI APIキーが必要です。使用手順は以下の通りです：\n\nDifyクラウドにサインアップし、新しいワークスペースを作成するか、既存のワークスペースに参加します。\nモデルプロバイダーを設定するか、Dify提供のモデルプロバイダーを使えます。\n以上で、アプリケーションを作成できます！\n​\nよくある質問\n\nQ: Difyクラウドを使用する際、私のデータはどのように処理・保存されますか？\n\nA: Difyクラウドを使用すると、ユーザーデータは米国東部地域にあるAWSサーバーに安全に保存されます。これには、積極的に入力したデータとアプリから生成されたデータの両方が含まれます。私たちはデータのセキュリティと完全性を最優先事項としており、クラウドストレージソリューションにおける最高水準の基準に基づき管理されることを確保しています。\n\nQ: APIキーや他の機密情報を保護するためにどのような対策がありますか？\n\nA: Difyでは、APIキーや他の機密情報を保護することの重要性を深く理解しています。これらの情報は保存時に暗号化され、Dify側から閲覧することはできません。アクセスは、正当な所有者であるユーザーご本人のみに限定されます。\n\nQ: Difyクラウドでのアプリの匿名化について説明していただけますか？\n\nA: Difyクラウドでは、プライバシーを確保し、暗号化と復号化のオーバーヘッドを減らすためにアプリのデータを匿名化しています。これは、アプリで使用されるデータが特定可能なユーザーアカウントと直接関連付けられないことを意味します。データを匿名化することで、クラウドサービスのパフォーマンスを維持しながらプライバシーを強化しています。\n\nQ: Difyクラウドから自分のアカウントと関連するすべてのデータを削除するプロセスはどのようになっていますか？\n\nA: アカウントおよび関連データの削除をご希望の場合、アカウント設定ページにアクセスするか、画面右上のアバターをクリックして「アカウント」を選択してください。ページ内に「アカウントを削除」ボタンがありますので、クリックして画面の指示に従ってください。当社はお客様のプライバシーとデータに関する権利を尊重しており、ご依頼に基づき、データ保護規制に従って、システムからお客様に関連するすべてのデータを消去いたします。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nモデルプロバイダーリスト\nコミュニティ版\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nよくある質問",
        "error": null
      },
      {
        "link_index": 7,
        "link_text": "Dify Premium",
        "target_url": "https://docs.dify.ai/ja-jp/getting-started/dify-premium",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\n入門\nDify Premium\nCopy page\n\nプレミアムPremium\n\nDify PremiumはAWS AMI製品であります。これにより、ブランドのカスタマイズが可能で、AWS EC2にワンクリックで展開できます。AWS Marketplaceから購読し、次のようなシナリオに最適です：\n\n中小企業が1つ以上のアプリケーションをサーバーに構築し、データのプライバシーに関心がある場合。\nDify Cloudのサブスクリプションプランに関心があり、しかし、活用事例がプランで提供されるリソースを超える場合。\nDify Enterpriseを組織内で導入する前に、POC検証を行いたい場合。\n​\nセットアップ\n\nDifyを初めて使用する際には、管理者初期化パスワード（EC2インスタンスIDとして設定）を入力し、セットアッププロセスを開始してください。\n\nAMIを展開した後は、EC2コンソールで見つかるインスタンスのパブリックIPを使用してDifyにアクセスします（デフォルトではHTTPポート80を使用します）。\n\n​\nアップグレード\n\nEC2インスタンスで、次のコマンドを実行してください：\n\nCopy\ngit clone https://github.com/langgenius/dify.git /tmp/dify\nmv -f /tmp/dify/docker/* /dify/\nrm -rf /tmp/dify\ndocker-compose down\ndocker-compose pull\ndocker-compose -f docker-compose.yaml -f docker-compose.override.yaml up -d\n\n\nコミュニティ版を v1.0.0 にアップグレードする\n\n​\nカスタマイズ\n\nセルフホスト展開の場合と同様に、EC2インスタンス内の.envファイルの環境変数を必要に応じて変更することができます。その後、以下のコマンドを使用してDifyを再起動してください：\n\nCopy\ndocker-compose down\nocker-compose -f docker-compose.yaml -f docker-compose.override.yaml up -d\n\n​\nカスタマイズ Webアプリのロゴやブランド\n\nこの機能は設定のカスタマイズで有効にすることができます。Powered by Difyを削除を有効にして、独自のロゴをアップロードしてください。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nよくある質問\nDify 教育版\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nセットアップ\nアップグレード\nカスタマイズ\nカスタマイズ Webアプリのロゴやブランド",
        "error": null
      },
      {
        "link_index": 8,
        "link_text": "Dify 教育版",
        "target_url": "https://docs.dify.ai/ja-jp/getting-started/dify-for-education",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\n入門\nDify 教育版\nCopy page\n​\nはじめに\n\nDify教育版は、学生、教師、教育機関に手軽で手頃なAI学習・開発ツールを提供し、AI教育をより身近で普及させることを目指しています。\n\n​\nメリット\n\n学生の方へ：Dify SaaSサブスクリプションサービスを割安な価格で利用でき、より多くの計算リソースを獲得できます。授業の課題、研究プロジェクト、AIアプリケーション開発に役立ちます。\n\n教師の方へ：Difyを教育現場でAI教材として活用し、学生たちがAIアプリケーション開発について深く学べるようサポートします。\n\n教育機関・学校の方へ：チームでAIリソースを簡単に管理でき、教育効率を高め、教育分野におけるAIの可能性をさらに探求できます。\n\n​\n特典\n\n現在のDify教育版特典は、Difyプロフェッショナルプランのサブスクリプションが50%割引になるクーポンです。\n\n今後も学習や授業をサポートするための教育版専用の特典を継続的に提供していく予定です。ご期待ください。\n\n​\n申請方法\n​\n申請資格\n\nDify教育版認証を申請するには、以下の条件をすべて満たす必要があります：\n\n18歳以上であること\n現在、学生、教師、または教育機関の職員であること\n教育用メールアドレスでDifyアカウントを登録していること\n​\n申請手順\nDifyアカウントの作成\n\n教育版認証を申請する前に、教育用メールアドレスでDifyアカウントを登録してください。\n\nDify教育版認証の申請\n\n教育用メールアドレスで登録したDifyアカウントにログインし、右上のユーザーアイコンをクリックして、ドロップダウンメニューから設定を選択します。\n\n設定ページで、請求 > 教育版認証を申請をクリックします。\n\n学校の正式名称を入力します （略称は使用しないでください）。\n\n申請人の身分を選択します。\n\n利用規約に同意するにチェックを入れ、送信をクリックします。\n\n認証が成功すると、Dify教育版専用の割引クーポンが付与されます。\n​\nDify教育認証状況の確認方法\n\n教育認証の申請が成功すると、右上のユーザーアイコンをクリックして、ドロップダウンメニューからサブスクリプション状況を確認できます。サブスクリプション状況がEduと表示されていれば、教育認証が成功しています。\n\n​\nクーポンの使用方法\n​\n概要\n\nDify教育認証が完了すると、教育クーポンが自動的にあなたのDifyアカウントに付与されます。Difyプロフェッショナルプランを購読する際にこのクーポンを使用できます。\n\nクーポン割引：50%\n\nクーポン有効期間：12ヶ月\n\nクーポン使用条件：\n\n有効期限内にクーポンを使用する必要があります。有効期限が過ぎると使用できなくなります。\n教育版認証は年に一度のみ申請可能で、一度に1枚のクーポンしか取得できません。\nクーポンはワークスペースの所有者本人のみ利用可能です。\n​\n使い方\nサブスクリプションページで「Dify プロフェッショナルプラン」を選択：\n月額払いの場合：今すぐ始めるボタンを直接クリックし、決済ページへ進みます。\n年額払いの場合：ページ右上の年額請求スイッチをオンにした後、今すぐ始めるボタンをクリックし決済ページへ進みます。\n支払いページに進むと、クーポンコードが自動的に適用されます。このページでクーポンが有効になっていることを確認し、割引後の金額を確認できます。\n\n注文内容に問題がなければ、お支払い方法を選択してください。\n\nお支払いが完了すると、サブスクリプションの設定が完了となります。\n\nサブスクリプション後、あなたのステータスはPro(Edu)に更新されます。\n\n​\n教育情報の更新方法\n​\nメールアドレスの更新\n\nメールアドレスを変更する必要がある場合は、現在のところ手動対応となっております。<support@dify.ai>までご連絡ください。\n\n​\n学校情報の更新\n\n認証完了後に学校情報を変更したい場合：教育認証が完了した後に学校情報を変更する必要がある場合は、<support@dify.ai>までご連絡ください。\n\n認証期限切れ後の学校情報変更：教育認証の期限が切れた後は、再認証の際に新しい学校情報を入力することができます。\n\n​\nDify教育認証の更新方法\n\n教育認証の期限が切れた場合は、前述のDify教育認証の完了セクションを参照して、再度申請を行ってください。\n\n​\nよくある質問\nDifyを学習の方法は？\n\n公式ドキュメントを参照する：Dify公式ドキュメントで、詳細な使用ガイドをご覧いただけます。\n\nコミュニティに参加する：Dify Discordコミュニティに参加して、開発者と交流し、使用体験を共有しましょう。\n\nDifyプランの料金はいくらですか？\n\nDifyの料金ページで詳細をご確認いただけます。\n\n教育認証を申請できないのは誰ですか？\n\n18歳未満のユーザー。\n\n個人用メールアドレス（Gmailなど）でアカウント登録したユーザー。\n\n教育認証が拒否/取り消された理由と対処法は？\n\n以下の状況では、教育認証の申請が拒否または取り消される可能性があります：\n\n教育認証申請時に利用規約に同意するにチェックを入れなかった\n教育機関のメールアドレスを使用していない\n偽の学校や企業のメールアドレスを使用している\n虚偽の個人情報や学校情報を提供している\n教育特典の不正使用\n\n申請が拒否されたり認証が取り消された場合は、<support@dify.ai>までご連絡ください。\n\n卒業または学校を離れた後も教育認証は有効ですか？\n\n教育認証は教育機関のメールアドレスの状態に直接関連しています。教育メールアドレスが正常に使用できる限り、認証は有効です。\n\n教育メールアドレスが使用できなくなった場合は、<support@dify.ai>までご連絡ください。\n\n教育機関のメールアドレスを持っていない場合、教育認証を申請するにはどうすればよいですか？\n\n現在、Dify教育認証は主に教育機関のメールアドレスによる身分確認を通じて行われています。教育機関のメールアドレスをお持ちでない場合は、誠に申し訳ありませんが、教育認証を申請することはできません。\n\n以前にサブスクリプションを利用していましたが、現在は期限切れです。教育優待クーポンはまだ使用可能ですか？\n\n購読が期限切れの場合でも、アカウントにStripeの支払い情報が登録されている場合、次回の再購読時に教育優待クーポンが自動適用されます。\n\n現在Difyプランを購読中です。教育認証を申請した後、サブスクリプション内容はどうなりますか？\n\nプロフェッショナルプランを購読中の場合、教育優待クーポンは次回の課金周期から自動適用されます。\n\nプロフェッショナルプラン以外を購読中の場合、教育優待クーポンはアカウントに保存され、将来プロフェッショナルプランを選択した際に自動使用されます。\n\n教育認証済みでDifyプロフェッショナルプランを購読中ですが、次回課金開始前に解約した場合はどうなりますか？\n\n現在の課金周期終了時にサブスクリプションが解除され、同時に教育優待クーポンも失効し、再度有効化することはできません。\n\n解約後に教育認証を有効化した場合、割引は適用されますか？\n\n教育優待は保持されますが、以下の点にご注意ください：\n\n現在の購読期間終了後の再購読時にはクーポンが自動適用されます。\n購読期間終了前の更新/延長時には適用されず、割引を利用するには現行プラン終了後の再購入が必要です。\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nDify Premium\nModel configuration\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nはじめに\nメリット\n特典\n申請方法\n申請資格\n申請手順\nDify教育認証状況の確認方法\nクーポンの使用方法\n概要\n使い方\n教育情報の更新方法\nメールアドレスの更新\n学校情報の更新\nDify教育認証の更新方法\nよくある質問",
        "error": null
      },
      {
        "link_index": 9,
        "link_text": "支援を求める",
        "target_url": "https://docs.dify.ai/ja-jp/community/support",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nコミュニティ\n支援を求める\nCopy page\n\nこのドキュメントを読んでも製品の使用に関して疑問や提案がある場合は、以下の方法で支援を求めることができます。私たちのチームとコミュニティは、できる限りのサポートを提供いたします。\n\n​\nコミュニティサポート\n\nDifyのアカウント情報やその他の情報をコミュニティに投稿しないでください。また、サポートスタッフもアカウント情報を要求することはありません。\n\nGithub 上でイシューを提出\nDiscordコミュニティに参加\n​\nお問い合わせ\n\n製品サポート以外のその他の事柄に適用されます。\n\nhello@dify.ai へメールを送信\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nチャットストリームエージェントを使用した Twitter アカウントの分析方法\n貢献者になる\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nコミュニティサポート\nお問い合わせ",
        "error": null
      },
      {
        "link_index": 10,
        "link_text": "貢献者になる",
        "target_url": "https://docs.dify.ai/ja-jp/community/contribution",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nコミュニティ\n貢献者になる\nCopy page\n\nDifyに貢献したいと思っていることには素晴らしいと思います。私たちはあなたの貢献を心待ちにしております。スタッフも資金も限られた新興企業として、私たちはLLMアプリケーションの構築と管理のための最も直感的なワークフローを設計するという野心的な目標を持っています。そのため、コミュニティからのあらゆるサポートは貴重です。\n\n我々の現状を考えると、柔軟かつ迅速に更新する必要がありますが、貢献者がスムーズに貢献できるようにしたいとも考えています。そのために、この貢献ガイドを作成しました。このガイドは、あなたがコードベースに慣れ、貢献者としての活動を迅速に開始できるようにすることを目的としています。\n\nこのガイドは、Dify自体と同様に、常に改善されています。時折プロジェクトの実態よりも遅れることがあるかもしれませんが、ご理解と改善のためのフィードバックを心から歓迎します。\n\nライセンスに関しては、時間を取って短いライセンスと貢献者協定を読んでください。また、コミュニティは行動規範にも従います。\n\n​\n始める前に\n\n既存のイシューを探すか、新しいイシューを作成することができます。イシューは次の2つのカテゴリに分かれます：\n\n​\n機能リクエスト：\n\n新しい機能リクエストを行う場合は、提案する機能の目的を説明し、できるだけ詳細なコンテキストを提供してください。@perzeusssが作成した優れた機能リクエスト助手を使ってドラフトを作成することもできます。ぜひ試してみてください。\n\n既存のイシューから選びたい場合は、その下にコメントを残して意思を示してください。\n\n関連するチームメンバーが関与します。うまくいけば、彼らがコーディングを開始することを承認します。それまでは、変更が提案される可能性があるため、作業を開始しないでください。\n\n提案された機能が属する領域に応じて、異なるチームメンバーと連携する必要があります。以下は、各チームメンバーが現在取り組んでいる分野の概要です：\n\nMember\tScope\n@yeuoly\tArchitecting Agents\n@jyong\tRAG pipeline design\n@GarfieldDai\tBuilding workflow orchestrations\n@iamjoel & @zxhlyh\tMaking our frontend a breeze to use\n@guchenhe & @crazywoola\tDeveloper experience, points of contact for anything\n@takatost\tOverall product direction and architecture\n\n優先順位の判定ルール：\n\nFeature Type\tPriority\nHigh-Priority Features as being labeled by a team member\tHigh Priority\nPopular feature requests from our community feedback board\tMedium Priority\nNon-core features and minor enhancements\tLow Priority\nValuable but not immediate\tFuture-Feature\n​\nその他（例えばバグ報告、パフォーマンス向上、タイポ修正）：\n\nすぐにコーディングを開始してください。\n\n優先順位の判定ルール：\n\nIssue Type\tPriority\nBugs in core functions (cannot login, applications not working, security loopholes)\tCritical\nNon-critical bugs, performance boosts\tMedium Priority\nMinor fixes (typos, confusing but working UI)\tLow Priority\n​\nインストール\n\n以下はDifyを開発用に設定する手順です：\n\n​\n1. リポジトリをフォークする\n​\n2. リポジトリをクローンする\n\nターミナルからフォークしたリポジトリをクローンします：\n\nCopy\ngit clone git@github.com:<github_username>/dify.git\n\n​\n3. 依存関係を確認する\n\nDifyは以下のツールとライブラリに依存しています：\n\nDocker\nDocker Compose\nNode.js v18.x (LTS)\nnpm バージョン 8.x.x もしくは Yarn\nPython バージョン 3.10.x\n​\n4. インストール\n\nDifyはバックエンドとフロントエンドで構成されています。cd api/を使ってバックエンドディレクトリに移動し、次はバックエンドREADMEに従ってインストールして下さい。別のターミナルでcd web/を使ってフロントエンドディレクトリに移動し、そしてフロントエンドREADMEに従ってインストールして下さい。\n\n一般的な問題とトラブルシューティングの手順についてはインストールFAQを参照してください。\n\n​\n5. ブラウザでDifyにアクセスする\n\n設定を確認するため、ブラウザを開きhttp://localhost:3000（デフォルトまたはカスタムURLとポート）にアクセスします。これでDifyが動作しているはずです。\n\n​\n開発\n\nモデルを追加提供する場合は、このガイドを参照してください。\n\nエージェントやワークフローにツールを追加提供する場合は、このガイドを参照してください。\n\n注意点：新しいツールを提供したい場合は、必ずツールの YAML 説明ページに連絡先を残し、ドキュメントDify-docs のコードリポジトリに対応するPRを提出してください。\n\n貢献する部分を迅速に理解できるように、以下にDifyのバックエンドとフロントエンドの簡単な注釈付きアウトラインを示します：\n\n​\nバックエンド\n\nDifyのバックエンドはPythonで書かれており、Flaskフレームワークを使用しています。SQLAlchemyをORMとして使用し、Celeryをタスクキューとして使用しています。認証ロジックはFlask-loginで処理されます。\n\nCopy\n[api/]\n├── constants             // コードベース全体で使用される定数設定。\n├── controllers           // APIルート定義とリクエスト処理ロジック。           \n├── core                  // コアアプリケーションオーケストレーション、モデル統合、ツール。\n├── docker                // Dockerおよびコンテナ化関連の設定。\n├── events                // イベント処理と処理\n├── extensions            // サードパーティフレームワーク/プラットフォームとの拡張機能。\n├── fields                // シリアライズ/マーシャリングのためのフィールド定義。\n├── libs                  // 再利用可能なライブラリとヘルパー。\n├── migrations            // データベース移行のためのスクリプト。\n├── models                // データベースモデルとスキーマ定義。\n├── services              // ビジネスロジックを指定。\n├── storage               // 秘密鍵保管。      \n├── tasks                 // 非同期タスクとバックグラウンドジョブの処理。\n└── tests\n\n​\nフロントエンド\n\nこのWebサイトはNext.jsテンプレートを使用しており、スタイリングにはTailwind CSSを使用しています。React-i18nextを国際化に使用しています。\n\nCopy\n[web/]\n├── app                   // レイアウト、ページ、およびコンポーネント\n│   ├── (commonLayout)    // アプリ全体で使用される共通レイアウト\n│   ├── (shareLayout)     // トークン固有のセッション間で共有されるレイアウト \n│   ├── activate          // アクティベートページ\n│   ├── components        // ページとレイアウトで共有されるコンポーネント\n│   ├── install           // インストールページ\n│   ├── signin            // サインインページ\n│   └── styles            // グローバルに共有されるスタイル\n├── assets                // 静的アセット\n├── bin                   // ビルドステップで実行されるスクリプト\n├── config                // 調整可能な設定とオプション \n├── context               // アプリの異なる部分で使用される共有コンテキスト\n├── dictionaries          // 言語固有の翻訳ファイル \n├── docker                // コンテナ設定\n├── hooks                 // 再利用可能なフック\n├── i18n                  // 国際化設定\n├── models                // データモデルとAPIレスポンスの形状を記述\n├── public                // ファビコンなどのメタアセット\n├── service               // APIアクションの形状を指定\n├── test                  \n├── types                 // 関数パラメータと戻り値の記述\n└── utils                 // 共有ユーティリティ関数\n\n​\nPRを提出する\n\n最後に、私たちのリポジトリにプルリクエスト（PR）を提出する時が来ました。重要な機能の場合、最初に deploy/dev ブランチにマージしてテストを行い、その後 main ブランチにマージします。マージコンフリクトが発生した場合や、プルリクエストの提出方法が分からない場合は、GitHubのプルリクエストチュートリアルを参照してください。\n\nこれで完了です！あなたのPRがマージされると、あなたは私たちのREADMEに貢献者として掲載されます。\n\n​\nヘルプを求める\n\n貢献の過程で困難に直面したり質問がある場合は、関連するGitHubのイシューで質問を提出するか、私たちのDiscordに参加して迅速なコミュニケーションを行ってください。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\n支援を求める\nドキュメントへの貢献\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\n始める前に\n機能リクエスト：\nその他（例えばバグ報告、パフォーマンス向上、タイポ修正）：\nインストール\n1. リポジトリをフォークする\n2. リポジトリをクローンする\n3. 依存関係を確認する\n4. インストール\n5. ブラウザでDifyにアクセスする\n開発\nバックエンド\nフロントエンド\nPRを提出する\nヘルプを求める",
        "error": null
      },
      {
        "link_index": 11,
        "link_text": "ドキュメントへの貢献",
        "target_url": "https://docs.dify.ai/ja-jp/community/docs-contribution",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nコミュニティ\nドキュメントへの貢献\nCopy page\n\nDify のヘルプドキュメントは、オープンソースプロジェクトとして運営されています。どのような形式の貢献も歓迎します。ドキュメントに問題を見つけた場合や、自分で内容を追加したい場合には、GitHub 上で issue を提出するか、もしくは直接 pull request を作成してください。我々は迅速に対応いたします。\n\n​\n貢献の方法\n\nドキュメントの問題は次の2つのカテゴリーに分けられます：\n\nコンテンツ修正\nコンテンツ追加\nベストプラクティス\n​\nコンテンツの誤り\n\nドキュメントを読んでいる際に内容の誤りを見つけたり、一部を修正したい場合は、文書ページの右側にある目次内の “Github に編集” ボタンをクリックしてください。これにより、GitHub のオンラインエディターを使用してファイルを修正できます。その後、修正内容を簡潔に説明した pull request を作成してください。タイトルは Fix: Update xxx の形式を使用してください。リクエストを受け取った後、レビューを行い、問題がなければ修正をマージします。\n\nもちろん、Issues ページにドキュメントのリンクを貼り付け、修正が必要な内容を簡単に説明していただくことも可能です。フィードバックを受け取った後、迅速に対応いたします。\n\n​\nコンテンツの欠落\n\n新しいドキュメントをコードリポジトリに追加したい場合は、以下の手順に従ってください：\n\nリポジトリをフォークする\n\nリポジトリを GitHub アカウントにフォークし、リポジトリをローカルにクローンします:\n\nCopy\ngit clone https://github.com/<your-github-account>/dify-docs.git\n\n\n注: GitHub のオンラインコードエディターを使用して、新しい md ファイルを適切なディレクトリに直接送信することもできます。\n\n関連するドキュメントディレクトリを見つけてファイルを追加する\n\nたとえば、サードパーティツールの使用方法に関するドキュメントを追加したい場合は、/guides/tools/tool-configuration/ ディレクトリに新しい md ファイルを追加してください。\n\npull request を提出する\n\npull request を提供する時、Docs: add xxx のタイトルで説明欄に書いて、文章内容を簡単に記載してください。request を受け取った後、review を行い、問題がなければ merge します。\n\n​\nベストプラクティス\n\nDifyで構築した革新的なアプリケーション事例の共有を大歓迎します！コミュニティメンバーが皆様の実践経験を理解・再現しやすくするため、以下の構成でのコンテンツ作成をお勧めします：\n\nCopy\n1. プロジェクト概要\n   - アプリケーションの活用シーンと解決課題\n   - コア機能と特徴\n   - デモンストレーションと成果\n\n2. システム設計・処理フロー\n\n3. 事前準備（必要な場合）\n   - 必要リソース一覧\n   - ツールと依存関係\n\n4. Dify実装手順（参考）\n   - アプリケーション作成と基本設定\n   - ワークフロー構築の詳細\n   - 主要ノード設定解説\n\n5. FAQ\n\n\n説明用のスクリーンショットを追加される場合は、オンライン画像ホスティングサービスのリンクをご利用ください。\n\n皆様の貴重なナレッジシェアが、Difyコミュニティの発展を支えます！\n\n​\nヘルプを受ける\n\n貢献の過程で困難に直面したり、疑問がある場合は、関連する GitHub の issue に質問を投稿するか、Discord に参加して迅速にコミュニケーションを取ることができます。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\n貢献者になる\nはじめに\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\n貢献の方法\nコンテンツの誤り\nコンテンツの欠落\nベストプラクティス\nヘルプを受ける",
        "error": null
      },
      {
        "link_index": 12,
        "link_text": "はじめに",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/introduction",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nプラグイン\nはじめに\nCopy page\n\nコミュニティーバージョンでプラグイン機能を利用するには、バージョンをv1.0.0にアップデートしてください。\n\n​\nプラグインとは\n\nプラグインとは、開発者がより手軽に機能を拡張できる、サードパーティ製の拡張モジュールです。Difyプラットフォームには、Difyチームやコミュニティによってメンテナンスされた多くのツールがすでに用意されていますが、多様化するニッチなニーズを完全に満たせない場合があります。また、新しいツールをDifyプラットフォームに開発・統合するには、時間と手間がかかることが少なくありません。\n\nそこで、よりアジャイルな開発を可能にするため、Difyのエコシステムをオープンにし、包括的なプラグイン開発SDKを提供することにしました。これにより、すべての開発者が独自のツールを容易に構築し、サードパーティのモデルやツールをシームレスに統合して、アプリケーションの可能性を飛躍的に向上させることができます。\n\n​\nプラグインのメリット\n\n新しいプラグインシステムは、従来のフレームワークの制約を超え、より豊富で強力な拡張機能を提供します。明確に定義されたシナリオに対応するために、5つの異なるプラグインタイプを用意しており、開発者はDifyアプリケーションを自由にカスタマイズし、強化することができます。\n\nさらに、プラグインシステムは共有しやすいように設計されています。Difyマーケットプレイス、GitHub、またはローカルファイルパッケージを通じてプラグインを配布できます。他の開発者は、これらのプラグインを迅速にインストールし、そのメリットを享受できます。\n\nDifyマーケットプレイスは、開発者向けのオープンなエコシステムであり、モデル、ツール、AIエージェント、拡張機能、プラグインバンドルなど、幅広いリソースを提供しています。マーケットプレイスを通じて、サードパーティのサービスを既存のDifyアプリケーションにシームレスに統合し、機能を強化し、Difyコミュニティ全体の発展に貢献できます。\n\n新しいモデルを統合したい場合も、Difyの既存機能を拡張するための専用ツールを追加したい場合も、Dify マーケットプレイスには必要なリソースが揃っています。より多くの開発者の皆様に参加していただき、Difyのエコシステムを共に発展させ、関係者全員に利益をもたらすことを願っています。\n\n​\nプラグインの種類\n\nモデル\n\nこれらのプラグインは、さまざまなAIモデル（主要なLLMプロバイダーやカスタムモデルを含む）を統合し、LLM APIの設定とリクエストを処理します。モデルプラグインの作成の詳細については、クイックスタート：モデルプラグインをご覧ください。\n\nツール\n\nツールとは、Chatflow、Workflow、Agentタイプのアプリケーションから呼び出すことができるサードパーティのサービスのことです。Difyアプリケーションの機能を拡張するためのAPI実装を提供します。たとえば、Google検索プラグインの開発については、クイックスタート：ツールプラグインをご参照ください。\n\nエージェント戦略\n\nエージェント戦略プラグインは、エージェントノード内の推論および意思決定ロジックを定義します。これには、ツール選択、呼び出し、および結果処理などが含まれます。\n\nエージェント戦略プラグインは、エージェントノード内部の推論および意思決定ロジックを定義します。これには、ツールの選択、実行、およびLLMから返された結果の処理ロジックが含まれます。詳細な開発ガイダンスについては、クイックスタート：エージェント戦略プラグインをご参照ください。\n\n拡張機能\n\nよりシンプルなシナリオのエンドポイント機能のみを提供する軽量プラグインで、HTTPサービスを介して迅速な拡張を可能にします。基本的なAPI呼び出しを必要とする簡単な統合に最適です。詳細については、クイックスタート：拡張機能プラグインをご参照ください。\n\nバンドル\n\n「プラグインバンドル」は、複数のプラグインをまとめたものです。バンドルを使用すると、厳選されたプラグインセットを一度にインストールできます。プラグインを1つずつ追加する手間が省けます。プラグインバンドルの作成の詳細については、プラグイン開発：バンドルプラグインをご覧ください。\n\n​\nプラグインの新機能\n\nLLMのマルチモーダル対応を拡張\n\nプラグインを使用すると、LLMがマルチモーダルデータを処理する能力を高めることができます。開発者は、画像編集や動画処理などのタスクを追加できます。トリミングや背景の削除から、ポートレート画像の処理まで、幅広い用途に対応できます。\n\n開発者フレンドリーなデバッグ機能\n\nプラグインシステムは、一般的なIDEとデバッグツールをサポートしています。いくつかの環境変数を設定するだけで、SaaSとして実行されているDifyインスタンスにリモートで接続できます。Difyでプラグインに対して実行した操作は、デバッグのためにローカルランタイムに転送されます。\n\n永続的なデータストレージ\n\nより複雑なユースケースに対応するために、プラグインシステムにはデータ永続性が組み込まれています。\n\nプラグインレベルのデータストレージ: ワークスペースレベルの情報をプラグインと共有して、より高度なカスタム機能を実現できます。\n組み込みのデータ管理: プラグインはデータを確実に保存および管理できるため、複雑なビジネスロジックを容易に実装できます。\n\n便利な双方向通信\n\nプラグインは、Difyのコア機能と双方向に対話できるようになりました。\n\nAIモデルの呼び出し\nツールの使用\nアプリケーションへのアクセス\nナレッジベースとの対話\n関数ノードの呼び出し（質問分類、パラメータ抽出など）\n\nこの双方向メカニズムにより、プラグインは既存のDify機能を活用するだけでなく、スタンドアロンのゲートウェイとしても機能し、アプリケーションのユースケースを拡大します。\n\n強化されたエンドポイントのカスタマイズ機能\n\n既存のDify API（ChatbotやWorkflow APIなど）に加えて、プラグイン内にカスタムAPIを作成できるようになりました。開発者はビジネスロジックをプラグインとしてラップし、Dify マーケットプレイスでホストすることで、データ処理とリクエスト処理のエンドポイントサポートを自動的に得られます。\n\n​\n詳しくはこちら\n\nクイックスタート\n\nプラグインをすばやくインストールして使用するには、以下を参照してください。\n\ninstall-plugins.md\n\ninstall-plugins.md\n\nプラグインの開発を開始するには、以下を参照してください。\n\ndevelop-plugins\n\ndevelop-plugins\n\nプラグインの公開\n\nプラグインをDify Marketplaceで公開するには、必要な情報と利用方法に関するドキュメントを記入してください。その後、プラグインのコードをGitHubリポジトリに提出してください。承認されると、マーケットプレイスに掲載されます。\n\npublish-to-dify-marketplace\n\npublish-to-dify-marketplace\n\n公式のDifyマーケットプレイスに加えて、個人のGitHubリポジトリでプラグインをホストしたり、ファイルとしてパッケージ化して直接共有することもできます。\n\npackage-plugin-file-and-publish.md\n\npackage-plugin-file-and-publish.md\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nドキュメントへの貢献\nQuick start\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nプラグインとは\nプラグインのメリット\nプラグインの種類\nプラグインの新機能\n詳しくはこちら",
        "error": null
      },
      {
        "link_index": 13,
        "link_text": "Quick start",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/quick-start",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nTermbase\nクイックスタート\nCopy page\n\n目的に応じて最適な学習パスを選択してください：\n\n​\nプラグインを使用したい場合\n\nプラグインのインストールと利用を優先する場合は、以下を参照してください：\n\nプラグインのインストールと利用方法.md\n\nプラグインのインストールと利用方法.md\n\n​\nプラグインを開発したい場合\n\nプラグイン開発を始める方向けのステップバイステップガイド：\n\n​\n1. クイックスタート\n\n主要プラグインタイプの開発例を通じて、基本構造と開発フローを習得：\n\nツールプラグイン.md\n\nツールプラグイン.md\n\nモデルプラグイン.md\n\nモデルプラグイン.md\n\nエージェント戦略プラグイン.md\n\nエージェント戦略プラグイン.md\n\n拡張機能型プラグイン.md\n\n拡張機能型プラグイン.md\n\nバンドルプラグイン.md\n\nバンドルプラグイン.md\n\n​\n2. アドバンスト開発\n\nエンドポイントドキュメントで、プラグイン開発の重要なインターフェースと実装詳細を理解：\n\nスキーマ仕様\n\nスキーマ仕様\n\n目的に応じて学習内容をカスタマイズし、効率的にスキル習得を目指しましょう。\n\n本セクションでは主にプラグインのインストールと基本的な利用方法を解説します。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nプラグインを使用したい場合\nプラグインを開発したい場合\n1. クイックスタート\n2. アドバンスト開発",
        "error": null
      },
      {
        "link_index": 14,
        "link_text": "プラグインのインストールと利用方法",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/quick-start/install-plugins",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nQuick start\nプラグインのインストールと利用方法\nプラグイン開発の入門\nプラグインのデバッグ方法\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nクイックスタート\nプラグインのインストールと利用方法\nCopy page\n\nAuthor: Allen\n\n​\nプラグインのインストール\n\nDifyプラットフォームの右上角にある 「プラグイン」 を選択し、現在のワークスペースでプラグインを管理するページにアクセスしてください。プラグインのインストール方法は以下の3つです：\n\nマーケットプレース\nGitHub\nローカルからのアップロード\n\n​\nマーケットプレース\n\nDifyのマーケットプレースでは、公式にサポートされているモデルやツール、さらにはコミュニティから提供されるプラグインが見つかります。プラグインの 「インストール」 ボタンを押すことで、手軽に現在のワークスペースに追加可能です。\n\n​\nGitHub\n\nGitHubのリポジトリリンクを使用して、直接プラグインをインストールすることもできます。この方法でインストールする際は、プラグインがコードの基準を満たしているか確認することが大切です。プラグインのリポジトリはリリースを作成し、プラグインのパッケージファイルを添付する必要があります。詳細は、プラグインの公開：GitHubをご覧ください。\n\n​\nローカルからのアップロード\n\nローカルファイルとは、.difypkg拡張子を持つファイルパッケージを指し、主にオフライン環境やテスト環境で利用されます。開発者はこの方法を用いて、公式マーケットプレースに公開されていないプラグインをインストール可能です。組織においては、内部プラグインを開発・保守し、ローカル環境から直接インストールできる点が利点です。これにより、機密情報を外部に公開することなく、セキュアに運用することが可能となります。\n\nプラグインのパッケージ化手順や.difypkgファイルの取得方法については、プラグインのパッケージ化ドキュメントで詳細をご確認いただけます。\n\n​\nプラグインの活用\n\nプラグインをワークスペースにインストールすると、Difyのアプリ内で使用できます。以下では、プラグインの種類ごとのさまざまな使用方法を簡単に紹介します。\n\n​\nモデルタイプのプラグイン\n\n例としてOpenAIの場合、モデルタイプのプラグインをインストールした後、右上のプロフィールアイコン → 設定 → モデルプロバイダーの順に進み、API Keyを入力してモデルプロバイダーを有効化します。\n\nこの認証を済ませることで、あらゆるアプリタイプでこの高性能な言語モデルを選択し、活用することが可能になります。\n\n​\nツールタイプのプラグイン\n\nツールプラグインは、チャットフロー、ワークフロー、エージェントの各アプリで利用可能です。このセクションでは、Googleのツールプラグインを例に取り、これらのアプリタイプでどのように使用するかを示します。\n\n注意：一部のツールプラグインはAPIキーによる認証が必要です。そのため、プラグインのインストール後には、引き続き使用するための設定を行う必要があります。\n\n​\nエージェント\n\nエージェントアプリを作成したら、アプリ編集ページの下部にある 「ツール」 オプションを見つけてください。そこから、インストール済みのツールプラグインを選択します。\n\nアプリを使用する際には、特定のコマンドを入力してツールを操作します。たとえば、「今日のニュース」と入力することで、Googleの検索エンジンを利用してオンラインで最新のニュース内容を検索できます。\n\n​\nチャットフロー / ワークフロー\n\nチャットフローやワークフローを組み立てるアプリケーションは、共通のワークフローを構築するためのキャンバスを共有しています。このため、どのツールプラグインも一貫した操作方法で使用できます。\n\nノードの末端に表示される「+」アイコンをクリックすると、インストール済みのGoogle関連プラグインツールを選択し、そのノードを別のノードに接続することが可能です。\n\nプラグインには、ユーザーからの問い合わせ内容を含むquery変数や、オンラインで検索が必要なその他の情報を入力します。\n\nその他のプラグインの使い方については、各プラグインの詳細ページにある説明をご覧ください。\n\n​\n詳細情報\n\nプラグインの開発に着手する方法については、以下のセクションをご参照ください：\n\nプラグイン開発\n\nプラグイン開発\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nQuick start\nDevelop plugins\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nプラグインのインストール\nマーケットプレース\nGitHub\nローカルからのアップロード\nプラグインの活用\nモデルタイプのプラグイン\nツールタイプのプラグイン\nエージェント\nチャットフロー / ワークフロー\n詳細情報",
        "error": null
      },
      {
        "link_index": 15,
        "link_text": "Develop plugins",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/quick-start/develop-plugins",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nTermbase\nプラグイン開発ガイド\nCopy page\n​\nはじめに\n\nこのガイドでは、ツール型プラグインやモデルプラグインなど、様々な種類のプラグインの開発方法を例を挙げて説明します。これにより、プラグイン開発における様々な機能の組み合わせを迅速に理解し、活用できるようになります。開発を始める前には、まず開発環境を用意し、必要なフレームワークをインストールして初期設定を行ってください。詳細は以下を参照してください：\n\ninitialize-development-tools.md\n\ninitialize-development-tools.md\n\nGoogleSearchツールを例に、ツール型プラグインの開発方法を紹介します。具体的な手順は以下をご覧ください：\n\ntool-plugin.md\n\ntool-plugin.md\n\nAnthropicやXinferenceモデルを例に、事前にトレーニングされたモデルプラグインとカスタムモデルプラグインの開発方法について説明します。\n\n事前にトレーニングされたモデルは、GPTやClaudeなどの商用モデルを指し、追加の訓練や設定なしで利用できます。\nカスタムモデルプラグインは、開発者が独自に訓練または設定したモデルを統合し、特定のニーズに合わせた機能を提供します。\n\n具体的な開発例は以下を参照してください：\n\nmodel\n\nmodel\n\nExtensionプラグインにより、開発者はビジネスロジックをプラグインとしてパッケージ化し、Difyプラットフォーム上でAPIサービスとして公開できます。詳細は以下をご覧ください：\n\nextension-plugin.md\n\nextension-plugin.md\n\n​\nインターフェースドキュメント\n\nプラグインの詳細なインターフェース仕様が必要な場合は、以下の標準仕様書を参照してください：\n\n一般的な構造の標準定義\nマニフェストの標準定義\nツールとの接続の標準定義\nモデルとの接続の標準定義\nエンドポイントの標準定義\n拡張エージェント策略\nDifyサービスの逆呼び出し機能\nアプリの逆呼び出し\nモデルの逆呼び出し\nノードの逆呼び出し\nツールの逆呼び出し\nプラグインの永続化されたストレージ機能\n​\n貢献ガイド\n\nDifyプラグインにコードや機能を提供し、公式プラグインに貢献したいとお考えですか？開発者がプラグインの開発と貢献のプロセスをスムーズに理解し、参加できるように、詳細なガイドを用意しています：\n\nマーケットプレイスの公開ガイド\n\nあなたのプラグインを Dify Marketplace に公開し、多くの開発者と成果を共有する方法についてご案内します。\n\nGitHub での公開ガイド\n\nGitHub でプラグインを公開・管理する方法を学び、プラグインの継続的な最適化とコミュニティとの協力を促進します。\n\n貢献者の参加を歓迎し、世界中の開発者とともにDifyエコシステムを充実させていきましょう！\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nはじめに\nインターフェースドキュメント\n貢献ガイド",
        "error": null
      },
      {
        "link_index": 16,
        "link_text": "開発環境のセットアップ",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/quick-start/develop-plugins/initialize-development-tools",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nQuick start\nプラグインのインストールと利用方法\nプラグイン開発の入門\nDevelop plugins\n開発環境のセットアップ\nツールプラグイン\nモデル型プラグイン\nエージェント戦略プラグイン\n拡張機能型プラグイン\nバンドル\nプラグインのデバッグ方法\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nプラグイン開発の入門\n開発環境のセットアップ\nCopy page\n\nDifyプラグインを開発する前に、次の準備を整えましょう。\n\nDifyプラグイン用のスキャフォールディングツール\nバージョン3.12以上のPython環境\n​\n1. Difyプラグインスキャフォールディングツールのインストール方法\n\nDify プラグイン開発スキャフォールディングツール、別名 dify-plugin-daemon は、プラグイン開発 SDK として見なすことができます。\n\nDifyプラグインのGitHubページ へアクセスし、ご利用のオペレーティングシステムに適したバージョンをダウンロードしてください。\n\nMシリーズチップ搭載のmacOS向けのダウンロード例：プロジェクトページからdify-plugin-darwin-arm64をダウンロードし、ターミナルを開いてファイルのあるディレクトリに移動した後、以下のコマンドで実行権限を付与します：\n\nCopy\nchmod +x dify-plugin-darwin-arm64\n\n\nインストールが成功したかどうかを確認するには、次のコマンドを実行します。\n\nCopy\n./dify-plugin-darwin-arm64 version\n\n\nシステムが「Appleによって検証されていません」と警告を出す場合は、設定 → セキュリティとプライバシー → セキュリティボタンを開き、「とにかく開く」を選択してください。\n\nコマンドを実行し、v0.0.1-beta.15などのバージョン情報が表示されれば、インストール完了です。\n\nTips:\n\ndifyコマンドをシステム全体で利用したい場合は、ダウンロードしたバイナリファイルの名前をdifyに変更し、/usr/local/binにコピーすることをお勧めします。\n\nこの設定を行うと、ターミナルからdify versionと入力するだけで、インストールされたバージョンを確認できます。\n\n​\n2. Initialize Python Environment\n\nFor detailed instructions, please refer to the Python installation tutorial, or ask the LLM for complete installation instructions.\n\n​\n2. Python環境の設定\n\nPythonのインストール方法については、Pythonインストールチュートリアルを参照するか、LLMに詳細な手順を尋ねてみてください。\n\n​\n3. プラグインの開発について\n\nさまざまなタイプのプラグイン開発の具体例については、以下のリンクをご参照ください。\n\ntool-plugin.md\n\ntool-plugin.md\n\nmodel-plugin\n\nmodel-plugin\n\nagent-strategy-plugin.md\n\nagent-strategy-plugin.md\n\nextension.md\n\nextension.md\n\nbundle.md\n\nbundle.md\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nDevelop plugins\nツールプラグイン\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\n1. Difyプラグインスキャフォールディングツールのインストール方法\n2. Initialize Python Environment\n2. Python環境の設定\n3. プラグインの開発について",
        "error": null
      },
      {
        "link_index": 17,
        "link_text": "ツールプラグイン",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/quick-start/develop-plugins/tool-plugin",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nQuick start\nプラグインのインストールと利用方法\nプラグイン開発の入門\nDevelop plugins\n開発環境のセットアップ\nツールプラグイン\nモデル型プラグイン\nエージェント戦略プラグイン\n拡張機能型プラグイン\nバンドル\nプラグインのデバッグ方法\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nプラグイン開発の入門\nツールプラグイン\nCopy page\n\nTool（ツール）プラグインは、チャットフロー、ワークフロー、エージェントといったアプリタイプから参照できる外部ツールであり、Difyアプリの機能を拡張するために使用されます。例えば、アプリにオンライン検索機能や画像生成機能を追加するといったことが可能です。ツールプラグインは、包括的なツールセットとAPI実装機能を提供します。\n\n本篇では、「ツールプラグイン」とは、ツールプロバイダーファイル、機能コード、およびその他の関連コンポーネントを含む、一揃いのプロジェクトを指します。ツールプロバイダーは複数のツール（これは、単一のツールが提供する追加機能と解釈できます）を含むことがあり、以下の構造で構成されます。\n\nCopy\n- ツールプロバイダー\n    - Tool A\n    - Tool B\n\n\nこの記事では、GoogleSearchを例に、ツールプラグインを迅速に開発する方法をご紹介します。\n\n​\n事前準備\nDify プラグインの Scaffolding（スキャフォールディング）ツール\nPython 環境 (バージョン 3.12 以上)\n\nプラグイン開発用のScaffoldingツールの準備方法については、初期化開発ツールをご参照ください。\n\n​\n新規プロジェクトの作成\n\nScaffoldingのコマンドラインツールを実行し、新しいDifyプラグインプロジェクトを作成します。\n\nCopy\n./dify-plugin-darwin-arm64 plugin init\n\n\nバイナリファイルの名前を dify に変更し、/usr/local/bin ディレクトリにコピーした場合は、次のコマンドを実行して新しいプラグインプロジェクトを作成できます。\n\nCopy\ndify plugin init\n\n\n以下、コマンドラインツール dify を使用します。もし問題が発生した場合は、dify コマンドを、お使いのツールの実行パスに置き換えてください。\n\n​\nプラグインの種類とテンプレートの選択\n\nプラグインには、ツール、モデル、そしてエクステンションの3種類があります。SDK内のすべてのテンプレートには、完全なコードプロジェクトが付属しています。以下の部分では、ツールプラグインテンプレートを例として使用します。\n\nプラグイン開発に精通されている方は、各種プラグインの実装にあたり、スキーマ仕様をご参照ください。\n\n​\nプラグイン権限の設定\n\nプラグインを正常に接続するには、Difyプラットフォームの権限を読み取る必要があります。このサンプルツールプラグインには、以下の権限を付与する必要があります。\n\nツール\nアプリ\n永続的ストレージジストレージの有効化、デフォルトサイズのストレージの割り当て\nエンドポイントの登録許可\n\nターミナルで方向キーを使って権限を選択し、“タグ”のブタンで権限を付与してください。\n\nすべての権限項目にチェックを入れたら、Enterキーを押してプラグインの作成を完了させてください。システムが自動的にプラグインプロジェクトのコードを生成します。\n\n​\n開発ツールプラグイン\n​\n1. ツールプロバイダーの yaml ファイルを作成する\n\nツールプロバイダーファイルは、ツールプラグインの基本的な設定ファイルとして機能し、ツールが利用するために必要な認証情報を提供します。このセクションでは、この yaml ファイルの記述方法について説明します。\n\n/provider ディレクトリに移動し、その中にある yaml ファイルの名前を google.yaml に変更します。この yaml ファイルには、プロバイダー名、アイコン、作成者など、ツールプロバイダーに関する情報が含まれます。これらの情報は、プラグインのインストール時に表示されます。\n\nサンプルコード\n\nCopy\nidentity: # ツールプロバイダーの基本情報\n  author: Your-name # 作成者\n  name: google # 名前。一意である必要があり、他のプロバイダーと重複できません\n  label: # ラベル。フロントエンドでの表示に使用\n    en_US: Google # 英語ラベル\n    zh_Hans: Google # 中国語ラベル\n    ja_JP: Google # 日本語ラベル\n    pt_BR: Google # プルトガル語ラベル\n  description: # 説明。フロントエンドでの表示に使用\n    en_US: Google # 英語説明\n    zh_Hans: Google # 中国語説明\n    ja_JP: : Google # 日本語説明\n    pt_BR: : Google # プルトガル語説明\n  icon: icon.svg # アイコン。_assets フォルダに配置する必要があります\n  tags: # タグ。フロントエンドでの表示に使用\n    - search\n\nidentity には、作成者、名前、ラベル、説明、アイコンなど、ツールプロバイダーの基本的な情報が含まれます。\nアイコンは添付ファイルとして扱い、プロジェクトのルートディレクトリにある _assets フォルダに配置する必要があります。\nタグは、ユーザーがプラグインをカテゴリ別にすばやく検索するのに役立ちます。現在サポートされているすべてのタグは以下のとおりです。\nCopy\nclass ToolLabelEnum(Enum):\n  SEARCH = 'search'\n  IMAGE = 'image'\n  VIDEOS = 'videos'\n  WEATHER = 'weather'\n  FINANCE = 'finance'\n  DESIGN = 'design'\n  TRAVEL = 'travel'\n  SOCIAL = 'social'\n  NEWS = 'news'\n  MEDICAL = 'medical'\n  PRODUCTIVITY = 'productivity'\n  EDUCATION = 'education'\n  BUSINESS = 'business'\n  ENTERTAINMENT = 'entertainment'\n  UTILITIES = 'utilities'\n  OTHER = 'other'\n\n\nファイルパスが /tools ディレクトリにあることを確認してください。完全なパスは次のようになります。\n\nCopy\nplugins:\n  tools:\n    - \"google.yaml\"\n\n\nここで、google.yaml ファイルのパスは、プラグインプロジェクト内の絶対パスで指定する必要があります。\n\nサードパーティサービスの認証情報を設定する\n\n開発を容易にするため、サードパーティサービスである SerpApi が提供する Google Search API を利用することにしました。SerpApi を使用するには API キーが必要となるため、yaml ファイルに credentials_for_provider フィールドを追加する必要があります。\n\n完全なコードは次のとおりです。\n\nCopy\nidentity:\n  author: Dify\n  name: google\n  label:\n    en_US: Google\n    zh_Hans: Google\n    ja_JP: Google\n    pt_BR: Google\n  description:\n    en_US: Google\n    zh_Hans: GoogleSearch\n    ja_JP: Google\n    pt_BR: Google\n  icon: icon.svg\n  tags:\n    - search\ncredentials_for_provider: # credentials_for_provider フィールドを追加\n  serpapi_api_key:\n    type: secret-input\n    required: true\n    label:\n      en_US: SerpApi API key\n      zh_Hans: SerpApi API key\n      ja_JP: SerpApi API key\n      pt_BR: chave de API SerpApi\n    placeholder:\n      en_US: Please input your SerpApi API key\n      zh_Hans: 请输入你的 SerpApi API key\n      ja_JP: SerpApi API keyを入力してください\n      pt_BR: Por favor, insira sua chave de API SerpApi\n    help:\n      en_US: Get your SerpApi API key from SerpApi\n      zh_Hans: 从 SerpApi 获取您的 SerpApi API key\n      ja_JP: SerpApiからSerpApi APIキーを取得する\n      pt_BR: Obtenha sua chave de API SerpApi da SerpApi\n    url: https://serpapi.com/manage-api-key\ntools:\n  - tools/google_search.yaml\nextra:\n  python:\n    source: google.py\n\ncredentials_for_provider の子構造は、ProviderConfig の仕様に準拠する必要があります。\nこのプロバイダーに含まれるツールを指定する必要があります。この例では、tools/google_search.yaml ファイルが 1 つだけ含まれています。\nプロバイダーは、基本情報を定義するだけでなく、コードによるロジックの実装も必要です。そのため、実装ロジックを指定する必要があります。この例では、機能のコードファイルは google.py に配置されていますが、ここではまだ実装せず、先に google_search のコードを作成します。これは、google_search の機能が google.py の実装に依存するためです。\n​\n2. ツールの YAML ファイルへの入力\n\n1つのツールベンダーが複数のツールを提供することがあります。各ツールは、その基本的な情報、パラメータ、出力などを記述した yaml ファイルによって定義される必要があります。\n\nここでは、GoogleSearch ツールを例にとり、/tools フォルダに新しい google_search.yaml ファイルを作成する手順を見ていきましょう。\n\nCopy\nidentity:\n  name: google_search\n  author: Dify\n  label:\n    en_US: GoogleSearch\n    zh_Hans: 谷歌搜索\n    ja_JP: Google検索\n    pt_BR: Pesquisa Google\ndescription:\n  human:\n    en_US: A tool for performing a Google SERP search and extracting snippets and webpages.Input should be a search query.\n    zh_Hans: 一个用于执行 Google SERP 搜索并提取片段和网页的工具。输入应该是一个搜索查询。\n    ja_JP: Google SERP 検索を実行し、スニペットと Web ページを抽出するためのツール。入力は検索クエリである必要があります。\n    pt_BR: Uma ferramenta para realizar pesquisas no Google SERP e extrair snippets e páginas da web. A entrada deve ser uma consulta de pesquisa.\n  llm: A tool for performing a Google SERP search and extracting snippets and webpages.Input should be a search query.\nparameters:\n  - name: query\n    type: string\n    required: true\n    label:\n      en_US: Query string\n      zh_Hans: 查询字符串\n      ja_JP: クエリ文字列\n      pt_BR: Cadeia de consulta\n    human_description:\n      en_US: used for searching\n      zh_Hans: 用于搜索网页内容\n      ja_JP: ネットの検索に使用する\n      pt_BR: usado para pesquisar\n    llm_description: key words for searching\n    form: llm\nextra:\n  python:\n    source: tools/google_search.py\n\nidentity: ツールの名前、作成者、ラベル、説明といった基本的な情報が含まれます。\nparameters: パラメータに関する設定項目です。各項目の詳細は以下の通りです。\nname (必須): パラメータ名。一意である必要があり、他のパラメータ名との重複は許容されません。\ntype (必須): パラメータの型。string (文字列)、number (数値)、boolean (真偽値)、select (選択式ドロップダウン)、secret-input (暗号化入力フィールド)、file (ファイル)、files (ファイルセット)、model-selector (モデル選択)、app-selector (アプリケーション選択) の9種類がサポートされています。機密性の高い情報を取り扱う場合は、必ず secret-input 型を使用してください。\nlabel (必須): パラメータのラベル。フロントエンドに表示される際に用いられます。\nform (必須): フォームの種類。llm と form の2種類がサポートされています。\nAgentアプリケーションにおいて、llm はパラメータがLLMによって推論されることを意味し、form はツールを使用する前にユーザーが設定できるパラメータを意味します。\nワークフローアプリケーションにおいては、llm と form の両方のパラメータに対してフロントエンドでの入力が求められます。ただし、llm パラメータはツールノードの入力変数として機能します。\nrequired: 必須項目であるかどうかを示すフラグです。\nllm モードの場合、required が true に設定されたパラメータは、Agentが推論によって値を決定する必要があります。\nform モードの場合、required が true に設定されたパラメータは、ユーザーが会話を開始する前にフロントエンドで値を入力する必要があります。\noptions: パラメータの選択肢。\nllm モードでは、Dify はすべての選択肢をLLMに渡し、LLM はこれらの選択肢に基づいて推論を行います。\nform モードでは、type が select に設定されている場合、フロントエンドにこれらの選択肢が表示されます。\ndefault: デフォルト値。\nmin: 最小値。パラメータの型が number の場合に設定可能です。\nmax: 最大値。パラメータの型が number の場合に設定可能です。\nhuman_description: フロントエンドに表示されるパラメータの説明文です。多言語に対応しています。\nplaceholder: 入力フィールドに表示されるプレースホルダーテキストです。form 形式で、パラメータの型が string、number、secret-input の場合に設定できます。多言語に対応しています。\nllm_description: LLMに渡されるパラメータの説明文です。LLMがパラメータの内容をより深く理解できるよう、できる限り詳細な情報を提供してください。\n​\n3. ツールコードの準備\n\nツールの設定情報を入力したら、ツールの機能コードを記述し、ツールのロジックを実装します。 /tools ディレクトリに google_search.py を作成し、以下の内容を記述します。\n\nCopy\nfrom collections.abc import Generator\nfrom typing import Any\n\nimport requests\n\nfrom dify_plugin import Tool\nfrom dify_plugin.entities.tool import ToolInvokeMessage\n\nSERP_API_URL = \"https://serpapi.com/search\"\n\nclass GoogleSearchTool(Tool):\n    def _parse_response(self, response: dict) -> dict:\n        result = {}\n        if \"knowledge_graph\" in response:\n            result[\"title\"] = response[\"knowledge_graph\"].get(\"title\", \"\")\n            result[\"description\"] = response[\"knowledge_graph\"].get(\"description\", \"\")\n        if \"organic_results\" in response:\n            result[\"organic_results\"] = [\n                {\n                    \"title\": item.get(\"title\", \"\"),\n                    \"link\": item.get(\"link\", \"\"),\n                    \"snippet\": item.get(\"snippet\", \"\"),\n                }\n                for item in response[\"organic_results\"]\n            ]\n        return result\n\n    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage]:\n        params = {\n            \"api_key\": self.runtime.credentials[\"serpapi_api_key\"],\n            \"q\": tool_parameters[\"query\"],\n            \"engine\": \"google\",\n            \"google_domain\": \"google.com\",\n            \"gl\": \"us\",\n            \"hl\": \"en\",\n        }\n\n        response = requests.get(url=SERP_API_URL, params=params, timeout=5)\n        response.raise_for_status()\n        valuable_res = self._parse_response(response.json())\n        \n        yield self.create_json_message(valuable_res)\n\n\nこの例では、serpapi にリクエストを送信し、self.create_json_message を使用して json 形式のデータを返しています。その他の戻り値の型については、ツールインターフェースドキュメントを参照してください。\n\n​\n4. ツールプロバイダーコードの作成\n\n最後に、プロバイダーのコードを実装します。これは、プロバイダーの認証情報を検証するために使用されます。認証情報の検証に失敗すると、ToolProviderCredentialValidationError 例外が発生します。検証に成功すると、google_search ツールサービスが正常にリクエストされます。\n\n/provider ディレクトリに google.py ファイルを作成し、以下のコードを記述します。\n\nCopy\nfrom typing import Any\n\nfrom dify_plugin import ToolProvider\nfrom dify_plugin.errors.tool import ToolProviderCredentialValidationError\nfrom tools.google_search import GoogleSearchTool\n\nclass GoogleProvider(ToolProvider):\n    def _validate_credentials(self, credentials: dict[str, Any]) -> None:\n        try:\n            for _ in GoogleSearchTool.from_credentials(credentials).invoke(\n                tool_parameters={\"query\": \"test\", \"result_type\": \"link\"},\n            ):\n                pass\n        except Exception as e:\n            raise ToolProviderCredentialValidationError(str(e))\n\n​\nプラグインのデバッグ\n\nプラグインが正常に動作するかテストします。Dify はリモートデバッグをサポートしています。「プラグイン管理」ページで、デバッグキーとリモートサーバーアドレスを取得してください。\n\nプラグインプロジェクトに戻り、.env.example ファイルをコピーして .env にリネームし、取得したリモートサーバーアドレスとデバッグキーを入力します。\n\n.env ファイル\n\nCopy\nINSTALL_METHOD=remote\nREMOTE_INSTALL_HOST=remote\nREMOTE_INSTALL_PORT=5003\nREMOTE_INSTALL_KEY=****-****-****-****-****\n\n\npython -m main コマンドを実行してプラグインを起動します。プラグインページで、プラグインがワークスペースにインストールされていることを確認できます。これで、他のチームメンバーもこのプラグインを使用できます。\n\n​\nプラグインのパッケージ化\n\nプラグインが正常に動作することを確認したら、以下のコマンドラインツールを使用してプラグインをパッケージ化し、名前を付けます。実行後、現在のフォルダに google.difypkg ファイルが作成されます。これがプラグインの最終的なパッケージです。\n\nCopy\n# Replace ./google with your actual plugin project path.\n\ndify plugin package ./google\n\n\nおめでとうございます。これで、ツールタイプのプラグインの開発、デバッグ、パッケージ化の全プロセスが完了しました。\n\n​\nプラグインの公開\n\nDify Plugins コードリポジトリにアップロードして、プラグインを公開しましょう。アップロードする前に、プラグインがプラグイン公開仕様に準拠していることを確認してください。レビューに合格すると、コードはメインブランチにマージされ、Dify Marketplace に自動的に公開されます。\n\n​\nさらに詳しく\n\nクイックスタート:\n\n拡張タイププラグインの開発\nモデルタイププラグインの開発\nバンドルタイププラグイン：複数のプラグインをパッケージ化\n\nプラグインインターフェースドキュメント:\n\nマニフェスト 構造\nエンドポイント 詳細定義\nDifyサービスの逆呼び出し\nツール\nモデル\n拡張エージェント戦略\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\n開発環境のセットアップ\nModel plugin\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\n事前準備\n新規プロジェクトの作成\nプラグインの種類とテンプレートの選択\nプラグイン権限の設定\n開発ツールプラグイン\n1. ツールプロバイダーの yaml ファイルを作成する\n2. ツールの YAML ファイルへの入力\n3. ツールコードの準備\n4. ツールプロバイダーコードの作成\nプラグインのデバッグ\nプラグインのパッケージ化\nプラグインの公開\nさらに詳しく",
        "error": null
      },
      {
        "link_index": 18,
        "link_text": "Model plugin",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/quick-start/develop-plugins/model-plugin",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nTermbase\nモデルプラグイン\nCopy page\n\nモデルタイププラグインを導入することで、Difyプラットフォームは特定のモデルプロバイダーが提供するモデルを利用できるようになります。例えば、OpenAIモデルプラグインをインストールすると、DifyプラットフォームからOpenAIのGPT-4やGPT-4o-2024-05-13といったモデルをリクエストできるようになります。\n\n​\nモデルプラグインの構造\n\nプラグインモデルの開発に関する理解を深めるために、モデルタイププラグインの構造例を以下に示します。\n\nモデルプロバイダー：OpenAI、Anthropic、Googleなどの大規模モデル開発企業です。\nモデルカテゴリ：プロバイダーに応じて、大規模言語モデル（LLM）、テキスト埋め込みモデル、音声テキスト変換モデルなどがあります。\n具体的なモデル：claude-3-5-sonnet、gpt-4-turboなど。\n\nプラグインプロジェクトのコード構造：\n\nCopy\n- モデルプロバイダー\n  - モデルカテゴリ\n    - 具体的なモデル\n\n\nAnthropicを例にとると、モデルプラグインの構造は次のようになります。\n\nCopy\n- Anthropic\n  - llm\n    claude-3-5-sonnet-20240620\n    claude-3-haiku-20240307\n    claude-3-opus-20240229\n    claude-3-sonnet-20240229\n    claude-instant-1.2\n    claude-instant-1\n\n\nOpenAIを例にとると、複数のモデルタイプをサポートしています。\n\nCopy\n├── models\n│ ├── llm\n│ │ ├── chatgpt-4o-latest\n│ │ ├── gpt-3.5-turbo\n│ │ ├── gpt-4-0125-preview\n│ │ ├── gpt-4-turbo\n│ │ ├── gpt-4o\n│ │ ├── llm\n│ │ ├── o1-preview\n│ │ └── text-davinci-003\n│ ├── moderation\n│ │ ├── moderation\n│ │ └── text-moderation-stable\n│ ├── speech2text\n│ │ ├── speech2text\n│ │ └── whisper-1\n│ ├── text_embedding\n│ │ ├── text-embedding-3-large\n│ │ └── text_embedding\n│ └── tts\n│ ├── tts-1-hd\n│ ├── tts-1\n│ └── tts\n\n​\nモデルプラグイン作成の準備\n\nモデルプラグインを作成するには、以下の手順に従ってください。具体的な作成ガイドは、各ドキュメントのタイトルをクリックして参照してください。\n\nモデルプロバイダーの作成\n事前定義済みモデル、またはカスタムモデルの統合\nモデルプラグインのデバッグ\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nモデルプラグインの構造\nモデルプラグイン作成の準備",
        "error": null
      },
      {
        "link_index": 19,
        "link_text": "モデルプロバイダーの構築",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/quick-start/develop-plugins/model-plugin/create-model-providers",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nQuick start\nプラグインのインストールと利用方法\nプラグイン開発の入門\nDevelop plugins\n開発環境のセットアップ\nツールプラグイン\nモデル型プラグイン\nModel plugin\nモデルプロバイダーの構築\n定義済みモデルの組み込み\nカスタムモデルの組み込み\nエージェント戦略プラグイン\n拡張機能型プラグイン\nバンドル\nプラグインのデバッグ方法\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nモデル型プラグイン\nモデルプロバイダーの構築\nCopy page\n\nModelタイプのプラグインを作成する最初のステップは、プラグインプロジェクトを初期化し、モデルプロバイダーファイルを作成することです。その後、具体的な定義済みモデルやカスタムモデルを接続します。\n\n​\n事前準備 \nDifyプラグインのスキャフォールディングツール\nPython環境（バージョン3.12以上）\n\nプラグイン開発用のスキャフォールディングツールの準備方法については、開発ツールの初期化を参照してください。\n\n​\n新規プロジェクトの作成 \n\nスキャフォールディングツールのコマンドラインから、新しいDifyプラグインプロジェクトを作成します。\n\nCopy\n./dify-plugin-darwin-arm64 plugin init\n\n\nこのバイナリファイルをdifyにリネームし、/usr/local/binにコピーした場合は、次のコマンドで新しいプラグインプロジェクトを作成できます。\n\nCopy\ndify plugin init\n\n​\nモデルプラグインテンプレートの選択 \n\nスキャフォールディングツール内のすべてのテンプレートには、必要なコードが全て含まれています。LLMタイプのプラグインテンプレートを選択してください。\n\n​\nプラグイン権限の設定\n\nこのLLMプラグインには、次の権限を設定します。\n\nModels\nLLM\nStorage\n\n​\nモデルタイプ設定の説明\n\nモデルプロバイダーは、以下の2つのモデル設定方法をサポートしています。\n\npredefined-model 定義済みモデル\n\n一般的な大規模モデルタイプで、統一されたプロバイダー認証情報を設定するだけで、モデルプロバイダーが提供する定義済みモデルを利用できます。たとえば、OpenAIモデルプロバイダーは、gpt-3.5-turbo-0125やgpt-4o-2024-05-13など、様々な定義済みモデルを提供しています。詳細な開発手順については、定義済みモデルの接続を参照してください。\n\ncustomizable-model カスタムモデル\n\n各モデルの認証情報設定を手動で追加する必要があります。たとえば、XinferenceはLLMとText Embeddingの両方をサポートしていますが、各モデルには一意のmodel_uidがあります。両方を同時に接続する場合は、各モデルにmodel_uidを設定する必要があります。詳細な開発手順については、カスタムモデルの接続を参照してください。\n\nこれら2つの設定方法は共存可能です。つまり、プロバイダーがpredefined-modelとcustomizable-modelの両方、またはpredefined-modelのみをサポートしている場合、プロバイダーの統一認証情報を設定することで、定義済みモデルとリモートから取得したモデルを使用できます。さらに、新しいモデルを追加した場合は、それに基づいてカスタムモデルを使用することも可能です。\n\n​\n新しいモデルプロバイダーの追加\n\n新しいモデルプロバイダーを追加するには、主に次の手順が必要です。\n\nモデルプロバイダー設定YAMLファイルの作成\n\nプロバイダーディレクトリにYAMLファイルを追加し、プロバイダーの基本情報とパラメータ設定を記述します。ProviderSchemaの要件に従って記述し、システムの仕様との整合性を確保してください。\n\nモデルプロバイダーコードの記述\n\nプロバイダークラスのコードを作成します。システムのインターフェース要件に準拠したPythonクラスを実装して、プロバイダーのAPIに接続し、コア機能を実装します。\n\n以下は、各ステップの詳細な操作手順です。\n\n​\n1. モデルプロバイダー設定ファイルの作成\n\nManifestはYAML形式のファイルで、モデルプロバイダーの基本情報、サポートされているモデルタイプ、設定方法、認証情報ルールを定義します。プラグインプロジェクトのテンプレートには、/providersパスに設定ファイルが自動的に生成されます。\n\n以下は、Anthropicモデルの設定ファイルanthropic.yamlのサンプルコードです。\n\nCopy\nprovider: anthropic\nlabel:\n  en_US: Anthropic\ndescription:\n  en_US: Anthropic's powerful models, such as Claude 3.\n  zh_Hans: Anthropicの強力なモデル（例：Claude 3）。\nicon_small:\n  en_US: icon_s_en.svg\nicon_large:\n  en_US: icon_l_en.svg\nbackground: \"#F0F0EB\"\nhelp:\n  title:\n    en_US: Get your API Key from Anthropic\n    zh_Hans: AnthropicからAPIキーを取得\n  url:\n    en_US: https://console.anthropic.com/account/keys\nsupported_model_types:\n  - llm\nconfigurate_methods:\n  - predefined-model\nprovider_credential_schema:\n  credential_form_schemas:\n    - variable: anthropic_api_key\n      label:\n        en_US: API Key\n      type: secret-input\n      required: true\n      placeholder:\n        zh_Hans: APIキーを入力してください\n        en_US: Enter your API Key\n    - variable: anthropic_api_url\n      label:\n        en_US: API URL\n      type: text-input\n      required: false\n      placeholder:\n        zh_Hans: API URLを入力してください\n        en_US: Enter your API URL\nmodels:\n  llm:\n    predefined:\n      - \"models/llm/*.yaml\"\n    position: \"models/llm/_position.yaml\"\nextra:\n  python:\n    provider_source: provider/anthropic.py\n    model_sources:\n      - \"models/llm/llm.py\"\n\n\n接続するプロバイダーがカスタムモデル（たとえば、OpenAIがファインチューニングモデルを提供する場合）を提供する場合は、model_credential_schemaフィールドを追加する必要があります。\n\n以下は、OpenAIファミリーモデルのサンプルコードです。\n\nCopy\nmodel_credential_schema:\n  model: # ファインチューニングモデル名\n    label:\n      en_US: Model Name\n      zh_Hans: モデル名\n    placeholder:\n      en_US: Enter your model name\n      zh_Hans: モデル名を入力\n  credential_form_schemas:\n  - variable: openai_api_key\n    label:\n      en_US: API Key\n    type: secret-input\n    required: true\n    placeholder:\n      zh_Hans: APIキーを入力してください\n      en_US: Enter your API Key\n  - variable: openai_organization\n    label:\n        zh_Hans: 組織ID\n        en_US: Organization\n    type: text-input\n    required: false\n    placeholder:\n      zh_Hans: 組織IDを入力してください\n      en_US: Enter your Organization ID\n  - variable: openai_api_base\n    label:\n      zh_Hans: API Base\n      en_US: API Base\n    type: text-input\n    required: false\n    placeholder:\n      zh_Hans: API Baseを入力してください\n      en_US: Enter your API Base\n\n\nより詳細なモデルプロバイダーYAMLの仕様については、モデルインターフェースドキュメントを参照してください。\n\n​\n2. モデルプロバイダーコードの記述\n\n/providersフォルダに、同じ名前のPythonファイル（たとえば、anthropic.py）を作成し、__base.provider.Provider基本クラス（たとえば、AnthropicProvider）を継承するclassを実装します。\n\n以下は、Anthropicのサンプルコードです。\n\nCopy\nimport logging\nfrom dify_plugin.entities.model import ModelType\nfrom dify_plugin.errors.model import CredentialsValidateFailedError\nfrom dify_plugin import ModelProvider\n\nlogger = logging.getLogger(__name__)\n\n\nclass AnthropicProvider(ModelProvider):\n    def validate_provider_credentials(self, credentials: dict) -> None:\n        \"\"\"\n        Validate provider credentials\n\n        if validate failed, raise exception\n\n        :param credentials: provider credentials, credentials form defined in `provider_credential_schema`.\n        \"\"\"\n        try:\n            model_instance = self.get_model_instance(ModelType.LLM)\n            model_instance.validate_credentials(model=\"claude-3-opus-20240229\", credentials=credentials)\n        except CredentialsValidateFailedError as ex:\n            raise ex\n        except Exception as ex:\n            logger.exception(f\"{self.get_provider_schema().provider} credentials validate failed\")\n            raise ex\n\n\nプロバイダーは、__base.model_provider.ModelProvider基底クラスを継承し、validate_provider_credentialsプロバイダー統一認証情報検証メソッドを実装する必要があります。\n\nCopy\ndef validate_provider_credentials(self, credentials: dict) -> None:\n    \"\"\"\n    Validate provider credentials\n    You can choose any validate_credentials method of model type or implement validate method by yourself,\n    such as: get model list api\n\n    if validate failed, raise exception\n\n    :param credentials: provider credentials, credentials form defined in `provider_credential_schema`.\n    \"\"\"\n\n\nもちろん、validate_provider_credentialsの実装を後回しにして、モデル認証情報検証メソッドの実装後に直接再利用することもできます。\n\n​\nカスタムモデルプロバイダー\n\n他のタイプのモデルプロバイダーについては、以下の設定方法を参照してください。\n\nXinferenceのようなカスタムモデルプロバイダーの場合、完全な実装手順を省略できます。XinferenceProviderという名前の空のクラスを作成し、その中に空のvalidate_provider_credentialsメソッドを実装するだけで済みます。\n\n詳細説明：\n\nXinferenceProviderは、カスタムモデルプロバイダーを識別するためのプレースホルダーとして機能します。\nvalidate_provider_credentialsメソッドは実際には呼び出されませんが、親クラスが抽象クラスであるため、すべてのサブクラスがこのメソッドを実装する必要があります。空の実装を提供することで、抽象メソッドが実装されていないことによるインスタンス化エラーを回避できます。\nCopy\nclass XinferenceProvider(Provider):\n    def validate_provider_credentials(self, credentials: dict) -> None:\n        pass\n\n\nモデルプロバイダーを初期化した後、プロバイダーが提供する具体的なLLMモデルを接続する必要があります。詳細については、以下を参照してください。\n\n定義済みモデルの接続\nカスタムモデルの接続\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nModel plugin\n定義済みモデルの組み込み\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\n事前準備\n新規プロジェクトの作成\nモデルプラグインテンプレートの選択\nプラグイン権限の設定\nモデルタイプ設定の説明\n新しいモデルプロバイダーの追加\n1. モデルプロバイダー設定ファイルの作成\n2. モデルプロバイダーコードの記述\nカスタムモデルプロバイダー",
        "error": null
      },
      {
        "link_index": 20,
        "link_text": "定義済みモデルの組み込み",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/quick-start/develop-plugins/model-plugin/integrate-the-predefined-model",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nQuick start\nプラグインのインストールと利用方法\nプラグイン開発の入門\nDevelop plugins\n開発環境のセットアップ\nツールプラグイン\nモデル型プラグイン\nModel plugin\nモデルプロバイダーの構築\n定義済みモデルの組み込み\nカスタムモデルの組み込み\nエージェント戦略プラグイン\n拡張機能型プラグイン\nバンドル\nプラグインのデバッグ方法\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nモデル型プラグイン\n定義済みモデルの組み込み\nCopy page\n\nモデルプロバイダーの作成が完了していることを確認してください。事前定義済みモデルを組み込むには、以下の手順に従います。\n\nモデルタイプに応じたモジュール構造の作成\n\nモデルのタイプ（llmやtext_embeddingなど）に応じて、プロバイダーモジュール内に対応するサブモジュールを作成します。各モデルタイプが独立した論理構造を持つようにすることで、保守性と拡張性を高めます。\n\nモデル呼び出しコードの記述\n\n対応するモデルタイプのモジュール内に、モデルタイプと同名のPythonファイル（例：llm.py）を作成します。ファイル内に、具体的なモデルロジックを実装するクラスを定義します。このクラスは、システムのモデルインターフェース仕様に準拠している必要があります。\n\n事前定義済みモデル設定の追加\n\nプロバイダーが事前定義済みモデルを提供している場合、各モデルに対してモデル名と同名のYAMLファイル（例：claude-3.5.yaml）を作成します。AIModelEntityの仕様に従ってファイルの内容を記述し、モデルのパラメータと機能を定義します。\n\nプラグインのテスト\n\n新たに追加されたプロバイダー機能に対して、ユニットテストと統合テストを作成し、すべての機能モジュールが期待どおりに動作することを確認します。\n\n以下は、組み込みの詳細な手順です。\n\n​\n1. モデルタイプに応じたモジュール構造の作成\n\nモデルプロバイダーは、OpenAIが提供するllmやtext_embeddingのように、様々なモデルタイプを提供することがあります。プロバイダーモジュール内に、これらのモデルタイプに対応するサブモジュールを作成し、各モデルタイプが独立した論理構造を持つようにすることで、保守性と拡張性を高めます。\n\n現在サポートされているモデルタイプは以下のとおりです。\n\nllm: テキスト生成モデル\ntext_embedding: テキスト埋め込みモデル\nrerank: Rerankモデル\nspeech2text: 音声テキスト変換\ntts: テキスト音声変換\nmoderation: 審査\n\nAnthropicを例にとると、そのシリーズモデルにはLLMタイプのモデルのみが含まれているため、/modelsパスに/llmフォルダを新規作成し、異なるモデルのYAMLファイルを追加するだけで済みます。詳細なコード構造については、GitHubコードリポジトリを参照してください。\n\nCopy\n├── models\n│   └── llm\n│       ├── _position.yaml\n│       ├── claude-2.1.yaml\n│       ├── claude-2.yaml\n│       ├── claude-3-5-sonnet-20240620.yaml\n│       ├── claude-3-haiku-20240307.yaml\n│       ├── claude-3-opus-20240229.yaml\n│       ├── claude-3-sonnet-20240229.yaml\n│       ├── claude-instant-1.2.yaml\n│       ├── claude-instant-1.yaml\n│       └── llm.py\n\n\nOpenAIのファミリーモデルのように、モデルプロバイダーがllm、text_embedding、moderation、speech2text、ttsなど、さまざまなタイプのモデルを提供している場合は、/modelsパスに各タイプに対応するフォルダを作成する必要があります。構造は以下のようになります。\n\nCopy\n├── models\n│   ├── common_openai.py\n│   ├── llm\n│   │   ├── _position.yaml\n│   │   ├── chatgpt-4o-latest.yaml\n│   │   ├── gpt-3.5-turbo.yaml\n│   │   ├── gpt-4-0125-preview.yaml\n│   │   ├── gpt-4-turbo.yaml\n│   │   ├── gpt-4o.yaml\n│   │   ├── llm.py\n│   │   ├── o1-preview.yaml\n│   │   └── text-davinci-003.yaml\n│   ├── moderation\n│   │   ├── moderation.py\n│   │   └── text-moderation-stable.yaml\n│   ├── speech2text\n│   │   ├── speech2text.py\n│   │   └── whisper-1.yaml\n│   ├── text_embedding\n│   │   ├── text-embedding-3-large.yaml\n│   │   └── text_embedding.py\n│   └── tts\n│       ├── tts-1-hd.yaml\n│   │   ├── tts-1.yaml\n│   │   └── tts.py\n\n\nすべてのモデル設定を準備してから、モデルコードの実装を開始することをお勧めします。完全なYAMLの記述規則については、モデル設計規則を参照してください。詳細なコードについては、Githubコードリポジトリの例を参照してください。\n\n​\n2. モデル呼び出しコードの記述\n\n次に、/modelsパスにllm.pyというコードファイルを作成する必要があります。Anthropicを例にとると、llm.pyにAnthropic LLMクラスを作成し、AnthropicLargeLanguageModelという名前を付け、__base.large_language_model.LargeLanguageModel基本クラスを継承します。\n\n以下に、一部の機能のサンプルコードを示します。\n\nLLMの呼び出し\n\nLLMをリクエストする主要なメソッドです。ストリーミングと同期の両方のレスポンスをサポートします。\n\nCopy\ndef _invoke(self, model: str, credentials: dict,\n            prompt_messages: list[PromptMessage], model_parameters: dict,\n            tools: Optional[list[PromptMessageTool]] = None, stop: Optional[list[str]] = None,\n            stream: bool = True, user: Optional[str] = None) \\\n        -> Union[LLMResult, Generator]:\n    \"\"\"\n    Invoke large language model\n\n    :param model: model name\n    :param credentials: model credentials\n    :param prompt_messages: prompt messages\n    :param model_parameters: model parameters\n    :param tools: tools for tool calling\n    :param stop: stop words\n    :param stream: is stream response\n    :param user: unique user id\n    :return: full response or stream response chunk generator result\n    \"\"\"\n\n\n実装時には、同期リターンとストリームリターンを個別に処理するために、2つの関数を使用する必要があることに注意してください。これは、Pythonでyieldキーワードを含む関数はジェネレーター関数として認識され、その戻り値の型がGeneratorに固定されるためです。ロジックを明確にし、様々なリターンの要求に対応するために、同期リターンとストリームリターンは個別に実装する必要があります。\n\n以下はサンプルコードです（サンプルではパラメータが簡略化されています。実際の実装では、完全なパラメータリストに従って記述してください）。\n\nCopy\ndef _invoke(self, stream: bool, **kwargs) -> Union[LLMResult, Generator]:\n    \"\"\"戻り値の型に応じて、対応する処理関数を呼び出します。\"\"\"\n    if stream:\n        return self._handle_stream_response(**kwargs)\n    return self._handle_sync_response(**kwargs)\n\ndef _handle_stream_response(self, **kwargs) -> Generator:\n    \"\"\"ストリームリターンのロジックを処理します。\"\"\"\n    for chunk in response:  # responseがストリームデータのイテレーターであると仮定します\n        yield chunk\n\ndef _handle_sync_response(self, **kwargs) -> LLMResult:\n    \"\"\"同期リターンのロジックを処理します。\"\"\"\n    return LLMResult(**response)  # responseが完全な応答の辞書であると仮定します\n\n入力トークン数の事前計算\n\nモデルがトークン数の事前計算インターフェースを提供していない場合は、この機能が適用されないか、実装されていないことを示すために、直接0を返すことができます。例：\n\nCopy\ndef get_num_tokens(self, model: str, credentials: dict, prompt_messages: list[PromptMessage],\n                   tools: Optional[list[PromptMessageTool]] = None) -> int:\n    \"\"\"\n    Get number of tokens for given prompt messages\n\n    :param model: model name\n    :param credentials: model credentials\n    :param prompt_messages: prompt messages\n    :param tools: tools for tool calling\n    :return:\n    \"\"\"\n\n呼び出し例外エラーマッピングテーブル\n\nモデル呼び出しが例外の場合、Difyがさまざまなエラーに対して適切な処理を実行できるように、Runtimeによって指定されたInvokeErrorタイプにマッピングする必要があります。\n\nRuntime Errors:\n\nInvokeConnectionError: 呼び出し接続エラー\nInvokeServerUnavailableError: 呼び出しサービスが利用不可\nInvokeRateLimitError: 呼び出しが制限に達しました\nInvokeAuthorizationError: 呼び出し認証に失敗しました\nInvokeBadRequestError: 呼び出しパラメータにエラーがあります\nCopy\n@property\ndef _invoke_error_mapping(self) -> dict[type[InvokeError], list[type[Exception]]]:\n    \"\"\"\n    Map model invoke error to unified error\n    The key is the error type thrown to the caller\n    The value is the error type thrown by the model,\n    which needs to be converted into a unified error type for the caller.\n\n    :return: Invoke error mapping\n    \"\"\"\n\n\n完全なコードの詳細については、Githubコードリポジトリを参照してください。\n\n​\n3. 事前定義済みモデル設定の追加\n\nプロバイダーが事前定義済みモデルを提供している場合、各モデルに対してモデル名と同名のYAMLファイル（例：claude-3.5.yaml）を作成します。AIModelEntityの仕様に従ってファイルの内容を記述し、モデルのパラメータと機能を定義します。\n\nclaude-3-5-sonnet-20240620モデルのサンプルコード：\n\nCopy\nmodel: claude-3-5-sonnet-20240620\nlabel:\n  en_US: claude-3-5-sonnet-20240620\nmodel_type: llm\nfeatures:\n  - agent-thought\n  - vision\n  - tool-call\n  - stream-tool-call\n  - document\nmodel_properties:\n  mode: chat\n  context_size: 200000\nparameter_rules:\n  - name: temperature\n    use_template: temperature\n  - name: top_p\n    use_template: top_p\n  - name: top_k\n    label:\n      zh_Hans: 取样数量\n      en_US: Top k\n    type: int\n    help:\n      zh_Hans: 仅从每个后续标记的前 K 个选项中采样。\n      en_US: Only sample from the top K options for each subsequent token.\n    required: false\n  - name: max_tokens\n    use_template: max_tokens\n    required: true\n    default: 8192\n    min: 1\n    max: 8192\n  - name: response_format\n    use_template: response_format\npricing:\n  input: '3.00'\n  output: '15.00'\n  unit: '0.000001'\n  currency: USD\n\n​\n4. プラグインのデバッグ\n\n次に、プラグインが正常に動作するかどうかをテストする必要があります。Difyはリモートデバッグ方法を提供しており、「プラグイン管理」ページでデバッグキーとリモートサーバーアドレスを取得できます。\n\nプラグインプロジェクトに戻り、.env.exampleファイルをコピーして.envにリネームし、取得したリモートサーバーアドレスとデバッグKeyなどの情報を入力します。\n\n.env ファイル\n\nCopy\nINSTALL_METHOD=remote\nREMOTE_INSTALL_HOST=remote\nREMOTE_INSTALL_PORT=5003\nREMOTE_INSTALL_KEY=****-****-****-****-****\n\n\npython -m mainコマンドを実行してプラグインを起動します。プラグインページで、そのプラグインがWorkspaceにインストールされていることを確認できます。他のチームメンバーもこのプラグインにアクセスできます。\n\n「設定」→「モデルプロバイダー」でAPI Keyを入力して、モデルプロバイダーを初期化できます。\n\n​\nプラグインの公開\n\n作成したプラグインをDify Pluginsコードリポジトリにアップロードして公開できます。アップロードする前に、プラグインがプラグイン公開仕様に準拠していることを確認してください。審査に合格すると、コードがメインブランチにマージされ、Dify Marketplaceに自動的に公開されます。\n\n​\nさらに詳しく\n\nクイックスタート:\n\n拡張タイププラグインの開発\nモデルタイププラグインの開発\nバンドルタイププラグイン：複数のプラグインをパッケージ化\n\nプラグインインターフェースドキュメント:\n\nマニフェスト 構造\nエンドポイント 詳細定義\nDifyサービスの逆呼び出し\nツール\nモデル\n拡張エージェント戦略\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nモデルプロバイダーの構築\nカスタムモデルの組み込み\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\n1. モデルタイプに応じたモジュール構造の作成\n2. モデル呼び出しコードの記述\n3. 事前定義済みモデル設定の追加\n4. プラグインのデバッグ\nプラグインの公開\nさらに詳しく",
        "error": null
      },
      {
        "link_index": 21,
        "link_text": "カスタムモデルの組み込み",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/quick-start/develop-plugins/model-plugin/customizable-model",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nQuick start\nプラグインのインストールと利用方法\nプラグイン開発の入門\nDevelop plugins\n開発環境のセットアップ\nツールプラグイン\nモデル型プラグイン\nModel plugin\nモデルプロバイダーの構築\n定義済みモデルの組み込み\nカスタムモデルの組み込み\nエージェント戦略プラグイン\n拡張機能型プラグイン\nバンドル\nプラグインのデバッグ方法\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nモデル型プラグイン\nカスタムモデルの組み込み\nCopy page\n\nカスタムモデルとは、ユーザー自身でデプロイまたは設定する必要があるLLMのことです。この記事では、Xinferenceモデルを例に、モデルプラグイン内でカスタムモデルを組み込む方法を解説します。\n\nカスタムモデルには、デフォルトでモデルタイプとモデル名の2つのパラメータが含まれており、サプライヤのyamlファイルで定義する必要はありません。\n\nサプライヤ設定ファイルでvalidate_provider_credentialを実装する必要はありません。Runtimeは、ユーザーが選択したモデルタイプまたはモデル名に基づいて、対応するモデルレイヤのvalidate_credentialsメソッドを自動的に呼び出して検証します。\n\n​\nカスタムモデルプラグインの組み込み\n\nカスタムモデルを組み込むには、以下の手順に従います。\n\nモデルサプライヤファイルの作成\n\n組み込むカスタムモデルのモデルタイプを明確にします。\n\nモデルタイプに応じたコードファイルの作成\n\nモデルのタイプ（llmやtext_embeddingなど）に応じて、コードファイルを作成します。各モデルタイプが独立した論理構造を持つようにすることで、保守と拡張が容易になります。\n\nモデルモジュールに基づいたモデル呼び出しコードの記述\n\n対応するモデルタイプモジュールに、モデルタイプと同名のPythonファイル（例：llm.py）を作成します。ファイル内で、具体的なモデルロジックを実装するクラスを定義します。このクラスは、システムのモデルインターフェース仕様に準拠している必要があります。\n\nプラグインのデバッグ\n\n新たに追加されたサプライヤ機能について、ユニットテストと統合テストを作成し、すべての機能モジュールが期待どおりに動作することを確認します。\n\n​\n1. モデルサプライヤファイルの作成\n\nプラグインプロジェクトの/providerパスに、xinference.yamlファイルを作成します。\n\nXinferenceは、LLM、Text Embedding、Rerankのモデルタイプをサポートしているため、xinference.yamlファイルにこれらのモデルタイプを含める必要があります。\n\nサンプルコード：\n\nprovider: xinference # サプライヤIDを決定\nlabel: # サプライヤの表示名。en_US（英語）とzh_Hans（中国語）の2つの言語を設定できます。zh_Hansを設定しない場合、デフォルトでen_USが使用されます。\n  en_US: Xorbits Inference\nicon_small: # 小さいアイコン。他のサプライヤのアイコンを参考に、対応するサプライヤ実装ディレクトリの_assetsディレクトリに保存してください。言語設定はlabelと同様です。\n  en_US: icon_s_en.svg\nicon_large: # 大きいアイコン\n  en_US: icon_l_en.svg\nhelp: # ヘルプ\n  title:\n    en_US: How to deploy Xinference\n    zh_Hans: 如何部署 Xinference (Xinferenceのデプロイ方法)\n  url:\n    en_US: https://github.com/xorbitsai/inference\nsupported_model_types: # サポートされているモデルタイプ。XinferenceはLLM/Text Embedding/Rerankをサポートしています。\n- llm\n- text-embedding\n- rerank\nconfigurate_methods: # Xinferenceはローカルにデプロイするサプライヤであり、事前定義されたモデルはありません。使用するモデルはXinferenceのドキュメントに従ってデプロイする必要があるため、ここではカスタムモデルを使用します。\n- customizable-model\nprovider_credential_schema:\n  credential_form_schemas:\n\n\n次に、provider_credential_schemaフィールドを定義します。Xinferenceは、text-generation、embeddings、rerankingモデルをサポートしています。サンプルコードを以下に示します。\n\nprovider_credential_schema:\n  credential_form_schemas:\n  - variable: model_type\n    type: select\n    label:\n      en_US: Model type\n      zh_Hans: 模型类型 (モデルタイプ)\n    required: true\n    options:\n    - value: text-generation\n      label:\n        en_US: Language Model\n        zh_Hans: 语言模型 (言語モデル)\n    - value: embeddings\n      label:\n        en_US: Text Embedding\n    - value: reranking\n      label:\n        en_US: Rerank\n\n\nXinferenceの各モデルでは、model_nameという名前を定義する必要があります。\n\n  - variable: model_name\n    type: text-input\n    label:\n      en_US: Model name\n      zh_Hans: 模型名称 (モデル名)\n    required: true\n    placeholder:\n      zh_Hans: モデル名を入力してください\n      en_US: Input model name\n\n\nXinferenceモデルでは、ユーザーがモデルのローカルデプロイアドレスを入力する必要があります。プラグイン内では、Xinferenceモデルのローカルデプロイアドレス（server_url）とモデルUIDを入力できる場所を提供する必要があります。サンプルコードを以下に示します。\n\n  - variable: server_url\n    label:\n      zh_Hans: サーバーURL\n      en_US: Server url\n    type: text-input\n    required: true\n    placeholder:\n      zh_Hans: Xinferenceのサーバーアドレスをここに入力してください（例：https://example.com/xxx）\n      en_US: Enter the url of your Xinference, for example https://example.com/xxx\n  - variable: model_uid\n    label:\n      zh_Hans: モデルUID\n      en_US: Model uid\n    type: text-input\n    required: true\n    placeholder:\n      zh_Hans: モデルUIDを入力してください\n      en_US: Enter the model uid\n\n\nすべてのパラメータを入力すると、カスタムモデルサプライヤのyaml設定ファイルの作成が完了します。次に、設定ファイルで定義されたモデルに具体的な機能コードファイルを追加する必要があります。\n\n​\n2. モデルコードの記述\n\nXinferenceモデルサプライヤのモデルタイプには、llm、rerank、speech2text、ttsタイプが含まれています。そのため、/modelsパスに各モデルタイプの独立したグループを作成し、対応する機能コードファイルを作成する必要があります。\n\n以下では、llmタイプを例に、llm.pyコードファイルの作成方法を説明します。コードを作成する際には、Xinference LLMクラスを作成する必要があります。名前はXinferenceAILargeLanguageModelとし、__base.large_language_model.LargeLanguageModel基底クラスを継承し、以下のメソッドを実装します。\n\nLLMの呼び出し\n\nLLM呼び出しの中核となるメソッドです。ストリーミングと同期の両方の戻り値をサポートします。\n\ndef _invoke(self, model: str, credentials: dict,\n            prompt_messages: list[PromptMessage], model_parameters: dict,\n            tools: Optional[list[PromptMessageTool]] = None, stop: Optional[list[str]] = None,\n            stream: bool = True, user: Optional[str] = None) \\\n        -> Union[LLMResult, Generator]:\n    \"\"\"\n    Invoke large language model\n\n    :param model: model name\n    :param credentials: model credentials\n    :param prompt_messages: prompt messages\n    :param model_parameters: model parameters\n    :param tools: tools for tool calling\n    :param stop: stop words\n    :param stream: is stream response\n    :param user: unique user id\n    :return: full response or stream response chunk generator result\n    \"\"\"\n\n\nコードを実装する際には、同期戻り値とストリーミング戻り値で異なる関数を使用する必要があります。\n\nPythonでは、関数にyieldキーワードが含まれている場合、その関数はジェネレータ関数として認識され、戻り値の型はGeneratorに固定されます。したがって、同期戻り値とストリーミング戻り値をそれぞれ実装する必要があります。例えば、以下のサンプルコードを参照してください。\n\nこの例では、パラメータが簡略化されています。実際のコードを記述する際には、上記のパラメータリストを参照してください。\n\ndef _invoke(self, stream: bool, **kwargs) \\\n        -> Union[LLMResult, Generator]:\n    if stream:\n          return self._handle_stream_response(**kwargs)\n    return self._handle_sync_response(**kwargs)\n\ndef _handle_stream_response(self, **kwargs) -> Generator:\n    for chunk in response:\n          yield chunk\ndef _handle_sync_response(self, **kwargs) -> LLMResult:\n    return LLMResult(**response)\n\n入力トークンの事前計算\n\nモデルがトークンの事前計算インターフェースを提供していない場合は、0を返すことができます。\n\ndef get_num_tokens(self, model: str, credentials: dict, prompt_messages: list[PromptMessage],\n                 tools: Optional[list[PromptMessageTool]] = None) -> int:\n  \"\"\"\n  Get number of tokens for given prompt messages\n\n  :param model: model name\n  :param credentials: model credentials\n  :param prompt_messages: prompt messages\n  :param tools: tools for tool calling\n  :return:\n  \"\"\"\n\n\n直接0を返したくない場合は、self._get_num_tokens_by_gpt2(text: str)メソッドを使用してトークンを計算できます。このメソッドはAIModel基底クラスにあり、GPT-2のTokenizerを使用して計算を行います。ただし、あくまで代替手段であり、計算結果には誤差が生じる可能性があることに注意してください。\n\nモデルの認証情報の検証\n\nサプライヤの認証情報の検証と同様に、ここでは個々のモデルを検証します。\n\ndef validate_credentials(self, model: str, credentials: dict) -> None:\n    \"\"\"\n    Validate model credentials\n\n    :param model: model name\n    :param credentials: model credentials\n    :return:\n    \"\"\"\n\n\nモデルパラメータのスキーマ\n\n事前定義されたモデルタイプとは異なり、YAMLファイルにモデルがサポートするパラメータが事前に定義されていないため、モデルパラメータのスキーマを動的に生成する必要があります。\n\n例えば、Xinferenceはmax_tokens、temperature、top_pの3つのモデルパラメータをサポートしています。ただし、サプライヤによっては、モデルごとに異なるパラメータをサポートする場合があります（例：OpenLLM）。\n\n例として、サプライヤOpenLLMのモデルAはtop_kパラメータをサポートしていますが、モデルBはサポートしていません。この場合、各モデルに対応するパラメータスキーマを動的に生成する必要があります。以下にサンプルコードを示します。\n\ndef get_customizable_model_schema(self, model: str, credentials: dict) -> AIModelEntity | None:\n    \"\"\"\n        used to define customizable model schema\n    \"\"\"\n    rules = [\n        ParameterRule(\n            name='temperature', type=ParameterType.FLOAT,\n            use_template='temperature',\n            label=I18nObject(\n                zh_Hans='温度', en_US='Temperature'\n            )\n        ),\n        ParameterRule(\n            name='top_p', type=ParameterType.FLOAT,\n            use_template='top_p',\n            label=I18nObject(\n                zh_Hans='Top P', en_US='Top P'\n            )\n        ),\n        ParameterRule(\n            name='max_tokens', type=ParameterType.INT,\n            use_template='max_tokens',\n            min=1,\n            default=512,\n            label=I18nObject(\n                zh_Hans='最大生成长度', en_US='Max Tokens'\n            )\n        )\n    ]\n\n    # if model is A, add top_k to rules\n    if model == 'A':\n        rules.append(\n            ParameterRule(\n                name='top_k', type=ParameterType.INT,\n                use_template='top_k',\n                min=1,\n                default=50,\n                label=I18nObject(\n                    zh_Hans='Top K', en_US='Top K'\n                )\n            )\n        )\n\n    \"\"\"\n        some NOT IMPORTANT code here\n    \"\"\"\n\n    entity = AIModelEntity(\n        model=model,\n        label=I18nObject(\n            en_US=model\n        ),\n        fetch_from=FetchFrom.CUSTOMIZABLE_MODEL,\n        model_type=model_type,\n        model_properties={ \n            ModelPropertyKey.MODE:  ModelType.LLM,\n        },\n        parameter_rules=rules\n    )\n\n    return entity\n\n\n呼び出し例外エラーのマッピング\n\nモデルの呼び出し時に例外が発生した場合、Runtimeで指定されたInvokeErrorタイプにマッピングする必要があります。これは、Difyが異なるエラーに対して異なる後続処理を実行できるようにするためです。\n\nRuntime Errors:\n\n• `InvokeConnectionError`  呼び出し接続エラー\n• `InvokeServerUnavailableError`  呼び出しサービスが利用不可\n• `InvokeRateLimitError` 呼び出しが制限に達した\n• `InvokeAuthorizationError` 呼び出し認証失敗\n• `InvokeBadRequestError` 呼び出しパラメータエラー\n\n@property\ndef _invoke_error_mapping(self) -> dict[type[InvokeError], list[type[Exception]]]:\n    \"\"\"\n    Map model invoke error to unified error\n    The key is the error type thrown to the caller\n    The value is the error type thrown by the model,\n    which needs to be converted into a unified error type for the caller.\n\n    :return: Invoke error mapping\n    \"\"\"\n\n\nさらに詳しいインターフェースメソッドについては、インターフェースドキュメント：Modelを参照してください。\n\nこの記事で取り上げた完全なコードファイルについては、GitHubコードリポジトリをご覧ください。\n\n​\n3. プラグインのデバッグ\n\nプラグインの開発が完了したら、次にプラグインが正常に動作するかどうかをテストする必要があります。詳細については、以下を参照してください。\n\ndebug-plugin.md\n\ndebug-plugin.md\n\n​\n4.  プラグインの公開\n\nプラグインをDify マーケットプレイスに公開する場合は、以下を参照してください。\n\npublish-to-dify-marketplace.md\n\npublish-to-dify-marketplace\n\n​\nさらに詳しく\n\nクイックスタート:\n\n拡張タイププラグインの開発\nモデルタイププラグインの開発\nバンドルタイププラグイン：複数のプラグインをパッケージ化\n\nプラグインインターフェースドキュメント:\n\nマニフェスト 構造\nエンドポイント 詳細定義\nDifyサービスの逆呼び出し\nツール\nモデル\n拡張エージェント戦略\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\n定義済みモデルの組み込み\nエージェント戦略プラグイン\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nカスタムモデルプラグインの組み込み\n1. モデルサプライヤファイルの作成\n2. モデルコードの記述\n3. プラグインのデバッグ\n4. プラグインの公開\nさらに詳しく",
        "error": null
      },
      {
        "link_index": 22,
        "link_text": "エージェント戦略プラグイン",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/quick-start/develop-plugins/agent-strategy-plugin",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nQuick start\nプラグインのインストールと利用方法\nプラグイン開発の入門\nDevelop plugins\n開発環境のセットアップ\nツールプラグイン\nモデル型プラグイン\nエージェント戦略プラグイン\n拡張機能型プラグイン\nバンドル\nプラグインのデバッグ方法\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nプラグイン開発の入門\nエージェント戦略プラグイン\nCopy page\n\nエージェント戦略プラグインは、LLMが推論や意思決定ロジックを実行するのを支援します。具体的には、ツール選択、呼び出し、結果処理といった一連の動作をより自動化された方法で実行し、問題を解決します。\n\nこの記事では、ツール呼び出し（Function Calling）機能を備え、現在の正確な時刻を自動的に取得するプラグインの作成方法を説明します。\n\n​\n事前準備\nDifyプラグインの足場ツール\nPython環境（バージョン3.12以上）\n\nプラグイン開発の足場ツールを準備する方法については、開発ツールの初期化を参照してください。\n\nヒント：ターミナルで dify version コマンドを実行し、バージョン番号が表示されることを確認することで、足場ツールが正常にインストールされたことを確認できます。\n​\n1. プラグインテンプレートの初期化\n\n以下のコマンドを実行して、Agentプラグイン開発テンプレートを初期化します。\n\nCopy\ndify plugin init\n\n\n表示される指示に従い、必要な情報を入力します。以下のコードのコメントを参考に設定してください。\n\nCopy\n➜ ./dify-plugin-darwin-arm64 plugin init                                                                                                                                 ─╯\nEdit profile of the plugin\nPlugin name (press Enter to next step): # プラグイン名を入力\nAuthor (press Enter to next step): # プラグイン作者を入力\nDescription (press Enter to next step): # プラグインの説明を入力\n---\nSelect the language you want to use for plugin development, and press Enter to continue,\nBTW, you need Python 3.12+ to develop the Plugin if you choose Python.\n-> python # Python環境を選択\n  go (not supported yet)\n---\nBased on the ability you want to extend, we have divided the Plugin into four types: Tool, Model, Extension, and Agent Strategy.\n\n- Tool: It's a tool provider, but not only limited to tools, you can implement an endpoint there, for example, you need both Sending Message and Receiving Message if you are\n- Model: Just a model provider, extending others is not allowed.\n- Extension: Other times, you may only need a simple http service to extend the functionalities, Extension is the right choice for you.\n- Agent Strategy: Implement your own logics here, just by focusing on Agent itself\n\nWhat's more, we have provided the template for you, you can choose one of them below:\n  tool\n-> agent-strategy # Agent戦略テンプレートを選択\n  llm\n  text-embedding\n---\nConfigure the permissions of the plugin, use up and down to navigate, tab to select, after selection, press enter to finish\nBackwards Invocation:\nTools:\n    Enabled: [✔]  You can invoke tools inside Dify if it's enabled # デフォルトで有効\nModels:\n    Enabled: [✔]  You can invoke models inside Dify if it's enabled # デフォルトで有効\n    LLM: [✔]  You can invoke LLM models inside Dify if it's enabled # デフォルトで有効\n  → Text Embedding: [✘]  You can invoke text embedding models inside Dify if it's enabled\n    Rerank: [✘]  You can invoke rerank models inside Dify if it's enabled\n    TTS: [✘]  You can invoke TTS models inside Dify if it's enabled\n    Speech2Text: [✘]  You can invoke speech2text models inside Dify if it's enabled\n    Moderation: [✘]  You can invoke moderation models inside Dify if it's enabled\nApps:\n    Enabled: [✘]  Ability to invoke apps like BasicChat/ChatFlow/Agent/Workflow etc.\nResources:\nStorage:\n    Enabled: [✘]  Persistence storage for the plugin\n    Size: N/A  The maximum size of the storage\nEndpoints:\n    Enabled: [✘]  Ability to register endpoints\n\n\nプラグインテンプレートを初期化すると、プラグインの開発に必要なすべてのリソースを含むコードフォルダが生成されます。エージェント戦略プラグインのコード構造を理解することで、開発プロセスがスムーズになります。\n\nCopy\n├── GUIDE.md               # ユーザーガイドとドキュメント\n├── PRIVACY.md            # プライバシーポリシーとデータ処理ガイドライン\n├── README.md             # プロジェクト概要と設定手順\n├── _assets/             # 静的アセットディレクトリ\n│   └── icon.svg         # エージェント戦略プロバイダーのアイコン/ロゴ\n├── main.py              # メインアプリケーションのエントリーポイント\n├── manifest.yaml        # 基本的なプラグイン構成\n├── provider/           # プロバイダー構成ディレクトリ\n│   └── basic_agent.yaml # Agentプロバイダーの設定\n├── requirements.txt    # Python依存関係リスト\n└── strategies/         # 戦略実装ディレクトリ\n    ├── basic_agent.py  # 基本的なエージェント戦略の実装\n    └── basic_agent.yaml # 基本的なエージェント戦略の構成\n\n\nプラグインの機能コードは、strategies/ ディレクトリにまとめられています。\n\n​\n2. プラグイン機能の開発\n\nエージェントプラグインの開発は、主に以下の2つのファイルを中心に行います。\n\nプラグイン定義ファイル：strategies/basic_agent.yaml\nプラグイン機能コード：strategies/basic_agent.py\n​\n2.1 パラメータの定義\n\nAgentプラグインを作成するには、まず strategies/basic_agent.yaml ファイルでプラグインに必要なパラメータを定義します。これらのパラメータは、LLMモデルの呼び出しやツールの使用など、プラグインの核となる機能を決定します。\n\n次の4つの基本パラメータを優先的に設定することをお勧めします。\n\nmodel：呼び出すLLM（GPT-4、GPT-4o-miniなど）を指定します。\ntools：プラグインが使用できるツールリストを定義し、プラグインの機能を拡張します。\nquery：モデルとの対話に使用するプロンプトまたは入力内容を設定します。\nmaximum_iterations：プラグインの最大反復回数を制限し、過剰な計算を避けます。\nCopy\nidentity:\n  name: basic_agent # agent_strategyの名前\n  author: novice # agent_strategyの作者\n  label:\n    en_US: BasicAgent # agent_strategyの英語ラベル\ndescription:\n  en_US: BasicAgent # agent_strategyの英語説明\nparameters:\n  - name: model # modelパラメータの名前\n    type: model-selector # model-type\n    scope: tool-call&llm # パラメータのスコープ\n    required: true\n    label:\n      en_US: Model\n      zh_Hans: 模型\n      pt_BR: Model\n  - name: tools # toolsパラメータの名前\n    type: array[tools] # toolパラメータの型\n    required: true\n    label:\n      en_US: Tools list\n      zh_Hans: 工具列表\n      pt_BR: Tools list\n  - name: query # queryパラメータの名前\n    type: string # queryパラメータの型\n    required: true\n    label:\n      en_US: Query\n      zh_Hans: 查询\n      pt_BR: Query\n  - name: maximum_iterations\n    type: number\n    required: false\n    default: 5\n    label:\n      en_US: Maxium Iterations\n      zh_Hans: 最大迭代次数\n      pt_BR: Maxium Iterations\n    max: 50 # maxとminの値を設定すると、パラメータ表示がスライダーになります\n    min: 1\nextra:\n  python:\n    source: strategies/basic_agent.py\n\n\n\nパラメータ設定が完了すると、プラグインは対応する設定ページを自動的に生成し、直感的かつ使いやすく調整や利用ができます。\n\n​\n2.2 パラメータの取得と実行\n\nユーザーがプラグインの設定ページで基本情報を入力すると、プラグインは入力されたパラメータを処理する必要があります。そのため、まず strategies/basic_agent.py ファイル内で、後で使用するためのAgentパラメータクラスを定義します。\n\n入力パラメータの検証：\n\nCopy\nfrom dify_plugin.entities.agent import AgentInvokeMessage\nfrom dify_plugin.interfaces.agent import AgentModelConfig, AgentStrategy, ToolEntity\nfrom pydantic import BaseModel\n\nclass BasicParams(BaseModel):\n    maximum_iterations: int\n    model: AgentModelConfig\n    tools: list[ToolEntity]\n    query: str\n\n\n\nパラメータを取得した後、具体的な処理ロジックを実行します。\n\nCopy\nclass BasicAgentAgentStrategy(AgentStrategy):\n    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:\n        params = BasicParams(**parameters)\n\n​\n2.3 モデルの呼び出し\n\nエージェント戦略プラグインでは、モデルの呼び出しが中心的な処理ロジックの1つです。SDKが提供する session.model.llm.invoke() メソッドを使用すると、LLMモデルを効率的に呼び出して、テキスト生成や対話処理などの機能を実現できます。\n\nモデルにツール呼び出し機能を持たせたい場合は、まず、モデルがツール呼び出し形式に沿ったパラメータを出力できることを確認する必要があります。つまり、モデルはユーザーの指示に従って、ツールインターフェースの要件を満たすパラメータを生成する必要があります。\n\n以下のパラメータを構築します。\n\nmodel：モデル情報\nprompt_messages：プロンプト\ntools：ツール情報（Function Calling関連）\nstop：停止記号\nstream：ストリーミング出力をサポートするかどうか\n\nメソッド定義のサンプルコード：\n\nCopy\ndef invoke(\n        self,\n        model_config: LLMModelConfig,\n        prompt_messages: list[PromptMessage],\n        tools: list[PromptMessageTool] | None = None,\n        stop: list[str] | None = None,\n        stream: bool = True,\n    ) -> Generator[LLMResultChunk, None, None] | LLMResult:...\n\n\n完全な実装については、モデル呼び出しのサンプルコードを参照してください。\n\nこのコードでは、ユーザーが指示を入力すると、エージェント戦略プラグインが自動的にLLMを呼び出し、その結果に基づいてツールの呼び出しに必要なパラメータを構築し、渡します。これにより、モデルは連携されたツールを柔軟に活用し、複雑なタスクを効率的に完了できます。\n\n​\n2.4 モデルへのメモリ機能の追加\n\nAgentプラグインを使用してモデルを呼び出す際、メモリ機能を追加することで対話体験が大幅に向上します。メモリ機能により、モデルは完全な対話コンテキストを理解し、一貫性のある対話と正確なツール呼び出しを実現できます。\n\n実装手順：\n\nメモリ機能の設定\n\nAgentプラグインのYAML設定ファイルstrategies/agent.yamlにhistory-messages機能を追加します：\n\nCopy\nidentity:\n  name: basic_agent  # Agent戦略名\n  author: novice     # 作者\n  label:\n    en_US: BasicAgent  # 英語ラベル\ndescription:\n  en_US: BasicAgent    # 英語説明\nfeatures:\n  - history-messages   # 履歴メッセージ機能を有効化\n...\n\nメモリ設定の有効化\n\nプラグイン設定ファイルを修正して再起動後、ノード設定画面にメモリトグルが表示されます。右側のトグルボタンをクリックしてメモリ機能を有効にします。\n\n有効化後、ウィンドウサイズスライダーでメモリウィンドウを調整できます。これはモデルが「記憶」できる過去の対話の量を決定します。\n\n履歴メッセージのデバッグ\n\n以下のコードを追加して、履歴メッセージの内容を確認します：\n\nCopy\nclass BasicAgentAgentStrategy(AgentStrategy):\n    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:\n        params = BasicParams(**parameters)\n        print(f\"history_messages: {params.model.history_prompt_messages}\")\n        ...\n\n\nコンソールには以下のような出力が表示されます：\n\nCopy\nhistory_messages: []\nhistory_messages: [UserPromptMessage(role=<PromptMessageRole.USER: 'user'>, content='hello, my name is novice', name=None), AssistantPromptMessage(role=<PromptMessageRole.ASSISTANT: 'assistant'>, content='Hello, Novice! How can I assist you today?', name=None, tool_calls=[])]\n\n履歴メッセージのモデル呼び出しへの統合\n\n最後に、モデル呼び出しコードを修正して、履歴メッセージを現在のクエリに連結します：\n\nCopy\nclass BasicAgentAgentStrategy(AgentStrategy):\n    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:\n        params = BasicParams(**parameters)\n\n        chunks: Generator[LLMResultChunk, None, None] | LLMResult = (\n            self.session.model.llm.invoke(\n                model_config=LLMModelConfig(**params.model.model_dump(mode=\"json\")),\n                # 履歴メッセージを追加\n                prompt_messages=params.model.history_prompt_messages\n                + [UserPromptMessage(content=params.query)],\n                tools=[\n                    self._convert_tool_to_prompt_message_tool(tool)\n                    for tool in params.tools\n                ],\n                stop=params.model.completion_params.get(\"stop\", [])\n                if params.model.completion_params\n                else [],\n                stream=True,\n            )\n        )\n        ...\n\n効果の検証\n\nメモリ機能を追加後、モデルは履歴に基づいて応答できるようになります。以下の例では、モデルは以前の対話で言及されたユーザー名を正しく記憶し、対話の一貫性を実現しています。\n\n​\n2.5 ツールの呼び出し\n\nツールパラメータを設定した後、エージェント戦略プラグインに実際にツールを呼び出す機能を追加する必要があります。これは、SDKの session.tool.invoke() 関数を使用して行えます。\n\n以下のパラメータを構築します。\n\nprovider：ツール提供者\ntool_name：ツール名\nparameters：入力パラメータ\n\nメソッド定義のサンプルコード：\n\nCopy\n def invoke(\n        self,\n        provider_type: ToolProviderType,\n        provider: str,\n        tool_name: str,\n        parameters: dict[str, Any],\n    ) -> Generator[ToolInvokeMessage, None, None]:...\n\n\nLLMで直接パラメータを生成してツールを呼び出したい場合は、以下のツール呼び出しのサンプルコードを参照してください。\n\nCopy\ntool_instances = (\n    {tool.identity.name: tool for tool in params.tools} if params.tools else {}\n)\nfor tool_call_id, tool_call_name, tool_call_args in tool_calls:\n    tool_instance = tool_instances[tool_call_name]\n    self.session.tool.invoke(\n        provider_type=ToolProviderType.BUILT_IN,\n        provider=tool_instance.identity.provider,\n        tool_name=tool_instance.identity.name,\n        parameters={**tool_instance.runtime_parameters, **tool_call_args},\n    )\n\n\n完全な機能コードについては、ツール呼び出しのサンプルコードを参照してください。\n\nこの機能コードを実装すると、エージェント戦略プラグインは自動的にFunction Callingを実行できるようになります。例えば、現在の時刻を自動的に取得するなどが可能です。\n\n​\n2.6 ログの作成\n\nエージェント戦略プラグインでは、複雑なタスクを完了するために、通常、複数回の操作が必要です。各操作の実行結果を記録することは、開発者にとって非常に重要です。Agentの実行プロセスを追跡し、各ステップの意思決定の根拠を分析することで、戦略の効果をより適切に評価し、最適化できます。\n\nこの機能を実装するために、SDKの create_log_message と finish_log_message メソッドを利用してログを記録できます。この方法では、モデル呼び出しの前後に操作状態をリアルタイムで記録できるだけでなく、開発者が問題を迅速に特定するのに役立ちます。\n\nシナリオ例：\n\nモデルを呼び出す前に、「モデルの呼び出しを開始」というログを記録することで、開発者はタスクの実行状況を明確に把握できます。\nモデル呼び出しが成功した後、「呼び出し成功」というログを記録することで、モデルの応答の完全性を追跡できます。\nCopy\nmodel_log = self.create_log_message(\n            label=f\"{params.model.model} Thought\",\n            data={},\n            metadata={\"start_at\": model_started_at, \"provider\": params.model.provider},\n            status=ToolInvokeMessage.LogMessage.LogStatus.START,\n        )\nyield model_log\nself.session.model.llm.invoke(...)\nyield self.finish_log_message(\n    log=model_log,\n    data={\n        \"output\": response,\n        \"tool_name\": tool_call_names,\n        \"tool_input\": tool_call_inputs,\n    },\n    metadata={\n        \"started_at\": model_started_at,\n        \"finished_at\": time.perf_counter(),\n        \"elapsed_time\": time.perf_counter() - model_started_at,\n        \"provider\": params.model.provider,\n    },\n)\n\n\n設定が完了すると、ワークフローログに実行結果が出力されます。\n\nAgentの実行中には、複数ラウンドのログが生成される場合があります。ログに階層構造を持たせることで、開発者がログを確認しやすくなります。ログを記録する際に parent パラメータを渡すことで、異なるラウンドのログ間に親子関係が形成され、ログの表示がより明確になり、追跡が容易になります。\n\n使用方法：\n\nCopy\nfunction_call_round_log = self.create_log_message(\n    label=\"Function Call Round1 \",\n    data={},\n    metadata={},\n)\nyield function_call_round_log\n\nmodel_log = self.create_log_message(\n    label=f\"{params.model.model} Thought\",\n    data={},\n    metadata={\"start_at\": model_started_at, \"provider\": params.model.provider},\n    status=ToolInvokeMessage.LogMessage.LogStatus.START,\n    # 親ログを追加\n    parent=function_call_round_log,\n)\nyield model_log\n\n\nプラグイン機能のサンプルコード：\n\nモデルの呼び出し\nツールの呼び出し\n完全な機能コード例\n​\nモデルの呼び出し\n\n以下のコードは、エージェント戦略プラグインにモデルを呼び出す機能を追加する方法を示しています。\n\nCopy\nimport json\nfrom collections.abc import Generator\nfrom typing import Any, cast\n\nfrom dify_plugin.entities.agent import AgentInvokeMessage\nfrom dify_plugin.entities.model.llm import LLMModelConfig, LLMResult, LLMResultChunk\nfrom dify_plugin.entities.model.message import (\n    PromptMessageTool,\n    UserPromptMessage,\n)\nfrom dify_plugin.entities.tool import ToolInvokeMessage, ToolParameter, ToolProviderType\nfrom dify_plugin.interfaces.agent import AgentModelConfig, AgentStrategy, ToolEntity\nfrom pydantic import BaseModel\n\nclass BasicParams(BaseModel):\n    maximum_iterations: int\n    model: AgentModelConfig\n    tools: list[ToolEntity]\n    query: str\n\nclass BasicAgentAgentStrategy(AgentStrategy):\n    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:\n        params = BasicParams(**parameters)\n        chunks: Generator[LLMResultChunk, None, None] | LLMResult = (\n            self.session.model.llm.invoke(\n                model_config=LLMModelConfig(**params.model.model_dump(mode=\"json\")),\n                prompt_messages=[UserPromptMessage(content=params.query)],\n                tools=[\n                    self._convert_tool_to_prompt_message_tool(tool)\n                    for tool in params.tools\n                ],\n                stop=params.model.completion_params.get(\"stop\", [])\n                if params.model.completion_params\n                else [],\n                stream=True,\n            )\n        )\n        response = \"\"\n        tool_calls = []\n        tool_instances = (\n            {tool.identity.name: tool for tool in params.tools} if params.tools else {}\n        )\n\n        for chunk in chunks:\n            # ツール呼び出しがあるか確認\n            if self.check_tool_calls(chunk):\n                tool_calls = self.extract_tool_calls(chunk)\n                tool_call_names = \";\".join([tool_call[1] for tool_call in tool_calls])\n                try:\n                    tool_call_inputs = json.dumps(\n                        {tool_call[1]: tool_call[2] for tool_call in tool_calls},\n                        ensure_ascii=False,\n                    )\n                except json.JSONDecodeError:\n                    # エンコードエラーを避けるため、asciiを保証\n                    tool_call_inputs = json.dumps(\n                        {tool_call[1]: tool_call[2] for tool_call in tool_calls}\n                    )\n                print(tool_call_names, tool_call_inputs)\n            if chunk.delta.message and chunk.delta.message.content:\n                if isinstance(chunk.delta.message.content, list):\n                    for content in chunk.delta.message.content:\n                        response += content.data\n                        print(content.data, end=\"\", flush=True)\n                else:\n                    response += str(chunk.delta.message.content)\n                    print(str(chunk.delta.message.content), end=\"\", flush=True)\n\n            if chunk.delta.usage:\n                # モデルを使用する\n                usage = chunk.delta.usage\n\n        yield self.create_text_message(\n            text=f\"{response or json.dumps(tool_calls, ensure_ascii=False)}\\n\"\n        )\n        result = \"\"\n        for tool_call_id, tool_call_name, tool_call_args in tool_calls:\n            tool_instance = tool_instances[tool_call_name]\n            tool_invoke_responses = self.session.tool.invoke(\n                provider_type=ToolProviderType.BUILT_IN,\n                provider=tool_instance.identity.provider,\n                tool_name=tool_instance.identity.name,\n                parameters={**tool_instance.runtime_parameters, **tool_call_args},\n            )\n            if not tool_instance:\n                tool_invoke_responses = {\n                    \"tool_call_id\": tool_call_id,\n                    \"tool_call_name\": tool_call_name,\n                    \"tool_response\": f\"there is not a tool named {tool_call_name}\",\n                }\n            else:\n                # ツールを呼び出す\n                tool_invoke_responses = self.session.tool.invoke(\n                    provider_type=ToolProviderType.BUILT_IN,\n                    provider=tool_instance.identity.provider,\n                    tool_name=tool_instance.identity.name,\n                    parameters={**tool_instance.runtime_parameters, **tool_call_args},\n                )\n                result = \"\"\n                for tool_invoke_response in tool_invoke_responses:\n                    if tool_invoke_response.type == ToolInvokeMessage.MessageType.TEXT:\n                        result += cast(\n                            ToolInvokeMessage.TextMessage, tool_invoke_response.message\n                        ).text\n                    elif (\n                        tool_invoke_response.type == ToolInvokeMessage.MessageType.LINK\n                    ):\n                        result += (\n                            f\"result link: {cast(ToolInvokeMessage.TextMessage, tool_invoke_response.message).text}.\"\n                            + \" please tell user to check it.\"\n                        )\n                    elif tool_invoke_response.type in {\n                        ToolInvokeMessage.MessageType.IMAGE_LINK,\n                        ToolInvokeMessage.MessageType.IMAGE,\n                    }:\n                        result += (\n                            \"image has been created and sent to user already, \"\n                            + \"you do not need to create it, just tell the user to check it now.\"\n                        )\n                    elif (\n                        tool_invoke_response.type == ToolInvokeMessage.MessageType.JSON\n                    ):\n                        text = json.dumps(\n                            cast(\n                                ToolInvokeMessage.JsonMessage,\n                                tool_invoke_response.message,\n                            ).json_object,\n                            ensure_ascii=False,\n                        )\n                        result += f\"tool response: {text}.\"\n                    else:\n                        result += f\"tool response: {tool_invoke_response.message!r}.\"\n\n                tool_response = {\n                    \"tool_call_id\": tool_call_id,\n                    \"tool_call_name\": tool_call_name,\n                    \"tool_response\": result,\n                }\n        yield self.create_text_message(result)\n\n    def _convert_tool_to_prompt_message_tool(\n        self, tool: ToolEntity\n    ) -> PromptMessageTool:\n        \"\"\"\n        convert tool to prompt message tool\n        \"\"\"\n        message_tool = PromptMessageTool(\n            name=tool.identity.name,\n            description=tool.description.llm if tool.description else \"\",\n            parameters={\n                \"type\": \"object\",\n                \"properties\": {},\n                \"required\": [],\n            },\n        )\n\n        parameters = tool.parameters\n        for parameter in parameters:\n            if parameter.form != ToolParameter.ToolParameterForm.LLM:\n                continue\n\n            parameter_type = parameter.type\n            if parameter.type in {\n                ToolParameter.ToolParameterType.FILE,\n                ToolParameter.ToolParameterType.FILES,\n            }:\n                continue\n            enum = []\n            if parameter.type == ToolParameter.ToolParameterType.SELECT:\n                enum = (\n                    [option.value for option in parameter.options]\n                    if parameter.options\n                    else []\n                )\n\n            message_tool.parameters[\"properties\"][parameter.name] = {\n                \"type\": parameter_type,\n                \"description\": parameter.llm_description or \"\",\n            }\n\n            if len(enum) > 0:\n                message_tool.parameters[\"properties\"][parameter.name][\"enum\"] = enum\n\n            if parameter.required:\n                message_tool.parameters[\"required\"].append(parameter.name)\n\n        return message_tool\n\n    def check_tool_calls(self, llm_result_chunk: LLMResultChunk) -> bool:\n        \"\"\"\n        Check if there is any tool call in llm result chunk\n        \"\"\"\n        return bool(llm_result_chunk.delta.message.tool_calls)\n\n    def extract_tool_calls(\n        self, llm_result_chunk: LLMResultChunk\n    ) -> list[tuple[str, str, dict[str, Any]]]:\n        \"\"\"\n        Extract tool calls from llm result chunk\n\n        Returns:\n            List[Tuple[str, str, Dict[str, Any]]]: [(tool_call_id, tool_call_name, tool_call_args)]\n        \"\"\"\n        tool_calls = []\n        for prompt_message in llm_result_chunk.delta.message.tool_calls:\n            args = {}\n            if prompt_message.function.arguments != \"\":\n                args = json.loads(prompt_message.function.arguments)\n\n            tool_calls.append(\n                (\n                    prompt_message.id,\n                    prompt_message.function.name,\n                    args,\n                )\n            )\n\n        return tool_calls\n\n​\n3. プラグインのデバッグ\n\nプラグインの設定ファイルと機能コードを記述したら、プラグインのディレクトリ内で python -m main コマンドを実行してプラグインを再起動します。次に、プラグインが正常に動作するかどうかをテストする必要があります。Difyのリモートデバッグ機能を利用するには、「プラグイン管理」にアクセスしてデバッグキーとリモートサーバーのアドレスを取得してください。\n\nプラグインプロジェクトに戻り、.env.example ファイルをコピーして .env にリネームします。そして、取得したリモートサーバーのアドレスとデバッグキーを、.envファイルの REMOTE_INSTALL_HOST および REMOTE_INSTALL_KEY パラメータにそれぞれ入力します。\n\nCopy\nINSTALL_METHOD=remote\nREMOTE_INSTALL_HOST=remote\nREMOTE_INSTALL_PORT=5003\nREMOTE_INSTALL_KEY=****-****-****-****-****\n\n\npython -m main コマンドを実行してプラグインを起動します。プラグインページで、プラグインがワークスペースにインストールされたことを確認できます。このプラグインは、他のチームメンバーも利用可能です。\n\n​\nプラグインのパッケージ化（オプション）\n\nプラグインが正常に動作することを確認したら、以下のコマンドラインツールを使用してプラグインをパッケージ化し、名前を付けることができます。実行後、現在のフォルダに google.difypkg ファイルが生成されます。これが最終的なプラグインパッケージです。\n\nCopy\ndify plugin package ./basic_agent/\n\n\nおめでとうございます！これで、ツールタイプのプラグインの開発、デバッグ、パッケージ化の全プロセスが完了しました。\n\n​\nプラグインの公開（オプション）\n\n作成したプラグインは、Dify Plugins コードリポジトリにアップロードして公開できます。アップロードする前に、プラグインがプラグイン公開規約に準拠していることをご確認ください。審査に合格すると、コードはメインブランチにマージされ、Dify Marketplaceに自動的に公開されます。\n\n​\nさらに詳しく\n\n複雑なタスクでは、複数回の思考とツール呼び出しが必要になることがよくあります。より高度なタスク処理を実現するために、通常は反復実行戦略が採用されます。つまり、「モデル呼び出し → ツール呼び出し」という流れを、タスクが完了するか、設定された最大反復回数に達するまで繰り返します。\n\nこのプロセスにおいて、プロンプト管理は非常に重要です。モデル入力を効率的に整理し、動的に調整するために、プラグイン内のFunction Calling機能の実装コードを参照し、標準化された方法でモデルが外部ツールを呼び出し、その結果を処理する方法を理解することを推奨します。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nカスタムモデルの組み込み\n拡張機能型プラグイン\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\n事前準備\n1. プラグインテンプレートの初期化\n2. プラグイン機能の開発\n2.1 パラメータの定義\n2.2 パラメータの取得と実行\n2.3 モデルの呼び出し\n2.4 モデルへのメモリ機能の追加\n2.5 ツールの呼び出し\n2.6 ログの作成\n3. プラグインのデバッグ\nプラグインのパッケージ化（オプション）\nプラグインの公開（オプション）\nさらに詳しく",
        "error": null
      },
      {
        "link_index": 23,
        "link_text": "拡張機能型プラグイン",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/quick-start/develop-plugins/extension-plugin",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nQuick start\nプラグインのインストールと利用方法\nプラグイン開発の入門\nDevelop plugins\n開発環境のセットアップ\nツールプラグイン\nモデル型プラグイン\nエージェント戦略プラグイン\n拡張機能型プラグイン\nバンドル\nプラグインのデバッグ方法\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nプラグイン開発の入門\n拡張機能型プラグイン\nCopy page\n\nこのドキュメントでは、Extensionタイプのプラグインを迅速に開発し、プラグイン開発の基本的な流れを理解するのに役立つように解説します。\n\n​\n事前準備\nDifyプラグインの足場ツール\nPython環境、バージョン番号 ≥ 3.12\n\nプラグイン開発の足場ツールの準備方法については、開発ツールの初期化を参照してください。\n\n​\n新規プロジェクトの作成 \n\n現在のパスで、足場コマンドラインツールを実行し、新しいDifyプラグインプロジェクトを作成します。\n\nCopy\n./dify-plugin-darwin-arm64 plugin init\n\n\nこのバイナリファイルをdifyにリネームし、/usr/local/binパスにコピーした場合、以下のコマンドを実行して新しいプラグインプロジェクトを作成できます。\n\nCopy\ndify plugin init\n\n​\nプラグイン情報の入力\n\n表示される指示に従って、プラグイン名、作者情報、プラグインの説明を設定してください。チームで共同作業する場合は、作者を組織名にすることも可能です。\n\nプラグイン名の長さは1〜128文字で、文字、数字、ダッシュ、アンダースコアのみを使用できます。\n\n入力が完了したら、プラグイン開発言語の選択でPythonを選択してください。\n\n​\n3. プラグインタイプの選択とプロジェクトテンプレートの初期化\n\n足場ツール内のすべてのテンプレートには、完全なコードプロジェクトが用意されています。このドキュメントでは、例としてExtensionタイプのプラグインテンプレートを使用します。プラグインに精通している開発者であれば、テンプレートを使用せずに、APIドキュメントを参照して様々なタイプのプラグイン開発を進めることができます。\n\n​\nプラグイン権限の設定\n\nプラグインがDifyメインプラットフォームに正常に接続するためには、Difyメインプラットフォームの権限を読み取る必要があります。このサンプルプラグインには、以下の権限を付与してください。\n\nツール\nLLM\nアプリ\n永続ストレージを有効にし、デフォルトサイズのストレージを割り当てる\nエンドポイントの登録を許可する\n\nターミナル内で方向キーを使って権限を選択し、「Tab」キーで権限を付与します。\n\nすべての権限項目をチェックした後、Enterキーを押してプラグインの作成を完了します。システムが自動的にプラグインのプロジェクトコードを生成します。\n\nプラグインの基本ファイル構造は以下の通りです。\n\nCopy\n.\n├── GUIDE.md\n├── README.md\n├── _assets\n│   └── icon.svg\n├── endpoints\n│   ├── your-project.py\n│   └── your-project.yaml\n├── group\n│   └── your-project.yaml\n├── main.py\n├── manifest.yaml\n└── requirements.txt\n\nGUIDE.md: プラグインの作成プロセスを説明する簡単なチュートリアルです。\nREADME.md: 現在のプラグインに関する情報です。このプラグインの概要や使用方法をこのファイルに記述する必要があります。\n_assets: 現在のプラグインに関連するすべてのマルチメディアファイルを保存します。\nendpoints: CLIのガイドに従って作成されるExtensionタイプのプラグインテンプレートです。このディレクトリには、すべてのエンドポイントの機能実装コードが格納されています。\ngroup: 秘密鍵のタイプ、多言語設定、API定義ファイルのパスを指定します。\nmain.py: プロジェクト全体のエントリポイントとなるファイルです。\nmanifest.yaml: プラグインの基本設定ファイルです。このプラグインに必要な権限、拡張機能の種類などの設定情報が含まれています。\nrequirements.txt: Python環境の依存関係を記述します。\n​\nプラグインの開発\n​\n1. プラグインのリクエストエンドポイントの定義\n\nendpoints/test_plugin.yamlを編集し、以下のコードを参考に変更してください。\n\nCopy\npath: \"/neko\"\nmethod: \"GET\"\nextra:\n  python:\n    source: \"endpoints/test_plugin.py\"\n\n\nこのコードは、プラグインのエントリパスを/neko、リクエストメソッドをGETタイプとして定義するものです。プラグインの機能実装コードは、endpoints/test_plugin.pyファイルに記述します。\n\n​\n2. プラグイン機能の作成\n\nプラグインの機能：プラグインサービスをリクエストし、猫の情報を出力します。\n\nプラグインの機能実装コードをendpoints/test_plugin.pyファイルに記述します。以下のサンプルコードを参考にしてください。\n\nCopy\nfrom typing import Mapping\nfrom werkzeug import Request, Response\nfrom flask import Flask, render_template_string\nfrom dify_plugin import Endpoint\n\napp = Flask(__name__)\n\nclass NekoEndpoint(Endpoint):\n    def _invoke(self, r: Request, values: Mapping, settings: Mapping) -> Response:\n        ascii_art = '''\n⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛⬛️⬜️⬜️⬜️⬜️⬜⬜️⬜️️\n🟥🟥⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️🟥🟥🟥🟥🟥🟥🟥🟥⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬛🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧⬛️⬜️⬜️⬜️⬜️⬜⬜️️\n🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥⬛️🥧🥧🥧💟💟💟💟💟💟💟💟💟💟💟💟💟🥧🥧🥧⬛️⬜️⬜️⬜️⬜⬜️️\n🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥🟥⬛️🥧🥧💟💟💟💟💟💟🍓💟💟🍓💟💟💟💟💟🥧🥧⬛️⬜️⬜️⬜️⬜️⬜️️\n🟧🟧🟥🟥🟥🟥🟥🟥🟥🟥🟧🟧🟧🟧🟧🟧🟧🟧🟥🟥🟥🟥🟥🟥🟥⬛🥧💟💟🍓💟💟💟💟💟💟💟💟💟💟💟💟💟💟🥧⬛️⬜️⬜️⬜️⬜⬜️️\n🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧⬛️🥧💟💟💟💟💟💟💟💟💟💟⬛️⬛️💟💟🍓💟💟🥧⬛️⬜️⬛️️⬛️️⬜⬜️️\n🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧🟧⬛️🥧💟💟💟💟💟💟💟💟💟⬛️🌫🌫⬛💟💟💟💟🥧⬛️⬛️🌫🌫⬛⬜️️\n🟨🟨🟧🟧🟧🟧🟧🟧🟧🟧🟨🟨🟨🟨🟨🟨🟨🟨🟧⬛️⬛️⬛️⬛️🟧🟧⬛️🥧💟💟💟💟💟💟🍓💟💟⬛️🌫🌫🌫⬛💟💟💟🥧⬛️🌫🌫🌫⬛⬜️️\n🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨⬛️🌫🌫⬛️⬛️🟧⬛️🥧💟💟💟💟💟💟💟💟💟⬛️🌫🌫🌫🌫⬛️⬛️⬛️⬛️🌫🌫🌫🌫⬛⬜️️\n🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨🟨⬛️⬛️🌫🌫⬛️⬛️⬛️🥧💟💟💟🍓💟💟💟💟💟⬛️🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫⬛⬜️️\n🟩🟩🟨🟨🟨🟨🟨🟨🟨🟨🟩🟩🟩🟩🟩🟩🟩🟩🟨🟨⬛⬛️🌫🌫⬛️⬛️🥧💟💟💟💟💟💟💟🍓⬛️🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫⬛️\n🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩⬛️⬛️🌫🌫⬛️🥧💟🍓💟💟💟💟💟💟⬛️🌫🌫🌫⬜️⬛️🌫🌫🌫🌫🌫⬜️⬛️🌫🌫⬛️\n️🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩🟩⬛️⬛️⬛️⬛️🥧💟💟💟💟💟💟💟💟⬛️🌫🌫🌫⬛️⬛️🌫🌫🌫⬛️🌫⬛️⬛️🌫🌫⬛️\n🟦🟦🟩🟩🟩🟩🟩🟩🟩🟩🟦🟦🟦🟦🟦🟦🟦🟦🟩🟩🟩🟩🟩🟩⬛️⬛️🥧💟💟💟💟💟🍓💟💟⬛🌫🟥🟥🌫🌫🌫🌫🌫🌫🌫🌫🌫🟥🟥⬛️\n🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦⬛️🥧🥧💟🍓💟💟💟💟💟⬛️🌫🟥🟥🌫⬛️🌫🌫⬛️🌫🌫⬛️🌫🟥🟥⬛️\n🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦🟦⬛️🥧🥧🥧💟💟💟💟💟💟💟⬛️🌫🌫🌫⬛️⬛️⬛️⬛️⬛️⬛️⬛️🌫🌫⬛️⬜️\n🟪🟪🟦🟦🟦🟦🟦🟦🟦🟦🟪🟪🟪🟪🟪🟪🟪🟪🟦🟦🟦🟦🟦🟦⬛️⬛️⬛️🥧🥧🥧🥧🥧🥧🥧🥧🥧🥧⬛️🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫⬛️⬜️⬜️\n🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪⬛️🌫🌫🌫⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬛️⬜️⬜️⬜️\n🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪🟪⬛️🌫🌫⬛️⬛️⬜️⬛️🌫🌫⬛️⬜️⬜️⬜️⬜️⬜️⬛️🌫🌫⬛️⬜️⬛️🌫🌫⬛️⬜️⬜️⬜️⬜️\n⬜️⬜️🟪🟪🟪🟪🟪🟪🟪🟪⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬜️🟪🟪🟪🟪🟪⬛️⬛️⬛️⬛⬜️⬜️⬛️⬛️⬛️⬜️⬜️⬜️⬜️⬜️⬜️⬜️⬛️⬛️⬛️⬜️⬜️⬛️⬛️⬜️⬜️⬜️⬜️⬜️️\n        '''\n        ascii_art_lines = ascii_art.strip().split('\\n')\n        with app.app_context():\n            return Response(render_template_string('''\n    <!DOCTYPE html>\n    <html>\n    <head>\n        <style>\n            body {\n                background-color: black;\n                color: white;\n                overflow: hidden;\n                margin: 0;\n                padding: 0;\n            }\n            #ascii-art {\n                font-family: monospace;\n                white-space: pre;\n                position: absolute;\n                top: 50%;\n                transform: translateY(-50%);\n                display: inline-block;\n                font-size: 16px;\n                line-height: 1;\n            }\n        </style>\n    </head>\n    <body>\n        <div id=\"ascii-art\"></div>\n        <script>\n            var asciiArtLines = {{ ascii_art_lines | tojson }};\n            var asciiArtDiv = document.getElementById(\"ascii-art\");\n            var index = 0;\n            function displayNextLine() {\n                if (index < asciiArtLines.length) {\n                    var line = asciiArtLines[index];\n                    var lineElement = document.createElement(\"div\");\n                    lineElement.innerHTML = line;\n                    asciiArtDiv.appendChild(lineElement);\n                    index++;\n                    setTimeout(displayNextLine, 100);\n                } else {\n                    animateCat();\n                }\n            }\n            function animateCat() {\n                var pos = 0;\n                var screenWidth = window.innerWidth;\n                var catWidth = asciiArtDiv.offsetWidth;\n                function move() {\n                    asciiArtDiv.style.left = pos + \"px\";\n                    pos += 2;\n                    if (pos > screenWidth) {\n                        pos = -catWidth;\n                    }\n                    requestAnimationFrame(move);\n                }\n                move();\n            }\n            displayNextLine();\n        </script>\n    </body>\n    </html>\n        ''', ascii_art_lines=ascii_art_lines), status=200, content_type=\"text/html\")\n\nExpand code\n\nこのコードを実行する前に、まず以下のPythonの依存パッケージをインストールする必要があります。\n\nCopy\npip install werkzeug\npip install flask\npip install dify-plugin\n\n​\nプラグインのデバッグ\n\n次に、プラグインが正常に動作するかどうかをテストします。Difyはリモートデバッグ機能を提供しており、「プラグイン管理」ページでデバッグキーとリモートサーバーのアドレスを取得できます。\n\nプラグインのプロジェクトに戻り、.env.exampleファイルをコピーして.envにリネームします。そして、取得したリモートサーバーのアドレスやデバッグキーなどの情報を.envファイルに記入してください。\n\n.envファイルの内容：\n\nCopy\nINSTALL_METHOD=remote\nREMOTE_INSTALL_HOST=remote\nREMOTE_INSTALL_PORT=5003\nREMOTE_INSTALL_KEY=****-****-****-****-****\n\n\npython -m mainコマンドを実行してプラグインを起動します。プラグインページで、このプラグインがワークスペースにインストールされたことを確認できます。他のチームメンバーもこのプラグインにアクセス可能です。\n\nプラグイン内に新しいエンドポイントを追加し、名前やapi_keyなどの情報を任意で入力します。自動生成されたURLにアクセスすると、プラグインが提供するウェブサービスが表示されます。\n\n​\nプラグインのパッケージ化\n\nプラグインが正常に動作することを確認したら、以下のコマンドラインツールを使用してプラグインをパッケージ化し、名前を付けることができます。実行後、現在のフォルダにneko.difypkgというファイルが生成されます。このファイルが最終的なプラグインパッケージです。\n\nCopy\ndify plugin package ./neko\n\n\nおめでとうございます！これで、プラグインの開発、テスト、パッケージ化の全工程が完了しました。\n\n​\nプラグインの公開\n\n作成したプラグインは、Dify Plugins コードリポジトリにアップロードして公開できます。アップロードする前に、プラグインがプラグイン公開仕様に準拠していることを確認してください。審査に合格すると、コードはメインブランチにマージされ、Dify Marketplaceに自動的に公開されます。\n\n​\nさらに詳しく\n\nクイックスタート：\n\nバンドルタイププラグイン：複数のプラグインをまとめる\nツールタイププラグイン：Google検索\nモデルタイププラグイン\n\nプラグインインターフェースドキュメント：\n\nマニフェスト構造\nエンドポイント詳細定義\nDify機能の逆呼び出し\nツール\nモデル\n拡張エージェント戦略\n\nベストプラクティス：\n\nSlack Botプラグインの開発\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nエージェント戦略プラグイン\nバンドル\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\n事前準備\n新規プロジェクトの作成\nプラグイン情報の入力\n3. プラグインタイプの選択とプロジェクトテンプレートの初期化\nプラグイン権限の設定\nプラグインの開発\n1. プラグインのリクエストエンドポイントの定義\n2. プラグイン機能の作成\nプラグインのデバッグ\nプラグインのパッケージ化\nプラグインの公開\nさらに詳しく",
        "error": null
      },
      {
        "link_index": 24,
        "link_text": "バンドル",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/quick-start/develop-plugins/bundle",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nQuick start\nプラグインのインストールと利用方法\nプラグイン開発の入門\nDevelop plugins\n開発環境のセットアップ\nツールプラグイン\nモデル型プラグイン\nエージェント戦略プラグイン\n拡張機能型プラグイン\nバンドル\nプラグインのデバッグ方法\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nプラグイン開発の入門\nバンドル\nCopy page\n\nバンドルプラグインパッケージは、複数のプラグインをまとめたものです。複数のプラグインを一つのパッケージにまとめることで、プラグインの一括インストールを可能にし、より高度な機能を提供します。\n\nDify CLIツールを使用すると、複数のプラグインをバンドルとしてパッケージ化できます。バンドルプラグインパッケージには、以下の3つのタイプがあります。\n\nMarketplace タイプ：プラグインのIDとバージョン情報を保持します。インポート時には、Dify Marketplaceから該当するプラグインパッケージをダウンロードします。\nGitHub タイプ：GitHubリポジトリのアドレス、リリースバージョン番号、アセットファイル名を保持します。インポート時に、Difyは該当するGitHubリポジトリにアクセスしてプラグインパッケージをダウンロードします。\nPackage タイプ：プラグインパッケージをバンドル内に直接格納します。参照元は保持されませんが、バンドルパッケージのサイズが大きくなる可能性があります。\n​\n事前準備\nDifyプラグインのひな形ツール\nPython環境（バージョン3.11以上）\n\nプラグイン開発のひな形ツールを準備する方法の詳細については、「開発ツールの初期化」を参照してください。\n\n​\nバンドルプロジェクトの作成\n\n現在のディレクトリで、ひな形コマンドラインツールを実行し、新しいプラグインパッケージプロジェクトを作成します。\n\nCopy\n./dify-plugin-darwin-arm64 bundle init\n\n\nこのバイナリファイルを dify にリネームし、/usr/local/bin ディレクトリにコピーした場合、次のコマンドを実行して新しいプラグインプロジェクトを作成できます。\n\nCopy\ndify bundle init\n\n​\n1. プラグイン情報の入力\n\nプロンプトに従って、プラグイン名、作成者情報、プラグインの説明を設定します。チームで共同作業している場合は、作成者に組織名を記入することもできます。\n\n名前は1〜128文字で、文字、数字、ダッシュ、アンダースコアのみを使用できます。\n\n情報を入力してEnterキーを押すと、バンドルプラグインプロジェクトのディレクトリが自動的に作成されます。\n\n​\n2. 依存関係の追加\nマーケットプレイス(Marketplace)\n\n次のコマンドを実行します。\n\nCopy\ndify-plugin bundle append marketplace . --marketplace_pattern=langgenius/openai:0.0.1\n\n\nここで、marketplace_pattern は、Marketplaceでのプラグインの参照であり、形式は 組織名/プラグイン名:バージョン番号 です。\n\nGithub\n\n次のコマンドを実行します。\n\nCopy\ndify-plugin bundle append github . --repo_pattern=langgenius/openai:0.0.1/openai.difypkg\n\n\nここで、repo_pattern は、GitHubでのプラグインの参照であり、形式は 組織名/リポジトリ名:リリース/添付ファイル名 です。\n\nパッケージ(package)\n\n次のコマンドを実行します。\n\nCopy\ndify-plugin bundle append package . --package_path=./openai.difypkg\n\n\nここで、package_path は、プラグインパッケージのディレクトリです。\n\n​\nバンドルプロジェクトのパッケージ化\n\n次のコマンドを実行して、バンドルプラグインをパッケージ化します。\n\nCopy\ndify-plugin bundle package ./bundle\n\n\nコマンドを実行すると、現在のディレクトリに bundle.difybndl ファイルが自動的に作成されます。このファイルが最終的なパッケージ結果です。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\n拡張機能型プラグイン\nプラグインのデバッグ方法\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\n事前準備\nバンドルプロジェクトの作成\n1. プラグイン情報の入力\n2. 依存関係の追加\nバンドルプロジェクトのパッケージ化",
        "error": null
      },
      {
        "link_index": 25,
        "link_text": "プラグインのデバッグ方法",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/quick-start/debug-plugin",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nQuick start\nプラグインのインストールと利用方法\nプラグイン開発の入門\nプラグインのデバッグ方法\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nクイックスタート\nプラグインのデバッグ方法\nCopy page\n\nプラグインの開発が完了したら、次は正常に動作するかどうかをテストしましょう。Difyはリモートデバッグ機能を提供しており、「プラグイン管理」ページでデバッグキーとリモートサーバーアドレスを取得できます。\n\nリモートサーバーのアドレスとデバッグキーは、「プラグイン管理」ページにアクセスすることで取得できます。\n\nプラグインのプロジェクトに戻り、.env.exampleファイルをコピーして.envにリネームします。そして、取得したリモートサーバーアドレスやデバッグキーなどの情報を入力してください。\n\n.envファイル\n\nCopy\nINSTALL_METHOD=remote\nREMOTE_INSTALL_HOST=remote\nREMOTE_INSTALL_PORT=5003\nREMOTE_INSTALL_KEY=****-****-****-****-****\n\n\npython -m mainコマンドを実行してプラグインを起動します。プラグインページで、Workspaceにインストールされたことを確認できます。他のチームメンバーもこのプラグインを利用可能です。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nバンドル\nプラグイン管理方法\nx\ngithub\nlinkedin\nPowered by Mintlify",
        "error": null
      },
      {
        "link_index": 26,
        "link_text": "プラグイン管理方法",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/manage-plugins",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nプラグイン\nプラグイン管理方法\nCopy page\n\nこのガイドは、ワークスペースの所有者や管理者向けに、プラグインの権限を設定し、管理する方法を詳しく説明します。プラグインの権限を管理することで、どのユーザーがプラグインに関連する操作を行えるかを定めることができます。\n\n​\nプラグイン権限の設定\n\nチームの所有者や管理者は、Difyプラットフォームのホームページ右上にある 「プラグイン」 ページから、次のプラグイン権限を設定できます：\n\nプラグインのインストールと管理\n\nこの権限により、誰がプラグインをインストールや管理できるかを決めます。オプションには以下があります：\n\nEveryone（全員）: ワークスペース内の全てのユーザーがプラグインをインストールや管理できる\nAdmins（管理者）: ワークスペースの管理者だけがプラグインをインストールや管理できる\nNo one（無人）: 誰もプラグインをインストールや管理できない\n\nプラグインのデバッグの権限\n\nこの権限により、誰がプラグインのデバッグを行えるかを決めます。オプションには以下があります：\n\nEveryone（全員）: ワークスペース内の全てのユーザーがプラグインをデバッグできる\nAdmins（管理者）: ワークスペースの管理者だけがプラグインをデバッグできる\nNo one（無人）: 誰もプラグインをデバッグできない\n​\nプラグインの更新\n\nDifyプラットフォームの右上にある「プラグイン」ボタンをクリックし、更新が必要なプラグインを選択。その後、プラグインタイトルの隣にある 「アップグレード」 ボタンをクリックしてください。\n\n​\nプラグインの削除方法\n\nDifyプラットフォームの右上にある「プラグイン」ボタンをクリックし、現在ワークスペースにインストールされているプラグイン一覧を表示します。プラグインの詳細ページで、「削除」アイコンまたは「削除」ボタンをクリックして、プラグインを削除してください。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nプラグインのデバッグ方法\nSchema definition\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nプラグイン権限の設定\nプラグインの更新\nプラグインの削除方法",
        "error": null
      },
      {
        "link_index": 27,
        "link_text": "よくある質問",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/faq",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nプラグイン\nよくある質問\nCopy page\n​\nプラグインのインストール時にアップロードが失敗する場合の対処方法は？\n\nエラー詳細：PluginDaemonBadRequestError: plugin_unique_identifier is not valid というエラーメッセージが表示されます。\n\n解決方法：プラグインプロジェクトの manifest.yaml ファイルと /provider パス配下の .yaml ファイルの author フィールドを GitHub ID に変更してください。\n\nプラグインのパッケージングコマンドを再実行し、新しいプラグインパッケージをインストールしてください。\n\n​\nプラグインインストール時のエラーの対処方法\n\n問題: plugin verification has been enabled, and the plugin you want to install has a bad signature というエラーメッセージが表示された場合、どのように対処すればよいですか？\n\n解決方法: /docker/.env 設定ファイルの末尾に以下の行を追加してください：\nFORCE_VERIFYING_SIGNATURE=false.\n\nDify サービスを再起動するには、以下のコマンドを実行してください：\n\nCopy\ncd docker\ndocker compose down\ndocker compose up -d\n\n\nこのフィールドを追加すると、Dify プラットフォームは Dify Marketplace にリストされていない（つまり、未検証の）すべてのプラグインのインストールを許可します。\n\nただし、安全性を考慮して、未知のソースから提供されるプラグインは、テスト環境またはサンドボックス環境でまずインストールし、安全性を確認した後、本番環境にデプロイしてください。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\n第三者署名検証のためにプラグインに署名する\nSandbox\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nプラグインのインストール時にアップロードが失敗する場合の対処方法は？\nプラグインインストール時のエラーの対処方法",
        "error": null
      },
      {
        "link_index": 28,
        "link_text": "ライセンス",
        "target_url": "https://docs.dify.ai/ja-jp/policies/open-source",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nポリシー\nライセンス\nCopy page\n\nDifyのコミュニティエディションは、追加条件付きのApache 2.0ベースのライセンスの下でオープンソース化されています。詳細についてはLICENSEファイルをご参照ください。\n\nライセンスに関する質問や問題がございましたら、business@dify.aiまでお問い合わせください。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nプラグイン\nAgreement\nx\ngithub\nlinkedin\nPowered by Mintlify",
        "error": null
      },
      {
        "link_index": 29,
        "link_text": "​",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/quick-start/develop-plugins/model-plugin/README#%E3%83%A2%E3%83%87%E3%83%AB%E3%83%97%E3%83%A9%E3%82%B0%E3%82%A4%E3%83%B3%E3%81%AE%E6%A7%8B%E9%80%A0",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nTermbase\nモデルプラグイン\nCopy page\n\nモデルタイププラグインを導入することで、Difyプラットフォームは特定のモデルプロバイダーが提供するモデルを利用できるようになります。例えば、OpenAIモデルプラグインをインストールすると、DifyプラットフォームからOpenAIのGPT-4やGPT-4o-2024-05-13といったモデルをリクエストできるようになります。\n\n​\nモデルプラグインの構造\n\nプラグインモデルの開発に関する理解を深めるために、モデルタイププラグインの構造例を以下に示します。\n\nモデルプロバイダー：OpenAI、Anthropic、Googleなどの大規模モデル開発企業です。\nモデルカテゴリ：プロバイダーに応じて、大規模言語モデル（LLM）、テキスト埋め込みモデル、音声テキスト変換モデルなどがあります。\n具体的なモデル：claude-3-5-sonnet、gpt-4-turboなど。\n\nプラグインプロジェクトのコード構造：\n\nCopy\n- モデルプロバイダー\n  - モデルカテゴリ\n    - 具体的なモデル\n\n\nAnthropicを例にとると、モデルプラグインの構造は次のようになります。\n\nCopy\n- Anthropic\n  - llm\n    claude-3-5-sonnet-20240620\n    claude-3-haiku-20240307\n    claude-3-opus-20240229\n    claude-3-sonnet-20240229\n    claude-instant-1.2\n    claude-instant-1\n\n\nOpenAIを例にとると、複数のモデルタイプをサポートしています。\n\nCopy\n├── models\n│ ├── llm\n│ │ ├── chatgpt-4o-latest\n│ │ ├── gpt-3.5-turbo\n│ │ ├── gpt-4-0125-preview\n│ │ ├── gpt-4-turbo\n│ │ ├── gpt-4o\n│ │ ├── llm\n│ │ ├── o1-preview\n│ │ └── text-davinci-003\n│ ├── moderation\n│ │ ├── moderation\n│ │ └── text-moderation-stable\n│ ├── speech2text\n│ │ ├── speech2text\n│ │ └── whisper-1\n│ ├── text_embedding\n│ │ ├── text-embedding-3-large\n│ │ └── text_embedding\n│ └── tts\n│ ├── tts-1-hd\n│ ├── tts-1\n│ └── tts\n\n​\nモデルプラグイン作成の準備\n\nモデルプラグインを作成するには、以下の手順に従ってください。具体的な作成ガイドは、各ドキュメントのタイトルをクリックして参照してください。\n\nモデルプロバイダーの作成\n事前定義済みモデル、またはカスタムモデルの統合\nモデルプラグインのデバッグ\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nモデルプラグインの構造\nモデルプラグイン作成の準備",
        "error": null
      },
      {
        "link_index": 30,
        "link_text": "​",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/quick-start/develop-plugins/model-plugin/README#%E3%83%A2%E3%83%87%E3%83%AB%E3%83%97%E3%83%A9%E3%82%B0%E3%82%A4%E3%83%B3%E4%BD%9C%E6%88%90%E3%81%AE%E6%BA%96%E5%82%99",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nTermbase\nモデルプラグイン\nCopy page\n\nモデルタイププラグインを導入することで、Difyプラットフォームは特定のモデルプロバイダーが提供するモデルを利用できるようになります。例えば、OpenAIモデルプラグインをインストールすると、DifyプラットフォームからOpenAIのGPT-4やGPT-4o-2024-05-13といったモデルをリクエストできるようになります。\n\n​\nモデルプラグインの構造\n\nプラグインモデルの開発に関する理解を深めるために、モデルタイププラグインの構造例を以下に示します。\n\nモデルプロバイダー：OpenAI、Anthropic、Googleなどの大規模モデル開発企業です。\nモデルカテゴリ：プロバイダーに応じて、大規模言語モデル（LLM）、テキスト埋め込みモデル、音声テキスト変換モデルなどがあります。\n具体的なモデル：claude-3-5-sonnet、gpt-4-turboなど。\n\nプラグインプロジェクトのコード構造：\n\nCopy\n- モデルプロバイダー\n  - モデルカテゴリ\n    - 具体的なモデル\n\n\nAnthropicを例にとると、モデルプラグインの構造は次のようになります。\n\nCopy\n- Anthropic\n  - llm\n    claude-3-5-sonnet-20240620\n    claude-3-haiku-20240307\n    claude-3-opus-20240229\n    claude-3-sonnet-20240229\n    claude-instant-1.2\n    claude-instant-1\n\n\nOpenAIを例にとると、複数のモデルタイプをサポートしています。\n\nCopy\n├── models\n│ ├── llm\n│ │ ├── chatgpt-4o-latest\n│ │ ├── gpt-3.5-turbo\n│ │ ├── gpt-4-0125-preview\n│ │ ├── gpt-4-turbo\n│ │ ├── gpt-4o\n│ │ ├── llm\n│ │ ├── o1-preview\n│ │ └── text-davinci-003\n│ ├── moderation\n│ │ ├── moderation\n│ │ └── text-moderation-stable\n│ ├── speech2text\n│ │ ├── speech2text\n│ │ └── whisper-1\n│ ├── text_embedding\n│ │ ├── text-embedding-3-large\n│ │ └── text_embedding\n│ └── tts\n│ ├── tts-1-hd\n│ ├── tts-1\n│ └── tts\n\n​\nモデルプラグイン作成の準備\n\nモデルプラグインを作成するには、以下の手順に従ってください。具体的な作成ガイドは、各ドキュメントのタイトルをクリックして参照してください。\n\nモデルプロバイダーの作成\n事前定義済みモデル、またはカスタムモデルの統合\nモデルプラグインのデバッグ\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nモデルプラグインの構造\nモデルプラグイン作成の準備",
        "error": null
      },
      {
        "link_index": 32,
        "link_text": "事前定義済み",
        "target_url": "https://docs.dify.ai/ja-jp/guides/model-configuration/predefined-model",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nModel configuration\n新しいプロバイダーの追加\n事前定義されたモデルの追加\nカスタムモデルの追加\nインターフェース方法\n設定ルール\n負荷分散\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nモデル\n事前定義されたモデルの追加\nCopy page\n\nプロバイダー統合完了後、次にプロバイダーへのモデルの接続を行います。\n\nまず、接続するモデルのタイプを決定し、対応するプロバイダーのディレクトリ内に対応するモデルタイプのmoduleを作成する必要があります。\n\n現在サポートされているモデルタイプは以下の通りです：\n\nLLM テキスト生成モデル\ntext_embedding テキスト埋め込みモデル\nrerank ランク付けモデル\nspeech2text 音声からテキストへの変換モデル\nTTS テキストから音声への変換モデル\nmoderation 審査\n\nここではAnthropicを例に挙げると、AnthropicはLLMのみをサポートしているため、model_providers.anthropicにllmという名前のmoduleを作成します。\n\n事前に定義されたモデルについては、llm module の下に、モデル名をファイル名とするYAMLファイルを作成する必要があります、例えば、claude-2.1.yaml。\n\n​\nモデルのYAMLファイルのサンプル\nCopy\nmodel: claude-2.1  # モデル識別子\n# モデル表示名。en_US英語、zh_Hans中国語の二つの言語を設定できます。zh_Hansが設定されていない場合、デフォルトでen_USが使用されます。\n# ラベルを設定しない場合、モデル識別子が使用されます。\nlabel:\n  en_US: claude-2.1\nmodel_type: llm  # モデルタイプ、claude-2.1はLLMです\nfeatures:  # サポートする機能、agent-thoughtはエージェント推論、visionは画像理解をサポート\n- agent-thought\nmodel_properties:  # モデルプロパティ\n  mode: chat  # LLMモード、completeはテキスト補完モデル、chatは対話モデル\n  context_size: 200000  # 最大コンテキストサイズ\nparameter_rules:  # モデル呼び出しパラメータルール、LLMのみ提供が必要\n- name: temperature  # 呼び出しパラメータ変数名\n  # デフォルトで5つの変数内容設定テンプレートが用意されています。temperature/top_p/max_tokens/presence_penalty/frequency_penalty\n  # use_template内でテンプレート変数名を設定すると、entities.defaults.PARAMETER_RULE_TEMPLATE内のデフォルト設定が使用されます\n  # 追加の設定パラメータを設定した場合、デフォルト設定を上書きします\n  use_template: temperature\n- name: top_p\n  use_template: top_p\n- name: top_k\n  label:  # 呼び出しパラメータ表示名\n    zh_Hans: 取样数量\n    en_US: Top k\n  type: int  # パラメータタイプ、float/int/string/booleanがサポートされています\n  help:  # ヘルプ情報、パラメータの作用を説明\n    zh_Hans: 仅从每个后续标记的前 K 个选项中采样。\n    en_US: Only sample from the top K options for each subsequent token.\n  required: false  # 必須かどうか、設定しない場合もあります\n- name: max_tokens_to_sample\n  use_template: max_tokens\n  default: 4096  # パラメータデフォルト値\n  min: 1  # パラメータ最小値、float/intのみ使用可能\n  max: 4096  # パラメータ最大値、float/intのみ使用可能\npricing:  # 価格情報\n  input: '8.00'  # 入力単価、つまりプロンプト単価\n  output: '24.00'  # 出力単価、つまり返答内容単価\n  unit: '0.000001'  # 価格単位、上記価格は100Kあたりの単価\n  currency: USD  # 価格通貨\n\n\nすべてのモデル構成が完了した後に、モデルコードの実装を開始することをお勧めします。\n\n同様に、model_providersディレクトリ内の他のサプライヤーの対応するモデル タイプ ディレクトリにあるYAML構成情報を参照することもできます。全てのYAMLルールについては、「Schema1」をご覧ください。\n\n​\nモデル呼び出しコードの実装\n\n次に、llm module内に同名のPythonファイルllm.pyを作成し、コード実装を行います。\n\nllm.py内にAnthropic LLMクラスを作成し、AnthropicLargeLanguageModel(任意な名前)という名前を付けます。このクラスは__base.large_language_model.LargeLanguageModel基底クラスを継承し、以下のメソッドを実装します：\n\nLLM呼び出し\n\nLLM呼び出しの中核メソッドを実装し、ストリーミングと同期返り値の両方をサポートするメソッドを実装します。\n\nCopy\ndef _invoke(self, model: str, credentials: dict,\n            prompt_messages: list[PromptMessage], model_parameters: dict,\n            tools: Optional[list[PromptMessageTool]] = None, stop: Optional[List[str]] = None,\n            stream: bool = True, user: Optional[str] = None) \\\n        -> Union[LLMResult, Generator]:\n    \"\"\"\n    Invoke large language model\n\n    :param model: model name\n    :param credentials: model credentials\n    :param prompt_messages: prompt messages\n    :param model_parameters: model parameters\n    :param tools: tools for tool calling\n    :param stop: stop words\n    :param stream: is stream response\n    :param user: unique user id\n    :return: full response or stream response chunk generator result\n    \"\"\"\n\n\n実装時には、同期返答とストリーミング返答を処理するために2つの関数を使用する必要があります。Pythonはyieldキーワードを含む関数をジェネレータ関数として認識し、返されるデータタイプが固定されるため、同期返答とストリーミング返答を別々に実装する必要があります。以下のように（以下の例では簡略化されたパラメータを使用していますが、実際の実装では上記のパラメータリストに従う必要があります）：\n\nCopy\ndef _invoke(self, stream: bool, **kwargs) \\\n        -> Union[LLMResult, Generator]:\n    if stream:\n          return self._handle_stream_response(**kwargs)\n    return self._handle_sync_response(**kwargs)\n\ndef _handle_stream_response(self, **kwargs) -> Generator:\n    for chunk in response:\n          yield chunk\ndef _handle_sync_response(self, **kwargs) -> LLMResult:\n    return LLMResult(**response)\n\n\n事前計算入力トークン\n\nモデルが事前計算トークンインターフェースを提供していない場合は、0を返しても構いません。\n\nCopy\ndef get_num_tokens(self, model: str, credentials: dict, prompt_messages: list[PromptMessage],\n                   tools: Optional[list[PromptMessageTool]] = None) -> int:\n    \"\"\"\n    Get number of tokens for given prompt messages\n\n    :param model: model name\n    :param credentials: model credentials\n    :param prompt_messages: prompt messages\n    :param tools: tools for tool calling\n    :return:\n    \"\"\"\n\n\nモデル認証情報検証\n\nプロバイダーの認証情報検証と同様に、ここでは個別のモデルに対して検証を行います。\n\nCopy\ndef validate_credentials(self, model: str, credentials: dict) -> None:\n    \"\"\"\n    Validate model credentials\n\n    :param model: model name\n    :param credentials: model credentials\n    :return:\n    \"\"\"\n\n\n呼び出し異常エラーのマッピングテーブル\n\nモデル呼び出し異常時に、Runtime時に指定のInvokeErrorタイプにマッピングする必要があります。これにより、Difyは異なるエラーに対して異なる後続処理を行うことができます。\n\nランタイムエラー(Runtime Errors)：\n\nInvokeConnectionError 呼び出し接続エラー\nInvokeServerUnavailableError 呼び出しサーバー利用不可エラー\nInvokeRateLimitError 呼び出しレート制限エラー\nInvokeAuthorizationError 認証エラー\nInvokeBadRequestError 呼び出し不正リクエストエラー\nCopy\n@property\ndef _invoke_error_mapping(self) -> dict[type[InvokeError], list[type[Exception]]]:\n    \"\"\"\n    Map model invoke error to unified error\n    The key is the error type thrown to the caller\n    The value is the error type thrown by the model,\n    which needs to be converted into a unified error type for the caller.\n\n    :return: Invoke error mapping\n    \"\"\"\n\n\nインターフェースメソッドの説明については：Interfacesをご覧ください。具体的な実装については：llm.pyを参照してください。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nFootnotes\n\nWas this page helpful?\n\nYes\nNo\n新しいプロバイダーの追加\nカスタムモデルの追加\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nモデルのYAMLファイルのサンプル\nモデル呼び出しコードの実装",
        "error": null
      },
      {
        "link_index": 33,
        "link_text": "カスタム",
        "target_url": "https://docs.dify.ai/ja-jp/guides/model-configuration/customizable-model",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nModel configuration\n新しいプロバイダーの追加\n事前定義されたモデルの追加\nカスタムモデルの追加\nインターフェース方法\n設定ルール\n負荷分散\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nモデル\nカスタムモデルの追加\nCopy page\n​\nイントロダクション\n\nベンダー統合が完了した後、次にベンダーの下でモデルのインテグレーションを行います。ここでは、全体のプロセスを理解するために、例としてXinferenceを使用して、段階的にベンダーのインテグレーションを完了します。\n\n注意が必要なのは、カスタムモデルの場合、各モデルのインテグレーションには完全なベンダークレデンシャルの記入が必要です。\n\n事前定義モデルとは異なり、カスタムベンダーのインテグレーション時には常に以下の2つのパラメータが存在し、ベンダー yaml に定義する必要はありません。\n\n前述したように、ベンダーはvalidate_provider_credentialを実装する必要はなく、Runtimeがユーザーが選択したモデルタイプとモデル名に基づいて、対応するモデル層のvalidate_credentialsを呼び出して検証を行います。\n\n​\nベンダー yaml の作成\n\nまず、インテグレーションを行うベンダーがどのタイプのモデルをサポートしているかを確認します。\n\n現在サポートされているモデルタイプは以下の通りです：\n\nllm テキスト生成モデル\ntext_embedding テキスト Embedding モデル\nrerank Rerank モデル\nspeech2text 音声からテキスト変換\ntts テキストから音声変換\nmoderation モデレーション\n\nXinferenceはLLM、Text Embedding、Rerankをサポートしているため、xinference.yamlを作成します。\n\nCopy\nprovider: xinference # Specify vendor identifier\nlabel: # Vendor display name, can be set in en_US (English) and zh_Hans (Simplified Chinese). If zh_Hans is not set, en_US will be used by default.\n  en_US: Xorbits Inference\nicon_small: # Small icon, refer to other vendors' icons, stored in the _assets directory under the corresponding vendor implementation directory. Language strategy is the same as label.\n  en_US: icon_s_en.svg\nicon_large: # Large icon\n  en_US: icon_l_en.svg\nhelp: # Help\n  title:\n    en_US: How to deploy Xinference\n    zh_Hans: 如何部署 Xinference\n  url:\n    en_US: https://github.com/xorbitsai/inference\nsupported_model_types: # Supported model types. Xinference supports LLM/Text Embedding/Rerank\n- llm\n- text-embedding\n- rerank\nconfigurate_methods: # Since Xinference is a locally deployed vendor and does not have predefined models, you need to deploy the required models according to Xinference's documentation. Therefore, only custom models are supported here.\n- customizable-model\nprovider_credential_schema:\n  credential_form_schemas:\n\n\nその後、Xinferenceでモデルを定義するために必要なクレデンシャルを考えます。\n\n3つの異なるモデルをサポートするため、model_typeを使用してこのモデルのタイプを指定する必要があります。3つのタイプがあるので、次のように記述します。\nCopy\nprovider_credential_schema:\n  credential_form_schemas:\n  - variable: model_type\n    type: select\n    label:\n      en_US: Model type\n      zh_Hans: 模型类型\n    required: true\n    options:\n    - value: text-generation\n      label:\n        en_US: Language Model\n        zh_Hans: 言語モデル\n    - value: embeddings\n      label:\n        en_US: Text Embedding\n    - value: reranking\n      label:\n        en_US: Rerank\n\n各モデルには独自の名称model_nameがあるため、ここで定義する必要があります。\nCopy\n  - variable: model_name\n    type: text-input\n    label:\n      en_US: Model name\n      zh_Hans: 模型名称\n    required: true\n    placeholder:\n      zh_Hans: 填写模型名称\n      en_US: Input model name\n\nXinferenceのローカルデプロイのアドレスを記入します。\nCopy\n  - variable: server_url\n    label:\n      zh_Hans: 服务器URL\n      en_US: Server url\n    type: text-input\n    required: true\n    placeholder:\n      zh_Hans: 在此输入Xinference的服务器地址，如 https://example.com/xxx\n      en_US: Enter the url of your Xinference, for example https://example.com/xxx\n\n各モデルには一意の model_uid があるため、ここで定義する必要があります。\nCopy\n  - variable: model_uid\n    label:\n      zh_Hans: 模型 UID\n      en_US: Model uid\n    type: text-input\n    required: true\n    placeholder:\n      zh_Hans: 在此输入你的 Model UID\n      en_US: Enter the model uid\n\n\nこれで、ベンダーの基本定義が完了しました。\n\n​\nモデルコードの作成\n\n次に、llmタイプを例にとって、xinference.llm.llm.pyを作成します。\n\nllm.py内で、Xinference LLM クラスを作成し、XinferenceAILargeLanguageModel（任意の名前）と名付けて、__base.large_language_model.LargeLanguageModel基底クラスを継承し、以下のメソッドを実装します：\n\nLLM 呼び出し\n\nLLM 呼び出しのコアメソッドを実装し、ストリームレスポンスと同期レスポンスの両方をサポートします。\n\nCopy\ndef _invoke(self, model: str, credentials: dict,\n            prompt_messages: list[PromptMessage], model_parameters: dict,\n            tools: Optional[list[PromptMessageTool]] = None, stop: Optional[List[str]] = None,\n            stream: bool = True, user: Optional[str] = None) \\\n        -> Union[LLMResult, Generator]:\n    \"\"\"\n    Invoke large language model\n\n    :param model: model name\n    :param credentials: model credentials\n    :param prompt_messages: prompt messages\n    :param model_parameters: model parameters\n    :param tools: tools for tool calling\n    :param stop: stop words\n    :param stream: is stream response\n    :param user: unique user id\n    :return: full response or stream response chunk generator result\n    \"\"\"\n\n\n実装時には、同期レスポンスとストリームレスポンスを処理するために2つの関数を使用してデータを返す必要があります。Pythonはyieldキーワードを含む関数をジェネレータ関数として認識し、返されるデータ型は固定でジェネレーターになります。そのため、同期レスポンスとストリームレスポンスは別々に実装する必要があります。以下のように実装します（例では簡略化されたパラメータを使用していますが、実際の実装では上記のパラメータリストに従って実装してください）：\n\nCopy\ndef _invoke(self, stream: bool, **kwargs) \\\n        -> Union[LLMResult, Generator]:\n    if stream:\n          return self._handle_stream_response(**kwargs)\n    return self._handle_sync_response(**kwargs)\n\ndef _handle_stream_response(self, **kwargs) -> Generator:\n    for chunk in response:\n          yield chunk\ndef _handle_sync_response(self, **kwargs) -> LLMResult:\n    return LLMResult(**response)\n\n\n予測トークン数の計算\n\nモデルが予測トークン数の計算インターフェースを提供していない場合、直接0を返すことができます。\n\nCopy\ndef get_num_tokens(self, model: str, credentials: dict, prompt_messages: list[PromptMessage],\n                 tools: Optional[list[PromptMessageTool]] = None) -> int:\n  \"\"\"\n  Get number of tokens for given prompt messages\n\n  :param model: model name\n  :param credentials: model credentials\n  :param prompt_messages: prompt messages\n  :param tools: tools for tool calling\n  :return:\n  \"\"\"\n\n\n時には、直接0を返す必要がない場合もあります。その場合はself._get_num_tokens_by_gpt2(text: str)を使用して予測トークン数を取得することができます。このメソッドはAIModel基底クラスにあり、GPT2のTokenizerを使用して計算を行いますが、代替方法として使用されるものであり、完全に正確ではありません。\n\nモデルクレデンシャル検証\n\nベンダークレデンシャル検証と同様に、ここでは個々のモデルについて検証を行います。\n\nCopy\ndef validate_credentials(self, model: str, credentials: dict) -> None:\n    \"\"\"\n    Validate model credentials\n\n    :param model: model name\n    :param credentials: model credentials\n    :return:\n    \"\"\"\n\n\nモデルパラメータスキーマ\n\nカスタムタイプとは異なり、yamlファイルでモデルがサポートするパラメータを定義していないため、動的にモデルパラメータのスキーマを生成する必要があります。\n\n例えば、Xinferenceはmax_tokens、temperature、top_pの3つのモデルパラメータをサポートしています。\n\nしかし、ベンダーによっては異なるモデルに対して異なるパラメータをサポートしている場合があります。例えば、ベンダーOpenLLMはtop_kをサポートしていますが、全てのモデルがtop_kをサポートしているわけではありません。ここでは、例としてAモデルがtop_kをサポートし、Bモデルがtop_kをサポートしていない場合、以下のように動的にモデルパラメータのスキーマを生成します：\n\nCopy\ndef get_customizable_model_schema(self, model: str, credentials: dict) -> AIModelEntity | None:\n    \"\"\"\n        used to define customizable model schema\n    \"\"\"\n    rules = [\n        ParameterRule(\n            name='temperature', type=ParameterType.FLOAT,\n            use_template='temperature',\n            label=I18nObject(\n                zh_Hans='温度', en_US='Temperature'\n            )\n        ),\n        ParameterRule(\n            name='top_p', type=ParameterType.FLOAT,\n            use_template='top_p',\n            label=I18nObject(\n                zh_Hans='Top P', en_US='Top P'\n            )\n        ),\n        ParameterRule(\n            name='max_tokens', type=ParameterType.INT,\n            use_template='max_tokens',\n            min=1,\n            default=512,\n            label=I18nObject(\n                zh_Hans='最大生成长度', en_US='Max Tokens'\n            )\n        )\n    ]\n\n    # if model is A, add top_k to rules\n    if model == 'A':\n        rules.append(\n            ParameterRule(\n                name='top_k', type=ParameterType.INT,\n                use_template='top_k',\n                min=1,\n                default=50,\n                label=I18nObject(\n                    zh_Hans='Top K', en_US='Top K'\n                )\n            )\n        )\n\n    \"\"\"\n        some NOT IMPORTANT code here\n    \"\"\"\n\n    entity = AIModelEntity(\n        model=model,\n        label=I18nObject(\n            en_US=model\n        ),\n        fetch_from=FetchFrom.CUSTOMIZABLE_MODEL,\n        model_type=model_type,\n        model_properties={ \n            ModelPropertyKey.MODE:  ModelType.LLM,\n        },\n        parameter_rules=rules\n    )\n\n    return entity\n\n\n呼び出しエラーマッピングテーブル\n\nモデル呼び出し時にエラーが発生した場合、Runtimeが指定するInvokeErrorタイプにマッピングする必要があります。これにより、Difyは異なるエラーに対して異なる後続処理を行うことができます。\n\nRuntime Errors：\n\nInvokeConnectionError 呼び出し接続エラー\nInvokeServerUnavailableError 呼び出しサービスが利用不可\nInvokeRateLimitError 呼び出し回数制限に達した\nInvokeAuthorizationError 認証エラー\nInvokeBadRequestError 不正なリクエストパラメータ\nCopy\n@property\ndef _invoke_error_mapping(self) -> dict[type[InvokeError], list[type[Exception]]]:\n    \"\"\"\n    Map model invoke error to unified error\n    The key is the error type thrown to the caller\n    The value is the error type thrown by the model,\n    which needs to be converted into a unified error type for the caller.\n\n    :return: Invoke error mapping\n    \"\"\"\n\n\nインターフェース方法の詳細については：インターフェースをご覧ください。具体的な実装例については、llm.pyを参照してください。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\n事前定義されたモデルの追加\nインターフェース方法\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nイントロダクション\nベンダー yaml の作成\nモデルコードの作成",
        "error": null
      },
      {
        "link_index": 35,
        "link_text": "このページを編集する直接貢献することでドキュメントの改善にご協力ください",
        "target_url": "https://github.com/langgenius/dify-docs-mintlify/edit/main/ja-jp/plugins/quick-start/develop-plugins/model-plugin/README.mdx",
        "extract_target": "body",
        "extracted_data": "Skip to content\nSign in to GitHub\nUsername or email address\nPassword\nForgot password?\nPassword login alternatives\n\nNew to GitHub? Create an account\n\nTerms\nPrivacy\nDocs\nContact GitHub Support\nManage cookies\nDo not share my personal information",
        "error": null
      },
      {
        "link_index": 36,
        "link_text": "問題を報告するエラーを見つけたり提案がありますか？お知らせください",
        "target_url": "https://github.com/langgenius/dify-docs-mintlify/issues/new?title=ドキュメントの問題%3A%20&body=%23%23%20問題の説明%0A%3C%21--%20発見した問題について簡単に説明してください%20--%3E%0A%0A%23%23%20ページリンク%0Ahttps%3A%2F%2Fgithub.com%2Flanggenius%2Fdify-docs-mintlify%2Fblob%2Fmain%2Fja-jp/plugins/quick-start/develop-plugins/model-plugin%2FREADME.mdx%0A%0A%23%23%20提案される変更%0A%3C%21--%20特定の変更案がある場合は、ここで説明してください%20--%3E%0A%0A%3C%21--%20ドキュメントの品質向上にご協力いただきありがとうございます！%20--%3E",
        "extract_target": "body",
        "extracted_data": "Skip to content\nSign in to GitHub\nUsername or email address\nPassword\nForgot password?\nPassword login alternatives\n\nNew to GitHub? Create an account\n\nTerms\nPrivacy\nDocs\nContact GitHub Support\nManage cookies\nDo not share my personal information",
        "error": null
      },
      {
        "link_index": 37,
        "link_text": "x",
        "target_url": "https://x.com/dify_ai",
        "extract_target": "body",
        "extracted_data": "「いま」起きていることを見つけよう\nXなら、「いま」起きていることをいち早くチェックできます。\nログイン\nアカウント作成\nプロフィール\n新しいポストを表示\nXを使ってみよう\n今すぐ登録して、タイムラインをカスタマイズしましょう。\nGoogle で登録\nAppleのアカウントで登録\nアカウントを作成\nアカウントを登録することにより、利用規約とプライバシーポリシー（Cookieの使用を含む）に同意したとみなされます。\n利用規約\n |\nプライバシーポリシー\n |\nCookieのポリシー\n |\nアクセシビリティ\n |\n広告情報\n |\nもっと見る\n© 2025 X Corp.",
        "error": null
      },
      {
        "link_index": 38,
        "link_text": "github",
        "target_url": "https://github.com/langgenius/dify-docs-mintlify",
        "extract_target": "body",
        "extracted_data": "Skip to content\nNavigation Menu\nProduct\nSolutions\nResources\nOpen Source\nEnterprise\nPricing\nSign in\nSign up\nlanggenius\n/\ndify-docs-mintlify\nPublic\nNotifications\nFork 18\n Star 7\nCode\nIssues\n3\nPull requests\n4\nActions\nProjects\nSecurity\nInsights\nlanggenius/dify-docs-mintlify\n main\nBranches\nTags\nCode\nFolders and files\nName\tLast commit message\tLast commit date\n\nLatest commit\n \nHistory\n136 Commits\n\n\nen\n\t\n \n\t\n \n\n\nja-jp\n\t\n \n\t\n \n\n\nlogo\n\t\n \n\t\n \n\n\noutput\n\t\n \n\t\n \n\n\nplugin_dev_en\n\t\n \n\t\n \n\n\nplugin_dev_zh\n\t\n \n\t\n \n\n\nscripts\n\t\n \n\t\n \n\n\ntools\n\t\n \n\t\n \n\n\nzh-hans\n\t\n \n\t\n \n\n\n.DS_Store\n\t\n \n\t\n \n\n\nLICENSE\n\t\n \n\t\n \n\n\nREADME.md\n\t\n \n\t\n \n\n\nconversion.log\n\t\n \n\t\n \n\n\ndevelopment.mdx\n\t\n \n\t\n \n\n\ndify-logo.png\n\t\n \n\t\n \n\n\ndocs-3.21.json\n\t\n \n\t\n \n\n\ndocs.json\n\t\n \n\t\n \n\n\nfavicon.svg\n\t\n \n\t\n \n\n\ngoogle364c33c65ea1639f.html\n\t\n \n\t\n \n\n\nintroduction.mdx\n\t\n \n\t\n \n\n\ninvalid_links_report.md\n\t\n \n\t\n \n\n\nlink_validator.py\n\t\n \n\t\n \n\n\nquickstart.mdx\n\t\n \n\t\n \n\n\nrobots.txt\n\t\n \n\t\n \n\n\nsmart_link_fixer.py\n\t\n \n\t\n \n\n\nzh-hans.md\n\t\n \n\t\n \nRepository files navigation\nREADME\nCode of conduct\nCC-BY-4.0 license\n📘 Dify Documentation (Mintlify Edition)\n\nWelcome to the documentation repository for Dify.\n\nWe warmly welcome your contributions — whether it’s proofreading, fixing typos, or submitting new content. Please feel free to open issues or PRs if you find anything that could be improved!\n\n⸻\n\n🚀 Project Overview\n\nThis project uses the Mintlify Kit to build and serve modern, developer-friendly documentation.\n\n⸻\n\n🛠️ Local Development\n\nTo preview and develop documentation locally:\n\nInstall the Mintlify CLI\nnpm i -g mintlify\nStart local development\n\nRun this command at the root of your project (where docs.json is located):\n\nmintlify dev\n\n⸻\n\n🙌 Contributing\n\nYour help in reviewing, editing, and expanding the documentation is truly appreciated.\n\n📝 Contribution Workflow\n\nFork this repository to your own GitHub account.\n\nCreate a new branch based on the main branch.\n\nStart the local development server following the steps above to preview your changes live.\n\nMake your edits or write new content in the appropriate file under the content/ directory.\n\nSubmit a Pull Request (PR) after verifying your changes:\n\n• If you’ve added new pages or sections, don’t forget to update docs.json to include them in the sidebar navigation. • We welcome tri-lingual contributions (English, Simplified Chinese, Japanese) — contribute in one or more languages if possible.\n\nPlease submit PRs to this repository instead of the legacy one: 📘 https://github.com/langgenius/dify-docs\n\nThanks again for being part of Dify’s documentation journey!\n\n⸻\n\n📄 License\n\nThe Dify product documentation in the assets, content, and data folders are licensed under a CC-BY license.\n\nAbout\ndocs.dify.ai\nResources\n Readme\nLicense\n CC-BY-4.0 license\nCode of conduct\n Code of conduct\n Activity\n Custom properties\nStars\n 7 stars\nWatchers\n 11 watching\nForks\n 18 forks\nReport repository\n\n\nReleases\nNo releases published\n\n\nPackages\nNo packages published\n\n\n\nContributors\n8\n\n\nLanguages\nMDX\n93.7%\n \nPython\n6.3%\nFooter\n© 2025 GitHub, Inc.\nFooter navigation\nTerms\nPrivacy\nSecurity\nStatus\nDocs\nContact\nManage cookies\nDo not share my personal information",
        "error": null
      },
      {
        "link_index": 39,
        "link_text": "linkedin",
        "target_url": "https://www.linkedin.com/company/langgenius",
        "extract_target": "body",
        "extracted_data": "メインコンテンツにスキップ\nLinkedIn\n記事\nユーザー\nラーニング\n求人\nゲーム\nダウンロード\nメンバー登録\nサインイン\nDify\n技術・情報・インターネット\nMIDDLETOWN、DE3,276人のフォロワー\nDify is an open-source LLM app development platform. Orchestrate LLM apps from agents to complex AI workflows.\nフォローする\n  \n\n51人すべての社員を表示\n\n概要\n\n\n              Dify.AI is an LLM application development platform. It integrates the concepts of Backend as a Service and LLMOps.\n          \n\nウェブサイト\nhttps://dify.ai\n業種\n技術・情報・インターネット\n会社規模\n社員 11 - 50名\n本社\nMIDDLETOWN、DE\n種類\n共同経営\n創立\n2023\n専門分野\nAI、LLM、RAG、LLMOps\n製品\nDify\nDify\nSaaS管理ソフトウェア\n\nAn Open-Source Assistants API and GPTs alternative. Dify.AI is an LLM application development platform. It integrates the concepts of Backend as a Service and LLMOps and orchestrates LLM apps from agents to complex AI workflows with an RAG engine.\n\n場所\nプライマリ\n\nMIDDLETOWN、DE、19709、US\n\n道順を表示\nDifyの社員\nLuyu Zhang\nFounder&CEO of Dify.AI, Democratization of AI\nJia (Jake) Xie\nearly-stage venture capital investor\nLi Zheng\nSenior Developer Relations Manager\nJakob Morgan\nLicensed Independent Adjuster | Swift & Fair Claims Resolution | CAT & Daily Claims\n全社員を表示\nアップデート\nDify\n\n3,276人のフォロワー\n\n6日前\n\nDify 🤝 Palo Alto Networks\n\nWe’re excited to announce that the Palo Alto Networks PANW AI Runtime Security plugin is now live in the Dify Marketplace!\n\nAdd enterprise-grade protection to every Dify Workflow, Agent, and Chatflow with a single click. Stop prompt injection, data leaks, malicious links, denial of service attempts, and more while keeping your AI apps fast and reliable.\n\n🛡️ Try the plugin on Marketplace: https://lnkd.in/gQrM59w9\n\nRead the blog: https://lnkd.in/g5NXcYFV\n\n#Dify #PaloAltoNetworks #AISecurity #Plugins\n\n10\nいいね！\nコメント\nシェア\nDify\n\n3,276人のフォロワー\n\n6日前\n\n🛍️ Build E-commerce AI Agents with Dify! \n\nTransform your e-commerce workflow by automating key tasks with AI. This video shows beginners how to use Dify to create intelligent agents that can:\n\n1) Answer customer queries directly from your knowledge base.\n2) Automate tasks like product searching or order placement using APIs.\n\nThis step-by-step guide covers: \n🔹 Dify.AI basics \n🔹 Building both agent types\n🔹 Integrating agents into your web apps\n\nPerfect for anyone curious about AI agents for business. Dive in and start building: https://lnkd.in/gruAYw96\n\n29\n1件のコメント\nいいね！\nコメント\nシェア\n\nDifyさんが再投稿しました\n\nCEC\n\n160人のフォロワー\n\n1週間前\n\nYesterday, we hosted the Anthropic x New York University Student Founders Meetup!\n\nWe had a great time introducing Claude for NYU Students, hearing lightning pitches from NYU founders, and connecting with so many inspiring builders.\n\nA special thanks to Dify for the amazing demonstration of Claude's use case. Huge thanks to the NYU community for the amazing support, and hope you’re enjoying the Anthropic merch!\n\nJust in case you missed it:\n 👉 Unlock $1/Month Claude Pro for 3 months with your NYU email: https://lnkd.in/e3WZ8AQX\n\n#ClaudeAI #Anthropic #NYU #StudentFounders #AIForStudents  #CampusLife #FinalsSeason\n\n+5\n5\nいいね！\nコメント\nシェア\nDify\n\n3,276人のフォロワー\n\n1週間前  編集済み\n\n🎮 Tutorial: Building a Context-Aware AI Chatbot with Dify & InfraNodus GraphRAG\n\nMoving beyond basic RAG, this tutorial demonstrates using the structural relationships within your data (via knowledge graphs) to provide enhanced context to the LLM.\n\nLearn how to: \n1) Set up a Dify workflow \n2) Integrate the Infranodus GraphRAG API \n3) Augment prompts with contextual graph data \n4) Achieve significantly more precise and relevant chatbot responses\n\nUnlock the potential of your knowledge base and create truly intelligent AI assistants.\n\nSee how it's done: https://lnkd.in/g-HPQvQv\n\n#GraphRAG #Dify #AI #Chatbot\n\n…さらに表示\nHow to Build a Context-Aware AI Chatbot with InfraNodus and Dify\nhttps://www.youtube.com/\n15\nいいね！\nコメント\nシェア\nDify\n\n3,276人のフォロワー\n\n1週間前\n\nWe're excited to announce that Dify will be exhibiting at the AWS Summit Japan 2025!\nJoin us at Makuhari Messe from June 25th to 26th. You can register for the event using the link below. We look forward to connecting with you there!\n\nhttps://lnkd.in/e_dXkS-D\n\n14\nいいね！\nコメント\nシェア\nDify\n\n3,276人のフォロワー\n\n1週間前\n\n🎉 Recap of Japan IT Week Spring 2025 Panel Discussion\n\nOn April 23rd, LangGenius General Manager, Marudan Kiji, PhD, joined Shunsuke Kiriyama (NTT Data) and Yutaka Yoshida (Toyota Boshoku) for a panel on the \"Arrival of the AI Agent Era\" at Japan IT Week Spring, focusing on Dify/Tsunagi AI's role in Japan's Enterprise DX.\n\nMarudan Kiji, PhD shared insights on aspects such as:\n1) Global AI agent trends and the impact on knowledge management and breaking down information silos.\n2) Dify’s “easy-to-use” approach, enabling fast development and cost savings from PoC to implementation.\n3) Collaboration with partners and users is key to solving real-world challenges.\n4) The vision for “next-gen Dify/TsunagiAI,” intuitive even for new employees.\n\nThanks were extended to the Japan IT Week team, NTT DATA, TOYOTA BOSHOKU CORP./トヨタ紡織株式会社, and attendees. LangGenius remains committed to advancing AI-driven DX in Japan through Dify. \n\n\n19\n1件のコメント\nいいね！\nコメント\nシェア\n\nDifyさんが再投稿しました\n\nMarudan Kiji, PhD\n\nCTO，GenAI/Robotic, Ex-Honda R&D, CO-Founder\n\n1週間前  編集済み\n\nI recently concluded our panel discussion at #JapanITWeek Spring 2025 on the \"Arrival of the AI Agent Era\" with Kiriyama-san from #NTTData and Yoshida-san from #ToyotaBoshoku. We highlighted Dify/Tsunagi AI's crucial role in driving Japan's Enterprise DX.\n\nFrom my perspective, a key aspect was Dify/Tsunagi AI's potential to leverage corporate knowledge and break down information silos through the Progress AI Agent concept, aligning with global AI agent trends. I stressed how Dify's core philosophy of \"making AI easily accessible to everyone\" enables significant cost and development time reductions by providing a consistent environment from PoC to implementation. The panel also touched upon the importance of the horizontal deployment of targeted AI use cases that solve specific on-site challenges, requiring strong collaboration and trust with partners. Furthermore, I emphasized Dify/Tsunagi AI's value in clarifying AI applications and their real-world impact.\n \nLooking ahead, LangGenius is focused on the next-gen Dify designed for even greater user intuitiveness, which will be easily used even by new employees, further empowering everyone to solve their challenges. And yes, we're \"open to various GTM strategies!\"\n\n Looking forward to the continued advancements in AI-driven DX for Japanese enterprises.\n\n #Dify #tsunagiAI #AIAgent #LangGenius\n\nDify\n\n3,276人のフォロワー\n\n3週間前  編集済み\n\n🎉 We’re pleased to announce our participation in Japan IT Week Spring 2025 on April 23, 2025, starting at 10:00 AM (GMT+9).  \n\nJoin Marudan Kiji, PhD, General Manager, Japan at LangGenius, as he speaks at the event. At 2:00 PM, he will lead a panel discussion on “Driving Japan’s DX Strategy with Dify,” featuring Shunsuke kiriya from NTT DATA and Yutaka Yoshida from TOYOTA BOSHOKU CORP./トヨタ紡織株式会社.\n\nKey topics include:  \n\n1) Customized AI success stories for Japan’s manufacturing and finance sectors  \n2) The latest trends in AI, from autonomous agents to citizen development  \n3) Low-code strategies for cost efficiency and operational excellence led by non-IT teams\n\nThis session is ideal for professionals focused on AI-driven digital transformation and enterprise innovation.  \n\nFor more details and registration, visit the Japan IT Week website: https://lnkd.in/en7_qbk3\n\n#JapanITWeek #DigitalTransformation #AI #EnterpriseInnovation\n\n12\n1件のコメント\nいいね！\nコメント\nシェア\nDify\n\n3,276人のフォロワー\n\n1週間前\n\n✨ Dify v1.3.0 is LIVE! Featuring Structured Outputs with JSON Schema Editor & More!\n\nTired of unpredictable LLM outputs? Our Structured Outputs feature now comes with a built-in JSON Schema Editor directly in the LLM Node.\n\nThis is a game-changer for ensuring your models return data in reliable, predictable JSON formats. Design your schema once and get consistently structured results, making data handling and API interaction easier.\n\n📺 See how it works: https://lnkd.in/gD8w_3gC\n\n🔧 More Enhancements in v1.3.0:\n\n1) Plugin Update Notifications: Clear UI indicators let you know when new plugin versions are available.\n\n2) Smart Token Counting: New default rules and customization options for better cost management.\n\n3) Workflow Image Export: Easily share your workflows as image files (e.g., PNG).\n\n4) Enhanced Developer Experience: Upgraded from poetry to uv for significantly faster development workflows.\n\nDive into all the details in the full changelog: https://lnkd.in/gfXyDcWs\n\n21\n1件のコメント\nいいね！\nコメント\nシェア\nDify\n\n3,276人のフォロワー\n\n1週間前\n\n[Special Seminar Co-hosted with AWS] Dify Enterprise on AWS – Mastering AI Implementation for Enterprises\n \n🎙️ Featuring Guest Speakers: Kakaku.com, Inc., DNP, Mitsukoshi Isetan\n🗓 Date: Friday, May 23, 2025\n⏰ Time: 15:00–16:30 (Doors open at 14:30)\n📍 Venue: Amazon Japan G.K. Meguro Alcazar Tower\n(3-1-1 Kami-Osaki, Shinagawa-ku, Tokyo)\n\n🚀 Objective\n Discover how Dify Enterprise, an enterprise-grade AI platform, seamlessly integrates with AWS to deliver high-security infrastructure and flexible customization. Learn actionable strategies for enterprise DX through real-world case studies, including large-scale data processing and advanced permission management.\nIdeal for IT leaders and technical teams optimizing AI infrastructure.\n\n▼ Apply Now (Lottery-based registration, deadline: May 13)\n https://lnkd.in/gKykybNq\n\n #Dify #AWS #EnterpriseAI #GenerativeAI #DigitalTransformation\n\n\n25\nいいね！\nコメント\nシェア\nDify\n\n3,276人のフォロワー\n\n2週間前\n\n🧠 New: Workflow Agents now have Memory!\n\nEnable the new Memory toggle for your Agent node so it can recall conversation context. Adjust the Window Size to control how much it remembers for more coherent, context-aware responses. \n\nDocs: https://lnkd.in/g9SVkKFh\n\nThis applies to developers creating custom agent strategy plugins. You can also implement memory for these plugins. Use the history-messages feature, found within the plugin's YAML configuration file.\n\nDocs: https://lnkd.in/gD3zzR7B\n\n#AI #Workflow #Agent #Memory #PluginDevelopment\n\n…さらに表示\n38\n3件のコメント\nいいね！\nコメント\nシェア\n類似するページ\nn8n\n\nソフトウェア開発\n\nBerlin、BE\n\nFlowiseAI (YC S23)\n\nソフトウェア開発\n\nSan Francisco、California\n\nRelevance AI\n\nソフトウェア開発\n\nSurry Hills、New South Wales\n\nwordware (YC S24)\n\n技術・情報・インターネット\n\n類似するページをさらに表示 \n求人を参照\n科学者に関連する求人\n48,969件の募集中の求人\nモバイルエンジニアに関連する求人\n8,544件の募集中の求人\nCFOに関連する求人\n17,590件の募集中の求人\nエンジニアに関連する求人\n555,845件の募集中の求人\nアカウントマネージャーに関連する求人\n121,519件の募集中の求人\nプロダクトデザイナーに関連する求人\n45,389件の募集中の求人\nPython開発者に関連する求人\n46,642件の募集中の求人\nディレクターに関連する求人\n1,220,357件の募集中の求人\nデータサイエンティストに関連する求人\n264,158件の募集中の求人\nサポートに関連する求人\n114,327件の募集中の求人\nこれに類似する求人を表示 \n資金調達\nDify  合計1ラウンド\n\n最終ラウンド\n\nSeed  2023年7月1日\nCrunchbaseで詳しい情報を表示\nその他の検索 \nLinkedIn\n© 2025\n会社概要\nアクセシビリティ\n利用規約\nプライバシーポリシー\nCookieポリシー\n著作権ポリシー\nブランドポリシー\nゲスト向け管理ページ\nコミュニティガイドライン\n言語\nサインインしてDifyの知り合いを見つけましょう\nサインイン\n\nまたは\n\n初めてご利用ですか? 今すぐ登録\n\n登録またはサインインするために [続行] をクリックすることにより、LinkedInの利用規約、プライバシーポリシー、Cookieポリシーに同意したものとみなされます。",
        "error": null
      },
      {
        "link_index": 40,
        "link_text": "Powered by Mintlify",
        "target_url": "https://mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=referral&utm_source=docs.dify.ai",
        "extract_target": "body",
        "extracted_data": "Documentation\nResources\nRequest Preview\nCareers\nPricing\nLogin\nGet a demo\nSign up\n\nPowered by Mintlify\n\nYour documentation can look that nice too.\nTry for free\n\nWant to try it on for style? Submit a link to your documentation and we’ll share a preview of how it’d look on Mintlify.\n\nPowering experiences\nfrom next-gen startups to enterprises\nOur customers\nBuilt for modern teams\n\nCrafted with customizability and collaboration in mind. Designed to impress.\n\nBeautiful out of the box\nBuilt for collaboration\nDesigned for conversion\nThe documentation you want, available today\nGet started\nGet a demo\n\nDocumentation\n\nGetting Started\nComponents\nAPI playground\nPricing\n\nResources\n\nCustomers\nEnterprise\nRequest Preview\nIntegrations\nGuides\nTemplates\nWall of Love\n\nCompany\n\nCareers\nBlog\nSecurity\n\nLegal\n\nPrivacy Policy\nTerms of Service\nResponsible Disclosure\nAll systems normal\n© 2025 Mintlify, Inc.",
        "error": null
      },
      {
        "link_index": 14,
        "link_text": "Schema definition",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nTermbase\nスキーマ仕様\nCopy page\nmanifest.md\n\nmanifest.md\n\nendpoint.md\n\nendpoint.md\n\nmodel.md\n\nmodel.md\n\ngeneral-specifications.md\n\ngeneral-specifications.md\n\npersistent-storage.md\n\npersistent-storage.md\n\nreverse-invocation-of-the-dify-service\n\nreverse-invocation-of-the-dify-service\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify",
        "error": null
      },
      {
        "link_index": 15,
        "link_text": "Manifest(マニフェスト)",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/manifest",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nスキーマ仕様\nManifest(マニフェスト)\nCopy page\n\nマニフェストファイル マニフェストファイルとは、プラグインに関する最も基本的な情報を定義するYAML形式のファイルです。プラグイン名、作成者、含まれるツールやモデルなどの情報が含まれます。\n\nこのファイルの形式が正しくないと、プラグインの解析とパッケージング処理は失敗します。\n\n​\nコード例\n\n以下は、マニフェストファイルの簡単な例です。各データ要素の意味と機能については、以下で説明します。他のプラグインコードについては、Githubリポジトリ を参照してください。\n\nCopy\nversion: 0.0.1\ntype: \"plugin\"\nauthor: \"Yeuoly\"\nname: \"neko\"\nlabel:\n  en_US: \"Neko\"\ncreated_at: \"2024-07-12T08:03:44.658609186Z\"\nicon: \"icon.svg\"\nresource:\n  memory: 1048576\n  permission:\n    tool:\n      enabled: true\n    model:\n      enabled: true\n      llm: true\n    endpoint:\n      enabled: true\n    app:\n      enabled: true\n    storage: \n      enabled: true\n      size: 1048576\nplugins:\n  endpoints:\n    - \"provider/neko.yaml\"\nmeta:\n  version: 0.0.1\n  arch:\n    - \"amd64\"\n    - \"arm64\"\n  runner:\n    language: \"python\"\n    version: \"3.11\"\n    entrypoint: \"main\"\n\n​\nバージョン管理\n\nプラグインのバージョンは、マニフェストファイルのversionフィールドで管理されます。バージョン番号はmajor.minor.patchの形式である必要があります。そうでない場合、自動更新が期待どおりに動作しない可能性があります。\n\n​\n構造\nversion (version、required): プラグインのバージョン\ntype (type、required): プラグインの種類。現在はpluginのみをサポートしており、将来的にはbundleをサポート予定\nauthor (string、required): 作成者。マーケットプレイスでは組織名として扱われます\nlabel (label、required): 多言語対応の名前\ncreated_at (RFC3339、required): 作成時間。マーケットプレイスでは現在時刻より後の日時であってはなりません\nicon (アセット、required): アイコンのパス\nresource (object): 必要なリソース設定\nmemory (int64): 最大メモリ使用量。主にSaaS上のAWS Lambdaリソースリクエストに関連し、単位はバイト\npermission (object): 権限設定\ntool (object): ツール呼び出しの権限\nenabled (bool)\nmodel (object): モデル呼び出しの権限\nenabled (bool)\nllm (bool)\ntext_embedding (bool)\nrerank (bool)\ntts (bool)\nspeech2text (bool)\nmoderation (bool)\nnode (object): ノード呼び出しの権限\nenabled (bool)\nendpoint (object): エンドポイント登録の権限\nenabled (bool)\napp (object): アプリ呼び出しの権限\nenabled (bool)\nstorage (object): 永続ストレージの権限\nenabled (bool)\nsize (int64): 最大許容永続メモリサイズ（バイト単位）\nplugins (object、required): プラグインの機能を定義するYAMLファイルのリスト。プラグインパッケージ内の絶対パスで指定\n形式：\ntools (list[string]): 拡張されたツールプロバイダ\nmodels (list[string]): 拡張されたモデルプロバイダ\nendpoints (list[string]): 拡張されたエンドポイントプロバイダ\nagent_strategies (list[string]): 拡張されたエージェント戦略プロバイダ\n制限：\nツールとモデルの両方を同時に拡張することはできません。\n少なくとも1つの拡張が必要です。\nモデルとエンドポイントの両方を同時に拡張することはできません。\n現在、拡張タイプごとに1つのプロバイダのみをサポートしています。\nmeta (object): メタ情報\nversion (version、required): マニフェスト形式のバージョン。初期バージョンは0.0.1\narch (list[string]、required): サポートされるアーキテクチャ。現在はamd64とarm64のみ\nrunner (object、required): ランタイム設定\nlanguage (string): 現在はPythonのみをサポート\nversion (string): 言語バージョン。現在は3.12のみをサポート\nentrypoint (string): プログラムのエントリポイント。Pythonの場合はmainである必要があります。\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nSchema definition\nEndpoint（エンドポイント）\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nコード例\nバージョン管理\n構造",
        "error": null
      },
      {
        "link_index": 16,
        "link_text": "Endpoint（エンドポイント）",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/endpoint",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nスキーマ仕様\nEndpoint（エンドポイント）\nCopy page\n\nこの記事では、プラグイン内のエンドポイントの構造を説明するために、クイックスタート：レインボーキャットプロジェクトを例として取り上げます。完全なプラグインコードは、Githubで確認できます。\n\n​\nグループの定義\n\nEndpointグループは、複数のEndpointをまとめたものです。Difyプラグインで新しいEndpointを作成する際には、以下の設定項目を入力する必要があります。\n\n「Endpoint Name」の他に、グループ構成情報を記述することで、新しいフォーム項目を追加できます。保存すると、同じ構成情報を使用する複数のインターフェースが表示されるようになります。\n\n​\n構造\nsettings (map[string] ProviderConfig): エンドポイントの設定定義\nendpoints (list[string], required): 特定のendpointインターフェース定義を指定します。\nCopy\nsettings:\n  api_key:\n    type: secret-input\n    required: true\n    label:\n      en_US: API key\n      zh_Hans: API key\n      ja_Jp: API key\n      pt_BR: API key\n    placeholder:\n      en_US: Please input your API key\n      zh_Hans: 请输入你的 API key\n      ja_Jp: あなたの API key を入れてください\n      pt_BR: Por favor, insira sua chave API\nendpoints:\n  - endpoints/duck.yaml\n  - endpoints/neko.yaml\n\n​\nインターフェース定義\npath (string): werkzeugのインターフェース標準に従います。\nmethod (string): インターフェースのメソッド。HEAD GET POST PUT DELETE OPTIONSのみをサポートします。\nextra (object): 基本情報以外の設定情報\npython (object)\nsource (string): このインターフェースを実装するソースコード\nCopy\npath: \"/duck/<app_id>\"\nmethod: \"GET\"\nextra:\n  python:\n    source: \"endpoints/duck.py\"\n\n​\nエンドポイントの実装\n\ndify_plugin.Endpointを継承したサブクラスを実装し、_invokeメソッドを実装する必要があります。\n\n入力パラメータ\nr (Request): werkzeugからのリクエストオブジェクト\nvalues (Mapping): パスから解析されたパスパラメータ\nsettings (Mapping): このエンドポイントの設定情報\n戻り値\nwerkzeugからのレスポンスオブジェクト。ストリーミングでの応答をサポートします。\n直接的な文字列の戻り値はサポートしません。\n\nコード例:\n\nCopy\nimport json\nfrom typing import Mapping\nfrom werkzeug import Request, Response\nfrom dify_plugin import Endpoint\n\nclass Duck(Endpoint):\n    def _invoke(self, r: Request, values: Mapping, settings: Mapping) -> Response:\n        \"\"\"\n        Invokes the endpoint with the given request.\n        \"\"\"\n        app_id = values[\"app_id\"]\n        def generator():\n            yield f\"{app_id} <br>\"\n        return Response(generator(), status=200, content_type=\"text/html\")\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nManifest(マニフェスト)\nTool(ツール)\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nグループの定義\n構造\nインターフェース定義\nエンドポイントの実装",
        "error": null
      },
      {
        "link_index": 17,
        "link_text": "Tool(ツール)",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/tool",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nスキーマ仕様\nTool(ツール)\nCopy page\n\n詳細なインターフェースドキュメントを読む前に、クイックスタート：ツール を参照し、Difyプラグインにおけるツールの利用プロセスについて、概要を把握しておいてください。\n\n​\nデータ構造\n​\nメッセージの出力\n\nDifyは、text、links、images、file BLOBs、JSONといった複数のメッセージタイプをサポートしています。様々なインターフェースを通じて、これらの異なるタイプのメッセージを出力できます。\n\nデフォルトでは、ワークフロー内でツールが出力する際には、files、text、jsonという3つの固定の変数が用意されています。これらの変数にデータを設定するには、以下のメソッドを使用します。\n\n例えば、create_image_messageを使用すると、画像を出力できます。また、ツールはワークフロー内で参照しやすいように、カスタムの出力変数もサポートしています。\n\n​\n画像URL\n\n画像のURLを渡すだけで、Difyが自動的に画像をダウンロードし、ユーザーに送信します。\n\nCopy\ndef create_image_message(self, image: str) -> ToolInvokeMessage:\n    pass\n\n​\nリンク\n\nリンクを出力するには、このインターフェースを使用します。\n\nCopy\ndef create_link_message(self, link: str) -> ToolInvokeMessage:\n    pass\n\n​\nテキスト\n\nテキストメッセージを出力するには、このインターフェースを使用します。\n\nCopy\ndef create_text_message(self, text: str) -> ToolInvokeMessage:\n    pass\n\n​\nファイル\n\n生のファイルデータ（画像、音声、動画、PPT、Word、Excelなど）を出力するには、このインターフェースを使用します。\n\nblob: バイト形式の生ファイルデータ\nmeta: ファイルのメタデータです。mime_typeを指定することで、ファイルの種類を明示できます。指定しない場合は、Difyがデフォルトでoctet/streamを使用します。\nCopy\ndef create_blob_message(self, blob: bytes, meta: dict = None) -> ToolInvokeMessage:\n    pass\n\n​\nJSON\n\nフォーマットされたJSONを出力するには、このインターフェースを使用します。通常、ワークフロー内のノード間でデータをやり取りする際に使用されます。多くの大規模言語モデルは、エージェントモードでJSON形式のデータを読み取り、理解できます。\n\nCopy\ndef create_json_message(self, json: dict) -> ToolInvokeMessage:\n    pass\n\n​\n変数\n\nストリーミングではない出力変数を設定するには、このインターフェースを使用します。後から設定された値は、以前の設定値を上書きします。\n\nCopy\ndef create_variable_message(self, variable_name: str, variable_value: Any) -> ToolInvokeMessage:\n    pass\n\n​\nストリーミング変数\n\nテキストをタイプライターのように表示するには、ストリーミング変数を使用します。チャットフローアプリケーションの応答ノードでこの変数を参照すると、テキストがタイプライター効果で表示されます。現在、文字列データのみをサポートしています。\n\nCopy\ndef create_stream_variable_message(\n    self, variable_name: str, variable_value: str\n) -> ToolInvokeMessage:\n\n​\n出力変数の定義\n\nワークフロー内でツールの出力変数を参照するには、事前に出力される可能性のある変数を定義しておく必要があります。Difyプラグインは、json_schema形式での出力変数定義をサポートしています。以下に設定例を示します。\n\nCopy\nidentity:\n  author: author\n  name: tool\n  label:\n    en_US: label\n    zh_Hans: 标签\n    ja_JP: レベル\n    pt_BR: etiqueta\ndescription:\n  human:\n    en_US: description\n    zh_Hans: 描述\n    ja_JP: 説明\n    pt_BR: descrição\n  llm: description\noutput_schema:\n  type: object\n  properties:\n    name:\n      type: string\n\n\nこの例では、ワークフロー内で参照できる name フィールドを含む output_schema を持つシンプルなツールを定義しています。実際に使用するには、ツールの実装コード内で変数を設定する必要があることに注意してください。そうしないと、None が設定されます。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nEndpoint（エンドポイント）\nAgent(エージェント)\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nデータ構造\nメッセージの出力\n画像URL\nリンク\nテキスト\nファイル\nJSON\n変数\nストリーミング変数\n出力変数の定義",
        "error": null
      },
      {
        "link_index": 18,
        "link_text": "Agent(エージェント)",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/agent",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nスキーマ仕様\nAgent(エージェント)\nCopy page\n\nエージェント戦略の概要\n\nエージェント戦略とは、標準的な入力コンテンツと出力形式を定義する拡張可能なテンプレートです。特定のエージェント戦略インターフェースを開発することで、CoT（Chain of Thought：思考の連鎖）、ToT（Tree of Thought：思考の木）、GoT（Graph of Thought：思考のグラフ）、BoT（Backbone of Thought：思考のバックボーン）といった様々なエージェント戦略を実装したり、Semantic Kernel のような複雑な戦略を実現したりできます。\n\n​\nマニフェストへのフィールド追加\n\nプラグインにエージェント戦略を追加するには、manifest.yamlファイルにplugins.agent_strategiesフィールドを追加し、エージェントプロバイダーを定義します。以下にコード例を示します。\n\nversion: 0.0.2\ntype: plugin\nauthor: \"langgenius\"\nname: \"agent\"\nplugins:\n  agent_strategies:\n    - \"provider/agent.yaml\"\n\n\nマニフェストファイル内の関連性のないフィールドは省略されています。詳細なマニフェスト形式については、Manifestを参照してください。\n\n​\nエージェントプロバイダーの定義\n\n基本的なエージェントプロバイダー情報を含むagent.yamlファイルを作成します。\n\nidentity:\n  author: langgenius\n  name: agent\n  label:\n    en_US: Agent\n    zh_Hans: Agent\n    pt_BR: Agent\n  description:\n    en_US: Agent\n    zh_Hans: Agent\n    pt_BR: Agent\n  icon: icon.svg\nstrategies:\n  - strategies/function_calling.yaml\n\n​\nエージェント戦略の定義と実装\n​\n定義\n\nエージェント戦略のコードを定義するために、function_calling.yamlファイルを作成します。\n\nidentity:\n  name: function_calling\n  author: Dify\n  label:\n    en_US: FunctionCalling\n    zh_Hans: FunctionCalling\n    pt_BR: FunctionCalling\ndescription:\n  en_US: Function Calling is a basic strategy for agent, model will use the tools provided to perform the task.\nparameters:\n  - name: model\n    type: model-selector\n    scope: tool-call&llm\n    required: true\n    label:\n      en_US: Model\n  - name: tools\n    type: array[tools]\n    required: true\n    label:\n      en_US: Tools list\n  - name: query\n    type: string\n    required: true\n    label:\n      en_US: Query\n  - name: max_iterations\n    type: number\n    required: false\n    default: 5\n    label:\n      en_US: Max Iterations\n    max: 50\n    min: 1\nextra:\n  python:\n    source: strategies/function_calling.py\n\n\nこのコード形式はToolの標準形式に似ており、最も基本的なエージェント戦略を実装するために、model、tools、query、max_iterationsの4つのパラメーターを定義しています。これにより、ユーザーは以下のことが可能になります。\n\n使用するモデルを選択する\n利用するツールを選択する\n最大反復回数を設定する\nエージェントの実行を開始するためのクエリを入力する\n\nこれらのパラメーターはすべて連携して、エージェントがタスクを処理し、選択されたツールやモデルとどのように対話するかを定義します。\n\n​\n機能実装\n\nパラメーターの取得\n\n前述の4つのパラメーターに基づき、モデルタイプのパラメーターはmodel-selector、ツールタイプのパラメーターは特別なarray[tools]です。取得したパラメーターは、SDKに組み込まれているAgentModelConfigとlist[ToolEntity]を使用して変換できます。\n\nfrom dify_plugin.interfaces.agent import AgentModelConfig, AgentStrategy, ToolEntity\n\nclass FunctionCallingParams(BaseModel):\n    query: str\n    model: AgentModelConfig\n    tools: list[ToolEntity] | None\n    maximum_iterations: int = 3\n    \n class FunctionCallingAgentStrategy(AgentStrategy):\n    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:\n        \"\"\"\n        Run FunctionCall agent application\n        \"\"\"\n        fc_params = FunctionCallingParams(**parameters)\n\n\nモデルの呼び出し\n\n特定モデルの呼び出しは、エージェントプラグインの不可欠な機能です。SDKのsession.model.invoke()関数を使用してモデルを呼び出します。必要な入力パラメーターはモデルから取得できます。\n\nモデルを呼び出すメソッドの例：\n\ndef invoke(\n        self,\n        model_config: LLMModelConfig,\n        prompt_messages: list[PromptMessage],\n        tools: list[PromptMessageTool] | None = None,\n        stop: list[str] | None = None,\n        stream: bool = True,\n    ) -> Generator[LLMResultChunk, None, None] | LLMResult:\n\n\nモデル情報（model_config）、プロンプト情報（prompt_messages）、ツール情報（tools）を渡す必要があります。prompt_messagesパラメーターは以下のコード例を参照できますが、tool_messagesには特定の変換が必要です。\n\nモデル呼び出しのコード例を参照してください。\n\nfrom collections.abc import Generator\nfrom typing import Any\n\nfrom pydantic import BaseModel\n\nfrom dify_plugin.entities.agent import AgentInvokeMessage\nfrom dify_plugin.entities.model.llm import LLMModelConfig\nfrom dify_plugin.entities.model.message import (\n    PromptMessageTool,\n    SystemPromptMessage,\n    UserPromptMessage,\n)\nfrom dify_plugin.entities.tool import ToolParameter\nfrom dify_plugin.interfaces.agent import AgentModelConfig, AgentStrategy, ToolEntity\n\nclass FunctionCallingParams(BaseModel):\n    query: str\n    instruction: str | None\n    model: AgentModelConfig\n    tools: list[ToolEntity] | None\n    maximum_iterations: int = 3\n\nclass FunctionCallingAgentStrategy(AgentStrategy):\n    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:\n        \"\"\"\n        Run FunctionCall agent application\n        \"\"\"\n        # init params\n        fc_params = FunctionCallingParams(**parameters)\n        query = fc_params.query\n        model = fc_params.model\n        stop = fc_params.model.completion_params.get(\"stop\", []) if fc_params.model.completion_params else []\n        prompt_messages = [\n            SystemPromptMessage(content=\"your system prompt message\"),\n            UserPromptMessage(content=query),\n        ]\n        tools = fc_params.tools\n        prompt_messages_tools = self._init_prompt_tools(tools)\n\n        # invoke llm\n        chunks = self.session.model.llm.invoke(\n            model_config=LLMModelConfig(**model.model_dump(mode=\"json\")),\n            prompt_messages=prompt_messages,\n            stream=True,\n            stop=stop,\n            tools=prompt_messages_tools,\n        )\n\n    def _init_prompt_tools(self, tools: list[ToolEntity] | None) -> list[PromptMessageTool]:\n        \"\"\"\n        Init tools\n        \"\"\"\n\n        prompt_messages_tools = []\n        for tool in tools or []:\n            try:\n                prompt_tool = self._convert_tool_to_prompt_message_tool(tool)\n            except Exception:\n                # api tool may be deleted\n                continue\n\n            # save prompt tool\n            prompt_messages_tools.append(prompt_tool)\n\n        return prompt_messages_tools\n\n    def _convert_tool_to_prompt_message_tool(self, tool: ToolEntity) -> PromptMessageTool:\n        \"\"\"\n        convert tool to prompt message tool\n        \"\"\"\n        message_tool = PromptMessageTool(\n            name=tool.identity.name,\n            description=tool.description.llm if tool.description else \"\",\n            parameters={\n                \"type\": \"object\",\n                \"properties\": {},\n                \"required\": [],\n            },\n        )\n\n        parameters = tool.parameters\n        for parameter in parameters:\n            if parameter.form != ToolParameter.ToolParameterForm.LLM:\n                continue\n\n            parameter_type = parameter.type\n            if parameter.type in {\n                ToolParameter.ToolParameterType.FILE,\n                ToolParameter.ToolParameterType.FILES,\n            }:\n                continue\n            enum = []\n            if parameter.type == ToolParameter.ToolParameterType.SELECT:\n                enum = [option.value for option in parameter.options] if parameter.options else []\n\n            message_tool.parameters[\"properties\"][parameter.name] = {\n                \"type\": parameter_type,\n                \"description\": parameter.llm_description or \"\",\n            }\n\n            if len(enum) > 0:\n                message_tool.parameters[\"properties\"][parameter.name][\"enum\"] = enum\n\n            if parameter.required:\n                message_tool.parameters[\"required\"].append(parameter.name)\n\n        return message_tool\n\n\nツールの呼び出し\n\nツールの呼び出しも、エージェントプラグインの重要な機能です。ツールを呼び出すには、self.session.tool.invoke()を使用します。\n\nツールを呼び出すメソッドの例：\n\ndef invoke(\n        self,\n        provider_type: ToolProviderType,\n        provider: str,\n        tool_name: str,\n        parameters: dict[str, Any],\n    ) -> Generator[ToolInvokeMessage, None, None]\n\n\n必要なパラメーターには、provider_type、provider、tool_name、parametersが含まれます。通常、tool_nameとparametersは関数呼び出し中にLLMによって生成されます。\n\nツールを呼び出すコード例：\n\nfrom dify_plugin.entities.tool import ToolProviderType\n\nclass FunctionCallingAgentStrategy(AgentStrategy):\n    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:\n        \"\"\"\n        Run FunctionCall agent application\n        \"\"\"\n        fc_params = FunctionCallingParams(**parameters)\n        \n        # tool_call_name と tool_call_args パラメータはLLMの出力から取得されます。\n        tool_instances = {tool.identity.name: tool for tool in fc_params.tools} if fc_params.tools else {}\n        tool_instance = tool_instances[tool_call_name]\n        tool_invoke_responses = self.session.tool.invoke(\n            provider_type=ToolProviderType.BUILT_IN,\n            provider=tool_instance.identity.provider,\n            tool_name=tool_instance.identity.name,\n            # デフォルト値を追加\n            parameters={**tool_instance.runtime_parameters, **tool_call_args},\n        )\n\n\nself.session.tool.invoke()関数の出力はジェネレーターであり、ストリーム解析が必要です。\n\n解析については、以下の関数を参照してください。\n\nimport json\nfrom collections.abc import Generator\nfrom typing import cast\n\nfrom dify_plugin.entities.agent import AgentInvokeMessage\nfrom dify_plugin.entities.tool import ToolInvokeMessage\n\ndef parse_invoke_response(tool_invoke_responses: Generator[AgentInvokeMessage]) -> str:\n    result = \"\"\n    for response in tool_invoke_responses:\n        if response.type == ToolInvokeMessage.MessageType.TEXT:\n            result += cast(ToolInvokeMessage.TextMessage, response.message).text\n        elif response.type == ToolInvokeMessage.MessageType.LINK:\n            result += (\n                f\"result link: {cast(ToolInvokeMessage.TextMessage, response.message).text}.\"\n                + \" please tell user to check it.\"\n            )\n        elif response.type in {\n            ToolInvokeMessage.MessageType.IMAGE_LINK,\n            ToolInvokeMessage.MessageType.IMAGE,\n        }:\n            result += (\n                \"image has been created and sent to user already, \"\n                + \"you do not need to create it, just tell the user to check it now.\"\n            )\n        elif response.type == ToolInvokeMessage.MessageType.JSON:\n            text = json.dumps(cast(ToolInvokeMessage.JsonMessage, response.message).json_object, ensure_ascii=False)\n            result += f\"tool response: {text}.\"\n        else:\n            result += f\"tool response: {response.message!r}.\"\n    return result\n\n\nログ\n\nエージェントの思考プロセスを表示するために、通常のメッセージの戻り値に加えて、専用のインターフェースを使用して、エージェントの思考プロセス全体をツリー構造で表示できます。\n\nログの作成\n\nこのインターフェースは、ログツリー内のノードを表すAgentLogMessageを作成して返します。\n親が渡された場合、このノードに親ノードがあることを示します。\nデフォルトのステータスは「Success」です。ただし、タスク実行プロセスをより適切に表示したい場合は、最初にステータスを「start」に設定して「進行中」のログを表示し、タスク完了後にログステータスを「Success」に更新できます。これにより、ユーザーは最初から最後までプロセス全体を明確に把握できます。\nラベルは、ユーザーに表示されるログタイトルとして使用されます。\ndef create_log_message(\n    self,\n    label: str,\n    data: Mapping[str, Any],\n    status: AgentInvokeMessage.LogMessage.LogStatus = AgentInvokeMessage.LogMessage.LogStatus.SUCCESS,\n    parent: AgentInvokeMessage | None = None,\n) -> AgentInvokeMessage\n\n\nログの完了\n\n以前に初期ステータスとして「start」を設定した場合、ログ完了エンドポイントを使用してステータスを変更できます。\n\ndef finish_log_message(\n    self,\n    log: AgentInvokeMessage,\n    status: AgentInvokeMessage.LogMessage.LogStatus = AgentInvokeMessage.LogMessage.LogStatus.SUCCESS,\n    error: Optional[str] = None,\n) -> AgentInvokeMessage\n\n\n実装例\n\nこの例では、簡単な2段階の実行プロセスを示します。最初に「考え中」の状態のログを出力し、次に実際のタスク処理を完了します。\n\nclass FunctionCallingAgentStrategy(AgentStrategy):\n    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:\n        thinking_log = self.create_log_message(\n            data={\"Query\": parameters.get(\"query\")},\n            label=\"Thinking\",\n            status=AgentInvokeMessage.LogMessage.LogStatus.START,\n        )\n\n        yield thinking_log\n\n        llm_response = self.session.model.llm.invoke(\n            model_config=LLMModelConfig(\n                provider=\"openai\",\n                model=\"gpt-4o-mini\",\n                mode=\"chat\",\n                completion_params={},\n            ),\n            prompt_messages=[\n                SystemPromptMessage(content=\"you are a helpful assistant\"),\n                UserPromptMessage(content=parameters.get(\"query\")),\n            ],\n            stream=False,\n            tools=[],\n        )\n\n        thinking_log = self.finish_log_message(log=thinking_log)\n        yield thinking_log\n        yield self.create_text_message(text=llm_response.message.content)\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nTool(ツール)\nModel\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nマニフェストへのフィールド追加\nエージェントプロバイダーの定義\nエージェント戦略の定義と実装\n定義\n機能実装",
        "error": null
      },
      {
        "link_index": 19,
        "link_text": "Model",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/model",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nTermbase\nModel(モデル)\nCopy page\n\nモデルインターフェースには以下の内容が含まれます：\n\nモデル設計ルール.md\n\nモデル設計ルール.md\n\nモデルスキーマ.md\n\nモデルスキーマ.md\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify",
        "error": null
      },
      {
        "link_index": 20,
        "link_text": "モデル設計規則",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/model/model-designing-rules",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\nModel\nモデル設計規則\nモデルスキーマ\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nModel\nモデル設計規則\nCopy page\nモデルプロバイダーのルールは、Provider エンティティに基づいています。\nモデルルールは、AIModelEntity エンティティに基づいています。\n\n以下のすべてのエンティティは Pydantic BaseModel をベースにしており、entities モジュール内で対応するエンティティを見つけることができます。\n\n​\nProvider（プロバイダ）\nprovider (string) プロバイダー識別子。例：openai\nlabel (object) プロバイダーの表示名。多言語対応で、英語（en_US）と中国語（zh_Hans）の2言語を設定できます。\nzh_Hans (string) [optional] 中国語のラベル名。zh_Hans が設定されていない場合は、デフォルトで en_US が使用されます。\nen_US (string) 英語のラベル名\ndescription (object) [optional] プロバイダーの説明。多言語対応。\nzh_Hans (string) [optional] 中国語の説明\nen_US (string) 英語の説明\nicon_small (string) [optional] プロバイダーの小さなアイコン。対応するプロバイダーの実装ディレクトリ下の _assets ディレクトリに保存されます。英語と中国語の扱い方は label と同様です。\nzh_Hans (string) [optional] 中国語のアイコン\nen_US (string) 英語のアイコン\nicon_large (string) [optional] プロバイダーの大きなアイコン。対応するプロバイダーの実装ディレクトリ下の _assets ディレクトリに保存されます。英語と中国語の扱い方は label と同様です。\nzh_Hans (string) [optional] 中国語のアイコン\nen_US (string) 英語のアイコン\nbackground (string) [optional] 背景色のカラーコード。例：#FFFFFF。値が設定されていない場合は、フロントエンドのデフォルト色が使用されます。\nhelp (object) [optional] ヘルプ情報\ntitle (object) ヘルプタイトル。多言語対応。\nzh_Hans (string) [optional] 中国語のタイトル\nen_US (string) 英語のタイトル\nurl (object) ヘルプリンク。多言語対応。\nzh_Hans (string) [optional] 中国語のリンク\nen_US (string) 英語のリンク\nsupported_model_types (array[ModelType]) サポートされているモデルタイプ\nconfigurate_methods (array[ConfigurateMethod]) 設定方法\nprovider_credential_schema ([ProviderCredentialSchema]) プロバイダーの認証情報スキーマ（プロバイダーの資格情報仕様）\nmodel_credential_schema ([ModelCredentialSchema]) モデルの認証情報スキーマ（モデルの資格情報仕様）\n​\nAIModelEntity（AIモデルエンティティ）\nmodel (string) モデル識別子。例：gpt-3.5-turbo\nlabel (object) [optional] モデルの表示名。多言語対応で、英語（en_US）と中国語（zh_Hans）の2言語を設定できます。\nzh_Hans (string) [optional] 中国語のラベル名\nen_US (string) 英語のラベル名\nmodel_type ([ModelType](#ModelType)) モデルタイプ\nfeatures (array[[ModelFeature](#ModelFeature)]) [optional] サポートされている機能リスト\nmodel_properties (object) モデルのプロパティ\nmode ([LLMMode](#LLMMode)) モード（モデルタイプ llm で利用可能）\ncontext_size (int) コンテキストサイズ（モデルタイプ llm、text-embedding で利用可能）\nmax_chunks (int) 最大チャンク数（モデルタイプ text-embedding、moderation で利用可能）\nfile_upload_limit (int) ファイルの最大アップロード制限（単位：MB）。（モデルタイプ speech2text で利用可能）\nsupported_file_extensions (string) サポートされているファイル拡張子形式。例：mp3、mp4（モデルタイプ speech2text の場合）\ndefault_voice (string) デフォルトのボイス。必須：alloy,echo,fable,onyx,nova,shimmer（モデルタイプ tts で利用可能）\nvoices (list) 選択可能なボイスリスト。\nmode (string) ボイスモデル。（モデルタイプ tts で利用可能）\nname (string) ボイスモデルの表示名。（モデルタイプ tts で利用可能）\nlanguage (string) ボイスモデルがサポートする言語。（モデルタイプ tts で利用可能）\nword_limit (int) 1回の変換における文字数制限。デフォルトでは段落ごとに区切られます。（モデルタイプ tts で利用可能）\naudio_type (string) サポートされているオーディオファイルの拡張子形式。例：mp3、wav（モデルタイプ tts で利用可能）\nmax_workers (int) テキストからオーディオへの変換をサポートする同時実行タスク数。（モデルタイプ tts で利用可能）\nmax_characters_per_chunk (int) 1チャンクあたりの最大文字数（モデルタイプ moderation で利用可能）\nparameter_rules (array[ParameterRule]) [optional] モデル呼び出しパラメータのルール\npricing ([PriceConfig]) [optional] 価格情報\ndeprecated (bool) 非推奨かどうか。非推奨の場合、モデルリストには表示されなくなりますが、すでに設定済みのものは引き続き使用できます。デフォルトは False です。\n​\nModelType（モデルタイプ）\nllm テキスト生成モデル\ntext-embedding テキスト埋め込みモデル\nrerank Rerank モデル\nspeech2text 音声テキスト変換\ntts テキスト音声変換\nmoderation 審査\n​\nConfigurateMethod（構成方法）\npredefined-model 既定モデル\n\nユーザーは、統一されたプロバイダーの認証情報を設定するだけで、プロバイダーの既定モデルを利用できます。\n\ncustomizable-model カスタムモデル\n\nユーザーは、各モデルの認証情報設定を個別に追加する必要があります。\n\nfetch-from-remote リモートから取得\n\npredefined-model の設定方法と同様に、統一されたプロバイダーの認証情報を設定するだけで済みます。モデルは認証情報を通じてプロバイダーから取得されます。\n\n​\nModelFeature（モデル機能）\nagent-thought エージェントの推論。通常、70B を超えるモデルには思考連鎖能力があります。\nvision ビジョン、つまり画像理解。\ntool-call ツール呼び出し\nmulti-tool-call 複数ツール呼び出し\nstream-tool-call ストリームツール呼び出し\n​\nFetchFrom（入手先）\npredefined-model 既定モデル\nfetch-from-remote リモートモデル\n​\nLLMMode（LLMモード）\ncompletion テキスト補完\nchat 対話\n​\nParameterRule（パラメータールール）\nname (string) モデルを呼び出す際の実際のパラメータ名\nuse_template (string) [optional] テンプレートを使用\n\nデフォルトでは、5つの変数設定テンプレートが用意されています。\n\ntemperature\ntop_p\nfrequency_penalty\npresence_penalty\nmax_tokens\n\nuse_template でテンプレート変数名を直接設定すると、entities.defaults.PARAMETER_RULE_TEMPLATE のデフォルト設定が使用され、name と use_template 以外のすべてのパラメータを設定する必要はありません。追加の設定パラメータを設定した場合、デフォルト設定が上書きされます。openai/llm/gpt-3.5-turbo.yaml を参照してください。\n\nlabel (object) [optional] ラベル。多言語対応。\nzh_Hans (string) [optional] 中国語のラベル名\nen_US (string) 英語のラベル名\ntype (string) [optional] パラメータのタイプ\nint 整数\nfloat 浮動小数点数\nstring 文字列\nboolean ブール型\nhelp (string) [optional] ヘルプ情報\nzh_Hans (string) [optional] 中国語のヘルプ情報\nen_US (string) 英語のヘルプ情報\nrequired (bool) 必須かどうか。デフォルトは False です。\ndefault (int/float/string/bool) [optional] デフォルト値\nmin (int/float) [optional] 最小値。数値型のみ適用。\nmax (int/float) [optional] 最大値。数値型のみ適用。\nprecision (int) [optional] 精度。小数点以下の桁数。数値型のみ適用。\noptions (array[string]) [optional] ドロップダウンの選択肢。type が string の場合にのみ適用。設定しない、または null の場合は選択肢を制限しません。\n​\nPriceConfig（価格設定）\ninput (float) 入力単価。つまり、Prompt の単価。\noutput (float) 出力単価。つまり、返される内容の単価。\nunit (float) 価格単位。例：1M トークン単位で価格設定する場合、単価に対応するトークン数は 0.000001 になります。\ncurrency (string) 通貨単位\n​\nProviderCredentialSchema（プロバイダー資格情報スキーマ）\ncredential_form_schemas (array[CredentialFormSchema]) 資格情報フォームの仕様\n​\nModelCredentialSchema（モデル認証情報スキーマ）\nmodel (object) モデル識別子。変数名はデフォルトで model です。\nlabel (object) モデルフォーム項目の表示名\nen_US (string) 英語\nzh_Hans (string) [optional] 中国語\nplaceholder (object) モデルのプレースホルダー\nen_US (string) 英語\nzh_Hans (string) [optional] 中国語\ncredential_form_schemas (array[CredentialFormSchema]) 資格情報フォームの仕様\n​\nCredentialFormSchema（資格情報フォームスキーマ）\nvariable (string) フォーム項目の変数名\nlabel (object) フォーム項目のラベル名\nen_US (string) 英語\nzh_Hans (string) [optional] 中国語\ntype ([FormType](#FormType)) フォーム項目のタイプ\nrequired (bool) 必須かどうか\ndefault (string) デフォルト値\noptions (array[FormOption]) フォーム項目が select または radio の場合の専用属性。ドロップダウンの内容を定義します。\nplaceholder (object) フォーム項目が text-input の場合の専用属性。フォーム項目のプレースホルダー。\nen_US (string) 英語\nzh_Hans (string) [optional] 中国語\nmax_length (int) フォーム項目が text-input の場合の専用属性。入力の最大長を定義します。0 は制限なし。\nshow_on (array[FormShowOnObject]) 他のフォーム項目の値が条件を満たす場合に表示します。空の場合は常に表示します。\n​\nFormType（フォームタイプ）\ntext-input テキスト入力コンポーネント\nsecret-input パスワード入力コンポーネント\nselect 単一選択ドロップダウン\nradio ラジオコンポーネント\nswitch スイッチコンポーネント。true と false のみをサポート。\n​\nFormOption（フォームオプション）\nlabel (object) ラベル\nen_US (string) 英語\nzh_Hans (string) [optional] 中国語\nvalue (string) ドロップダウンの選択肢の値\nshow_on (array[FormShowOnObject]) 他のフォーム項目の値が条件を満たす場合に表示します。空の場合は常に表示します。\n​\nFormShowOnObject（フォーム表示オブジェクト）\nvariable (string) 他のフォーム項目の変数名\nvalue (string) 他のフォーム項目の値\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nModel\nモデルスキーマ\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nProvider（プロバイダ）\nAIModelEntity（AIモデルエンティティ）\nModelType（モデルタイプ）\nConfigurateMethod（構成方法）\nModelFeature（モデル機能）\nFetchFrom（入手先）\nLLMMode（LLMモード）\nParameterRule（パラメータールール）\nPriceConfig（価格設定）\nProviderCredentialSchema（プロバイダー資格情報スキーマ）\nModelCredentialSchema（モデル認証情報スキーマ）\nCredentialFormSchema（資格情報フォームスキーマ）\nFormType（フォームタイプ）\nFormOption（フォームオプション）\nFormShowOnObject（フォーム表示オブジェクト）",
        "error": null
      },
      {
        "link_index": 21,
        "link_text": "モデルスキーマ",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/model/model-schema",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\nModel\nモデル設計規則\nモデルスキーマ\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nModel\nモデルスキーマ\nCopy page\n\nここでは、プロバイダーと各モデルタイプが実装する必要があるインターフェースメソッドとパラメータについて説明します。\n\n​\nモデルプロバイダー\n\n__base.model_provider.ModelProvider 基底クラスを継承し、以下のインターフェースを実装します。\n\nCopy\ndef validate_provider_credentials(self, credentials: dict) -> None:\n    \"\"\"\n    Validate provider credentials\n    You can choose any validate_credentials method of model type or implement validate method by yourself,\n    such as: get model list api\n\n    if validate failed, raise exception\n\n    :param credentials: provider credentials, credentials form defined in `provider_credential_schema`.\n    \"\"\"\n\ncredentials (object): 認証情報\n\n認証情報のパラメータは、サプライヤーの YAML 設定ファイルの provider_credential_schemaで定義され、api_keyなどが渡されます。検証に失敗した場合は、errors.validate.CredentialsValidateFailedErrorエラーを発生させてください。注: プリ定義モデルはこのインターフェースを完全に実装する必要があります。カスタムモデルサプライヤーは、以下のような簡単な実装で十分です。\n\nCopy\nclass XinferenceProvider(Provider):\n    def validate_provider_credentials(self, credentials: dict) -> None:\n        pass\n\n​\nモデル\n\nモデルは5つの異なるモデルタイプに分類され、異なるモデルタイプは異なる基底クラスを継承し、実装する必要があるメソッドも異なります。\n\n​\n共通インターフェース\n\nすべてのモデルは、以下の2つのメソッドを共通して実装する必要があります。\n\nモデル認証情報の検証\n\nサプライヤーの認証情報検証と同様に、ここでは個々のモデルに対して検証を行います。\n\nCopy\ndef validate_credentials(self, model: str, credentials: dict) -> None:\n    \"\"\"\n    Validate model credentials\n\n    :param model: model name\n    :param credentials: model credentials\n    :return:\n    \"\"\"\n\n\nパラメータ:\n\nmodel (string): モデル名\ncredentials (object): 認証情報\n\n認証情報のパラメータは、サプライヤーの YAML 設定ファイルのprovider_credential_schemaまたはmodel_credential_schemaで定義され、api_keyなどが渡されます。検証に失敗した場合は、errors.validate.CredentialsValidateFailedErrorエラーを発生させてください。\n\n呼び出しエラーのマッピング\n\nモデルの呼び出し中に例外が発生した場合、Dify が異なるエラーに対して適切な後続処理を実行できるように、Runtime で定義されたInvokeErrorタイプにマッピングする必要があります。Runtime Errors:\n\nInvokeConnectionError: 呼び出し接続エラー\nInvokeServerUnavailableError: 呼び出しサービスが利用不可\nInvokeRateLimitError: 呼び出しがレート制限に達した\nInvokeAuthorizationError: 呼び出し認証失敗\nInvokeBadRequestError: 呼び出しパラメータエラー\nCopy\n@property\ndef _invoke_error_mapping(self) -> dict[type[InvokeError], list[type[Exception]]]:\n    \"\"\"\n    Map model invoke error to unified error\n    The key is the error type thrown to the caller\n    The value is the error type thrown by the model,\n    which needs to be converted into a unified error type for the caller.\n\n    :return: Invoke error mapping\n    \"\"\"\n\n\n対応するエラーを直接発生させ、以下のように定義することもできます。これにより、後続の呼び出しでInvokeConnectionErrorなどの例外を直接発生させることができます。\n\nはい、以下に修正後の翻訳を示します。\n\n​\nLLM\n\n__base.large_language_model.LargeLanguageModel 基底クラスを継承し、以下のインターフェースを実装します：\n\nLLM呼び出し\n\nLLMを呼び出すためのコアメソッドを実装します。ストリーミングと同期の両方の戻り値をサポートします。\n\nCopy\ndef _invoke(self, model: str, credentials: dict,\n            prompt_messages: list[PromptMessage], model_parameters: dict,\n            tools: Optional[list[PromptMessageTool]] = None, stop: Optional[list[str]] = None,\n            stream: bool = True, user: Optional[str] = None) \\\n        -> Union[LLMResult, Generator]:\n    \"\"\"\n    Invoke large language model\n\n    :param model: model name\n    :param credentials: model credentials\n    :param prompt_messages: prompt messages\n    :param model_parameters: model parameters\n    :param tools: tools for tool calling\n    :param stop: stop words\n    :param stream: is stream response\n    :param user: unique user id\n    :return: full response or stream response chunk generator result\n    \"\"\"\n\nパラメータ：\nmodel (string) モデル名\ncredentials (object) クレデンシャル\n\nクレデンシャルのパラメータは、ベンダーのYAML構成ファイルの provider_credential_schema または model_credential_schema で定義され、api_key などが渡されます。\n\nprompt_messages (array[PromptMessage]) プロンプト一覧\n\nモデルが Completion タイプの場合、リストにはUserPromptMessage 要素を1つだけ渡します。モデルが Chat タイプの場合、メッセージに応じてSystemPromptMessage、UserPromptMessage、AssistantPromptMessage、ToolPromptMessage 要素のリストを渡す必要があります。\n\n- model_parameters (object) モデルパラメータ。モデルパラメータは、モデルのYAML構成の parameter_rules で定義されます。\n\n- tools (array[PromptMessageTool]) [optional] ツール一覧。function calling における function と同等です。つまり、ツール呼び出しのためのツール一覧を渡します。\n\n- stop (array[string]) [optional] 停止シーケンス。モデルの出力は、停止シーケンスで定義された文字列の手前で停止します。\n\n- stream (bool) ストリーミング出力かどうか。デフォルトは True です。ストリーミング出力は Generator[LLMResultChunk] を返し、非ストリーミング出力は LLMResult を返します。\n\n- user (string) [optional] ユーザーの一意の識別子。ベンダーが不正行為を監視および検出するのに役立ちます。\n\n戻り値\n\nストリーミング出力は Generator[LLMResultChunk] を返し、非ストリーミング出力は LLMResult を返します。\n\n入力トークンの事前計算\n\nモデルがトークン数の事前計算インターフェースを提供していない場合は、直接0を返します。\n\nCopy\ndef get_num_tokens(self, model: str, credentials: dict, prompt_messages: list[PromptMessage],\n                   tools: Optional[list[PromptMessageTool]] = None) -> int:\n    \"\"\"\n    Get number of tokens for given prompt messages\n\n    :param model: model name\n    :param credentials: model credentials\n    :param prompt_messages: prompt messages\n    :param tools: tools for tool calling\n    :return:\n    \"\"\"\n\n\nパラメータの説明は上記の「LLM呼び出し」を参照してください。このインターフェースは、対応する model に応じて適切な tokenizer を選択して計算する必要があります。対応するモデルが tokenizer を提供していない場合は、AIModel 基底クラスの _get_num_tokens_by_gpt2(text: str) メソッドを使用して計算できます。\n\nカスタマイズ可能なモデルスキーマの取得 [オプション]\nCopy\ndef get_customizable_model_schema(self, model: str, credentials: dict) -> Optional[AIModelEntity]:\n    \"\"\"\n    Get customizable model schema\n\n    :param model: model name\n    :param credentials: model credentials\n    :return: model schema\n    \"\"\"\n\n\nベンダーがカスタムLLMの追加をサポートしている場合、このメソッドを実装してカスタムモデルがモデルスキーマを取得できるようにできます。デフォルトでは None を返します。\n\nOpenAI ベンダーのほとんどのファインチューニングモデルでは、ファインチューニングモデルの名前（例：gpt-3.5-turbo-1106）からその基底クラスモデルを取得し、基底クラスモデルの事前定義されたパラメータルールを返すことができます。具体的な実装については、OpenAI を参照してください。\n\n​\nTextEmbedding\n\n__base.text_embedding_model.TextEmbeddingModel 基底クラスを継承し、以下のインターフェースを実装します。\n\nEmbedding呼び出し\nCopy\ndef _invoke(self, model: str, credentials: dict,\n            texts: list[str], user: Optional[str] = None) \\\n        -> TextEmbeddingResult:\n    \"\"\"\n    Invoke large language model\n\n    :param model: model name\n    :param credentials: model credentials\n    :param texts: texts to embed\n    :param user: unique user id\n    :return: embeddings result\n    \"\"\"\n\nパラメータ：\n\n\n- model (string) モデル名\n\n\n- credentials (object) クレデンシャル\n\nクレデンシャルのパラメータは、ベンダーのYAML構成ファイルの provider_credential_schema または model_credential_schema で定義され、api_key などが渡されます。\n\n\n- texts (array[string]) テキスト一覧。バッチ処理が可能です。\n\n\n- user (string) [optional] ユーザーの一意の識別子。\nベンダーが不正行為を監視および検出するのに役立ちます。\n\n戻り値：\n\nTextEmbeddingResult エンティティ。\n\nトークンの事前計算\nCopy\ndef get_num_tokens(self, model: str, credentials: dict, texts: list[str]) -> int:\n    \"\"\"\n    Get number of tokens for given prompt messages\n\n    :param model: model name\n    :param credentials: model credentials\n    :param texts: texts to embed\n    :return:\n    \"\"\"\n\n\nパラメータの説明は上記の「Embedding呼び出し」を参照してください。\n\n上記の LargeLanguageModel と同様に、このインターフェースは対応する model に応じて適切な tokenizer を選択して計算する必要があります。対応するモデルが tokenizer を提供していない場合は、AIModel 基底クラスの _get_num_tokens_by_gpt2(text: str) メソッドを使用して計算できます。\n\n​\nRerank\n\n__base.rerank_model.RerankModel 基底クラスを継承し、以下のインターフェースを実装します。\n\nrerank呼び出し\nCopy\ndef _invoke(self, model: str, credentials: dict,\n            query: str, docs: list[str], score_threshold: Optional[float] = None, top_n: Optional[int] = None,\n            user: Optional[str] = None) \\\n        -> RerankResult:\n    \"\"\"\n    Invoke rerank model\n\n    :param model: model name\n    :param credentials: model credentials\n    :param query: search query\n    :param docs: docs for reranking\n    :param score_threshold: score threshold\n    :param top_n: top n\n    :param user: unique user id\n    :return: rerank result\n    \"\"\"\n\nパラメータ：\n\n\n- model (string) モデル名\n- credentials (object) クレデンシャル\nクレデンシャルのパラメータは、ベンダーのYAML構成ファイルの provider_credential_schema または model_credential_schema で定義され、api_key などが渡されます。\n- query (string) 検索クエリ\n- docs (array[string]) 並べ替え対象のテキストリスト\n- score_threshold (float) [optional] スコア閾値\n- top_n (int) [optional] 上位n件のテキストを取得\n- user (string) [optional] ユーザーの一意の識別子\nベンダーが不正行為を監視および検出するのに役立ちます。\n\n戻り値：\n\nRerankResult エンティティ。\n\n​\nSpeech2text(音声テキスト変換)\n\n\n__base.speech2text_model.Speech2TextModel 基底クラスを継承\n\nInvoke呼び出し\nCopy\ndef _invoke(self, model: str, credentials: dict,\n            file: IO[bytes], user: Optional[str] = None) \\\n        -> str:\n    \"\"\"\n    Invoke large language model\n\n    :param model: model name\n    :param credentials: model credentials\n    :param file: audio file\n    :param user: unique user id\n    :return: text for given audio file\n    \"\"\"        \n\nパラメータ：\n\n\n- model (string) モデル名\n- credentials (object) クレデンシャル\nクレデンシャルのパラメータは、ベンダーのYAML構成ファイルの provider_credential_schema または model_credential_schema で定義され、api_key などが渡されます。\n- file (File) ファイルストリーム\n- user (string) [optional] ユーザーの一意の識別子\nベンダーが不正行為を監視および検出するのに役立ちます。\n\n戻り値：\n\n音声変換された文字列。\n\nはい、以下に修正後の翻訳を示します。直訳の問題点を踏まえ、より自然で分かりやすい日本語になるように調整しました。\n\n​\nText2speech (テキスト音声変換)\n\n__base.text2speech_model.Text2SpeechModel を継承し、以下のインターフェースを実装します。\n\nInvoke (呼び出し)\nCopy\ndef _invoke(self, model: str, credentials: dict, content_text: str, streaming: bool, user: Optional[str] = None):\n    \"\"\"\n    Invoke large language model\n\n    :param model: model name\n    :param credentials: model credentials\n    :param content_text: text content to be translated\n    :param streaming: output is streaming\n    :param user: unique user id\n    :return: translated audio file\n    \"\"\"        \n\n\nパラメータ：\n\nmodel (string): モデル名\ncredentials (object): 認証情報\n認証情報のパラメータは、ベンダーの YAML 設定ファイルの provider_credential_schema または model_credential_schema で定義され、api_key などが渡されます。\ncontent_text (string): 変換するテキストコンテンツ\nstreaming (bool): ストリーミング出力を行うかどうか\nuser (string) [オプション]: ユーザーの一意な識別子\nベンダーが不正利用を監視・検出するのに役立ちます。\n\n戻り値：\n\nテキスト変換後の音声ストリーム。\n\n​\nModeration (モデレーション)\n\n__base.moderation_model.ModerationModel を継承し、以下のインターフェースを実装します。\n\nInvoke (呼び出し)\nCopy\ndef _invoke(self, model: str, credentials: dict,\n            text: str, user: Optional[str] = None) \\\n        -> bool:\n    \"\"\"\n    Invoke large language model\n\n    :param model: model name\n    :param credentials: model credentials\n    :param text: text to moderate\n    :param user: unique user id\n    :return: false if text is safe, true otherwise\n    \"\"\"\n\n\nパラメータ：\n\nmodel (string): モデル名\ncredentials (object): 認証情報\n認証情報のパラメータは、ベンダーの YAML 設定ファイルの provider_credential_schema または model_credential_schema で定義され、api_key などが渡されます。\ntext (string): テキストコンテンツ\nuser (string) [オプション]: ユーザーの一意な識別子\nベンダーが不正利用を監視・検出するのに役立ちます。\n\n戻り値：\n\n入力テキストが安全な場合は False、そうでない場合は True を返します。\n\n​\nEntity(エンティティ)\n​\nPromptMessageRole (プロンプトメッセージの役割)\n\nメッセージの役割を定義する列挙型です。\n\nCopy\nclass PromptMessageRole(Enum):\n    \"\"\"\n    Enum class for prompt message.\n    \"\"\"\n    SYSTEM = \"system\"\n    USER = \"user\"\n    ASSISTANT = \"assistant\"\n    TOOL = \"tool\"\n\n​\nPromptMessageContentType (プロンプトメッセージのコンテンツタイプ)\n\nメッセージコンテンツのタイプを定義する列挙型です。テキストと画像の2種類があります。\n\nCopy\nclass PromptMessageContentType(Enum):\n    \"\"\"\n    Enum class for prompt message content type.\n    \"\"\"\n    TEXT = 'text'\n    IMAGE = 'image'\n\n​\nPromptMessageContent (プロンプトメッセージのコンテンツ)\n\nメッセージコンテンツの基底クラスです。パラメータ定義のみに用いられ、直接の初期化はできません。\n\nCopy\nclass PromptMessageContent(BaseModel):\n    \"\"\"\n    Model class for prompt message content.\n    \"\"\"\n    type: PromptMessageContentType\n    data: str  # コンテンツデータ\n\n\n現在、テキストと画像の2種類のタイプがサポートされており、テキストと複数の画像を同時に渡すことができます。それぞれ TextPromptMessageContent および ImagePromptMessageContent を初期化して渡す必要があります。\n\n​\nTextPromptMessageContent\nCopy\nclass TextPromptMessageContent(PromptMessageContent):\n    \"\"\"\n    テキストプロンプトメッセージのコンテンツを定義するモデルクラスです。\n    \"\"\"\n    type: PromptMessageContentType = PromptMessageContentType.TEXT\n\n\nテキストと画像を同時に送信する場合、テキストはこのエンティティを content リストの一部として構成する必要があります。\n\n​\nImagePromptMessageContent\nCopy\nclass ImagePromptMessageContent(PromptMessageContent):\n    \"\"\"\n    Model class for image prompt message content.\n    \"\"\"\n    class DETAIL(Enum):\n        LOW = 'low'\n        HIGH = 'high'\n\n    type: PromptMessageContentType = PromptMessageContentType.IMAGE\n    detail: DETAIL = DETAIL.LOW  # 解像度\n\n\n画像とテキストを同時に送信する場合、画像はこのエンティティを content リストの一部として構成する必要があります。\ndata には、画像の url または base64 エンコードされた文字列を指定できます。\n\n​\nPromptMessage\n\nすべての Role メッセージの基底クラスで、パラメータ定義のみに使用され、インスタンス化はできません。\n\nCopy\nclass PromptMessage(ABC, BaseModel):\n    \"\"\"\n    Model class for prompt message.\n    \"\"\"\n    role: PromptMessageRole  # メッセージの役割\n    content: Optional[str | list[PromptMessageContent]] = None  # 文字列またはコンテンツリストのいずれかを指定できます。コンテンツリストはマルチモーダルに対応するためのもので、詳細は PromptMessageContent の説明を参照してください。\n    name: Optional[str] = None  # 名前（オプション）\n\n​\nUserPromptMessage\n\nユーザーメッセージを表す UserMessage のメッセージボディです。\n\nCopy\nclass UserPromptMessage(PromptMessage):\n    \"\"\"\n    Model class for user prompt message.\n    \"\"\"\n    role: PromptMessageRole = PromptMessageRole.USER\n\n​\nAssistantPromptMessage\n\nモデルからの応答メッセージを表し、通常は few-shots やチャット履歴の入力に使用されます。\n\nCopy\nclass AssistantPromptMessage(PromptMessage):\n    \"\"\"\n    Model class for assistant prompt message.\n    \"\"\"\n    class ToolCall(BaseModel):\n        \"\"\"\n        Model class for assistant prompt message tool call.\n        \"\"\"\n        class ToolCallFunction(BaseModel):\n            \"\"\"\n            Model class for assistant prompt message tool call function.\n            \"\"\"\n            name: str  # ツールの名前\n            arguments: str  # ツールの引数\n\n        id: str  # ツールID。OpenAI のツール呼び出しでのみ有効で、ツール呼び出しの一意なIDです。同じツールを複数回呼び出すことができます。\n        type: str  # デフォルトは function\n        function: ToolCallFunction  # ツール呼び出し情報\n\n    role: PromptMessageRole = PromptMessageRole.ASSISTANT\n    tool_calls: list[ToolCall] = []  # モデルが応答したツール呼び出しの結果です（tools が渡され、モデルがツールを呼び出す必要があると判断した場合のみ返されます）。\n\n\ntool_calls は、モデルに tools が渡された後、モデルから返されるツール呼び出しのリストです。\n\n​\nSystemPromptMessage\n\nシステムメッセージを表し、通常はモデルにシステム命令を設定するために使用されます。\n\nCopy\nclass SystemPromptMessage(PromptMessage):\n    \"\"\"\n    Model class for system prompt message.\n    \"\"\"\n    role: PromptMessageRole = PromptMessageRole.SYSTEM\n\n​\nToolPromptMessage\n\nツールメッセージを表し、ツールの実行結果をモデルに渡して、次の計画を立てるために使用されます。\n\nCopy\nclass ToolPromptMessage(PromptMessage):\n    \"\"\"\n    Model class for tool prompt message.\n    \"\"\"\n    role: PromptMessageRole = PromptMessageRole.TOOL\n    tool_call_id: str  # ツール呼び出しID。OpenAI のツール呼び出しをサポートしない場合は、ツール名を渡すこともできます。\n\n\n基底クラスの content にはツールの実行結果を渡します。\n\n​\nPromptMessageTool\nCopy\nclass PromptMessageTool(BaseModel):\n    \"\"\"\n    Model class for prompt message tool.\n    \"\"\"\n    name: str  # ツール名\n    description: str  # ツールの説明\n    parameters: dict  # ツールパラメータ（辞書形式）\n\n​\nLLMResult\nCopy\nclass LLMResult(BaseModel):\n    \"\"\"\n    Model class for llm result.\n    \"\"\"\n    model: str  # 使用モデル\n    prompt_messages: list[PromptMessage]  # プロンプトメッセージリスト\n    message: AssistantPromptMessage  # 返信メッセージ\n    usage: LLMUsage  # トークン及び費用情報\n    system_fingerprint: Optional[str] = None  # リクエスト指紋（OpenAIの定義に準拠）\n\n​\nLLMResultChunkDelta\n\nストリーミング結果の各イテレーションにおける差分エンティティ\n\nCopy\nclass LLMResultChunkDelta(BaseModel):\n    \"\"\"\n    Model class for llm result chunk delta.\n    \"\"\"\n    index: int  # 順番\n    message: AssistantPromptMessage  # 返信メッセージ\n    usage: Optional[LLMUsage] = None  # トークン及び費用情報（最後のチャンクのみ）\n    finish_reason: Optional[str] = None  # 終了理由（最後のチャンクのみ）\n\n​\nLLMResultChunk\n\nストリーミング結果の各イテレーションエンティティ\n\nCopy\nclass LLMResultChunk(BaseModel):\n    \"\"\"\n    Model class for llm result chunk.\n    \"\"\"\n    model: str  # 使用モデル\n    prompt_messages: list[PromptMessage]  # プロンプトメッセージリスト\n    system_fingerprint: Optional[str] = None  # リクエスト指紋（OpenAIの定義に準拠）\n    delta: LLMResultChunkDelta  # 各イテレーションで変化する内容\n\n​\nLLMUsage\nCopy\nclass LLMUsage(ModelUsage):\n    \"\"\"\n    Model class for llm usage.\n    \"\"\"\n    prompt_tokens: int  # プロンプト使用トークン数\n    prompt_unit_price: Decimal  # プロンプト単価\n    prompt_price_unit: Decimal  # プロンプト価格単位（単価が適用されるトークン数）\n    prompt_price: Decimal  # プロンプト料金\n    completion_tokens: int  # 回答使用トークン数\n    completion_unit_price: Decimal  # 回答単価\n    completion_price_unit: Decimal  # 回答価格単位（単価が適用されるトークン数）\n    completion_price: Decimal  # 回答料金\n    total_tokens: int  # 総使用トークン数\n    total_price: Decimal  # 総料金\n    currency: str  # 通貨単位\n    latency: float  # リクエスト処理時間（秒）\n\n​\nTextEmbeddingResult\nCopy\nclass TextEmbeddingResult(BaseModel):\n    \"\"\"\n    Model class for text embedding result.\n    \"\"\"\n    model: str  # 使用モデル\n    embeddings: list[list[float]]  # 埋め込みベクトルリスト（テキストに対応）\n    usage: EmbeddingUsage  # 使用情報\n\n​\nEmbeddingUsage\nCopy\nclass EmbeddingUsage(ModelUsage):\n    \"\"\"\n    Model class for embedding usage.\n    \"\"\"\n    tokens: int  # 使用トークン数\n    total_tokens: int  # 総使用トークン数\n    unit_price: Decimal  # 単価\n    price_unit: Decimal  # 価格単位（単価が適用されるトークン数）\n    total_price: Decimal  # 総料金\n    currency: str  # 通貨単位\n    latency: float  # リクエスト処理時間（秒）\n\n​\nRerankResult\nCopy\nclass RerankResult(BaseModel):\n    \"\"\"\n    Model class for rerank result.\n    \"\"\"\n    model: str  # 使用モデル\n    docs: list[RerankDocument]  # リランク後のドキュメントリスト\n\n​\nRerankDocument\nCopy\nclass RerankDocument(BaseModel):\n    \"\"\"\n    Model class for rerank document.\n    \"\"\"\n    index: int  # 元の順番\n    text: str  # ドキュメントテキスト\n    score: float  # スコア\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nモデル設計規則\n一般的な標準仕様\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nモデルプロバイダー\nモデル\n共通インターフェース\nLLM\nTextEmbedding\nRerank\nSpeech2text(音声テキスト変換)\nText2speech (テキスト音声変換)\nModeration (モデレーション)\nEntity(エンティティ)\nPromptMessageRole (プロンプトメッセージの役割)\nPromptMessageContentType (プロンプトメッセージのコンテンツタイプ)\nPromptMessageContent (プロンプトメッセージのコンテンツ)\nTextPromptMessageContent\nImagePromptMessageContent\nPromptMessage\nUserPromptMessage\nAssistantPromptMessage\nSystemPromptMessage\nToolPromptMessage\nPromptMessageTool\nLLMResult\nLLMResultChunkDelta\nLLMResultChunk\nLLMUsage\nTextEmbeddingResult\nEmbeddingUsage\nRerankResult\nRerankDocument",
        "error": null
      },
      {
        "link_index": 22,
        "link_text": "一般的な標準仕様",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/general-specifications",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nスキーマ仕様\n一般的な標準仕様\nCopy page\n\n本文では、プラグイン開発における共通構造について簡単に説明します。\n\n​\nパス仕様\n\nマニフェストまたは任意のyamlファイルでファイルパスを指定する場合、ファイルタイプに基づいて以下の2つのルールに従ってください：\n\n画像や動画などのマルチメディアファイル（例：プラグインのicon）の場合、プラグインのルートディレクトリの下の_assetsフォルダに配置します。\n.pyや.yamlなどの通常のテキストファイルの場合、プラグインプロジェクト内の絶対パスを使用します。\n​\n共通構造\n\nプラグインを定義する際、ツール、モデル、インターフェース間で共有できるデータ構造があります。以下がこれらの共有構造です。\n\n​\nI18nObject\n\nI18nObjectは、IETF BCP 47標準に準拠した国際化構造で、現在4つの言語をサポートしています：\n\nen_US\nzh_Hans\nja_Jp\npt_BR\n​\nProviderConfig\n\nProviderConfigは、ToolとEndpointの両方に適用可能な共通プロバイダーフォーム構造です。\n\nname (string): フォーム項目名\nlabel (I18nObject, 必須): IETF BCP 47に準拠\ntype (provider_config_type, 必須): フォームタイプ\nscope (provider_config_scope): オプション範囲、typeにより異なる\nrequired (bool): 空にできない\ndefault (any): デフォルト値、基本タイプfloat int stringのみサポート\noptions (list[provider_config_option]): オプション、typeがselectの場合のみ使用\nhelper (object): ヘルプドキュメントリンクラベル、IETF BCP 47に準拠\nurl (string): ヘルプドキュメントリンク\nplaceholder (object): IETF BCP 47に準拠\n​\nProviderConfigOption(object)\nvalue(string, 必須)：値\nlabel(object, 必須)：IETF BCP 47に準拠\n​\nProviderConfigType(string)\nsecret-input (string)：設定情報が暗号化される\ntext-input(string)：プレーンテキスト\nselect(string)：ドロップダウンボックス\nboolean(bool)：スイッチ\nmodel-selector(object)：プロバイダー名、モデル名、モデルパラメータなどを含むモデル設定情報\napp-selector(object)：アプリID\ntool-selector(object)：ツールプロバイダー、名前、パラメータなどを含むツール設定情報\ndataset-selector(string)：TBD\n​\nProviderConfigScope(string)\ntypeがmodel-selectorの場合\nall\nllm\ntext-embedding\nrerank\ntts\nspeech2text\nmoderation\nvision\ntypeがapp-selectorの場合\nall\nchat\nworkflow\ncompletion\ntypeがtool-selectorの場合\nall\nplugin\napi\nworkflow\n​\nModelConfig\nprovider (string): プラグインIDを含むプロバイダー名、形式はlanggenius/openai/openai\nmodel (string): 具体的なモデル名\nmodel_type (enum): モデルタイプの列挙、このドキュメントを参照\n​\nNodeResponse\ninputs (dict): ノードに最終的に入力される変数\noutputs (dict): ノード出力結果\nprocess_data (dict): ノード実行中に生成されたデータ\n​\nToolSelector\nprovider_id (string): ツールプロバイダー名\ntool_name (string): ツール名\ntool_description (string): ツールの説明\ntool_configuration (dict[str, Any]): ツール設定情報\ntool_parameters (dict[str, dict]): LLM推論が必要なパラメータ\nname (string): パラメータ名\ntype (string): パラメータタイプ\nrequired (bool): 必須かどうか\ndescription (string): パラメータの説明\ndefault (any): デフォルト値\noptions (list[string]): 利用可能なオプション\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nモデルスキーマ\n永続化されたストレージ\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nパス仕様\n共通構造\nI18nObject\nProviderConfig\nProviderConfigOption(object)\nProviderConfigType(string)\nProviderConfigScope(string)\nModelConfig\nNodeResponse\nToolSelector",
        "error": null
      },
      {
        "link_index": 23,
        "link_text": "永続化されたストレージ",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/persistent-storage",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nスキーマ仕様\n永続化されたストレージ\nCopy page\n\nプラグイン内のToolとEndpointを個別に見ると、ほとんどの場合、単一のラウンドの対話、つまりリクエストを送信してデータを返し、タスクが終了するだけであることがわかります。\n\n長期的なデータの保存が必要な場合、例えば永続的なメモリを実装する場合、プラグインには永続的なストレージ機能が必要です。永続ストレージメカニズムにより、プラグインは同じWorkspace内でデータを永続的に保存する機能を持つことができます。現在はKVデータベースを提供してストレージのニーズを満たしており、将来的には実際の使用状況に基づいて、より柔軟で強力なストレージインターフェースを導入する可能性があります。\n\n​\nストレージキー\n​\nエントリーポイント\nCopy\n    self.session.storage\n\n​\nエンドポイント\nCopy\n    def set(self, key: str, val: bytes) -> None:\n        pass\n\n\nbytesが渡されることに注意してください。これにより、実際にファイルを保存することができます。\n\n​\nキーの取得\n​\nエントリーポイント\nCopy\n    self.session.storage\n\n​\nエンドポイント\nCopy\n    def get(self, key: str) -> bytes:\n        pass\n\n​\nキーの削除\n​\nエントリーポイント\nCopy\n    self.session.storage\n\n​\nエンドポイント\nCopy\n    def delete(self, key: str) -> None:\n        pass\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\n一般的な標準仕様\nReverse invocation of the dify service\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nストレージキー\nエントリーポイント\nエンドポイント\nキーの取得\nエントリーポイント\nエンドポイント\nキーの削除\nエントリーポイント\nエンドポイント",
        "error": null
      },
      {
        "link_index": 24,
        "link_text": "Reverse invocation of the dify service",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/reverse-invocation-of-the-dify-service",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nTermbase\nDifyサービスへのバックコール\nCopy page\n\nプラグインは、Difyメインプラットフォーム内の特定のサービスを自由に呼び出し、プラグインの機能を拡張できます。\n\n​\n呼び出し可能なDifyモジュール\n\nApp\n\nプラグインは、Difyプラットフォーム内のAppデータにアクセスできます。\n\nModel\n\nプラグインは、Difyプラットフォーム内のLLM機能をバックコールできます。これには、プラットフォーム内のすべてのモデルタイプと機能（TTS、Rerankなど）が含まれます。\n\nTool\n\nプラグインは、Difyプラットフォーム内の他のツールタイプのプラグインを呼び出すことができます。\n\nNode\n\nプラグインは、Difyプラットフォーム内の特定のChatflow/Workflowアプリケーション内のノードを呼び出すことができます。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\n呼び出し可能なDifyモジュール",
        "error": null
      },
      {
        "link_index": 25,
        "link_text": "アプリ",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/reverse-invocation-of-the-dify-service/app",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nReverse invocation of the dify service\nアプリ\nモデル\nツール\nノード\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nDifyサービスの逆呼び出し\nアプリ\nCopy page\n\nリバース呼び出しとは、プラグインがDify内のAppデータにアクセスできることを意味します。このモジュールは、ストリーミングと非ストリーミングの両方のAppコールをサポートしています。\n\n​\nエンドポイントタイプ：\nChatbot/Agent/Chatflowタイプのアプリケーションは、すべてチャットタイプのアプリケーションであり、同じ入力パラメータと出力パラメータを持つため、統一的にチャットインターフェースとして扱うことができます。\nWorkflowアプリケーションは、独立したワークフローインターフェースを占有します。\nCompletion（テキスト生成）アプリケーションは、独立したCompletionエンドポイントを占有します。\n\n注意：プラグインは、プラグインと同じWorkspace内のAppにのみアクセスできます。\n\n​\nチャットインターフェースのリクエスト エントリーポイント\n​\nエントリーポイント\nCopy\nself.session.app.chat\n\n​\nエンドポイント仕様\nCopy\ndef invoke(\n    self,\n    app_id: str,\n    inputs: dict,\n    response_mode: Literal[\"streaming\", \"blocking\"],\n    conversation_id: str,\n    files: list,\n) -> Generator[dict, None, None] | dict:\n    pass\n\n\nresponse_modeがstreamingの場合、インターフェースはGenerator[dict]を返し、それ以外の場合はdictを返します。具体的なインターフェースフィールドについては、ServiceApiの戻り値を参照してください。\n\n​\n例\n\nEndpoint内でチャットタイプのAppをリクエストし、結果を直接返すことができます：\n\nCopy\nimport json\nfrom typing import Mapping\nfrom werkzeug import Request, Response\nfrom dify_plugin import Endpoint\n\nclass Duck(Endpoint):\n    def _invoke(self, r: Request, values: Mapping, settings: Mapping) -> Response:\n        \"\"\"\n        与えられたリクエストでエンドポイントを呼び出します。\n        \"\"\"\n        app_id = values[\"app_id\"]\n        def generator():\n            response = self.session.app.workflow.invoke(\n                app_id=app_id, inputs={}, response_mode=\"streaming\", files=[]\n            )\n            for data in response:\n                yield f\"{json.dumps(data)} <br>\"\n        return Response(generator(), status=200, content_type=\"text/html\")\n\n\nワークフローエンドポイント エントリーポイント\n\n​\nエントリー\nCopy\nself.session.app.workflow\n\n​\nエンドポイント仕様\nCopy\ndef invoke(\n    self,\n    app_id: str,\n    inputs: dict,\n    response_mode: Literal[\"streaming\", \"blocking\"],\n    files: list,\n) -> Generator[dict, None, None] | dict:\n    pass\n\n​\nCompletionエンドポイントのリクエスト\n​\nエントリー\nCopy\nself.session.app.completion\n\n\nエンドポイント仕様\n\nCopy\ndef invoke(\n    self,\n    app_id: str,\n    inputs: dict,\n    response_mode: Literal[\"streaming\", \"blocking\"],\n    files: list,\n) -> Generator[dict, None, None] | dict:\n    pass\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nReverse invocation of the dify service\nモデル\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nエンドポイントタイプ：\nチャットインターフェースのリクエスト エントリーポイント\nエントリーポイント\nエンドポイント仕様\n例\nエントリー\nエンドポイント仕様\nCompletionエンドポイントのリクエスト\nエントリー",
        "error": null
      },
      {
        "link_index": 26,
        "link_text": "モデル",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/reverse-invocation-of-the-dify-service/model",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nReverse invocation of the dify service\nアプリ\nモデル\nツール\nノード\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nDifyサービスの逆呼び出し\nモデル\nCopy page\n\nリバースモデルリクエストとは、プラグインがDify内のLLM機能に対してリバースリクエストを行う能力を指し、TTS、Rerankなど、プラットフォーム上のすべてのモデルタイプと機能が含まれます。\n\nモデルのリクエストには、ModelConfigタイプのパラメータを渡す必要があることに注意してください。その構造は共通仕様定義で参照でき、この構造は異なるタイプのモデルで若干の違いがあります。\n\n例えば、LLMタイプのモデルの場合、completion_paramsとmodeパラメータを含める必要があります。この構造は手動で構築するか、model-selectorタイプのパラメータまたは設定を使用することができます。\n\n​\nLLMのリクエスト\n​\nエントリー\nCopy\nself.session.model.llm\n\n​\nエンドポイント：\nCopy\ndef invoke(\n    self,\n    model_config: LLMModelConfig,\n    prompt_messages: list[PromptMessage],\n    tools: list[PromptMessageTool] | None = None,\n    stop: list[str] | None = None,\n    stream: bool = True,\n) -> Generator[LLMResultChunk, None, None] | LLMResult:\n    pass\n\n\n注意：リクエストするモデルにtool_call機能がない場合、ここで渡されるツールは効果を持ちません。\n\n​\n例\n\nツールでOpenAIのgpt-4o-miniモデルをリクエストする場合は、以下のサンプルコードを参照してください：\n\nCopy\nfrom collections.abc import Generator\nfrom typing import Any\n\nfrom dify_plugin import Tool\nfrom dify_plugin.entities.model.llm import LLMModelConfig\nfrom dify_plugin.entities.tool import ToolInvokeMessage\nfrom dify_plugin.entities.model.message import SystemPromptMessage, UserPromptMessage\n\nclass LLMTool(Tool):\n    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage]:\n        response = self.session.model.llm.invoke(\n            model_config=LLMModelConfig(\n                provider='openai',\n                model='gpt-4o-mini',\n                mode='chat',\n                completion_params={}\n            ),\n            prompt_messages=[\n                SystemPromptMessage(\n                    content='you are a helpful assistant'\n                ),\n                UserPromptMessage(\n                    content=tool_parameters.get('query')\n                )\n            ],\n            stream=True\n        )\n\n        for chunk in response:\n            if chunk.delta.message:\n                assert isinstance(chunk.delta.message.content, str)\n                yield self.create_text_message(text=chunk.delta.message.content)\n\n\nコードではtool_parametersからqueryパラメータが渡されていることに注意してください。\n\n​\nベストプラクティス\n\nLLMModelConfigを手動で構築することは推奨されません。代わりに、UIでユーザーが希望のモデルを選択できるようにします。この場合、以下の設定に従ってmodelパラメータを追加することでツールのパラメータリストを変更できます：\n\nCopy\nidentity:\n  name: llm\n  author: Dify\n  label:\n    en_US: LLM\n    zh_Hans: LLM\n    pt_BR: LLM\ndescription:\n  human:\n    en_US: A tool for invoking a large language model\n    zh_Hans: 用于调用大型语言模型的工具\n    pt_BR: A tool for invoking a large language model\n  llm: A tool for invoking a large language model\nparameters:\n  - name: prompt\n    type: string\n    required: true\n    label:\n      en_US: Prompt string\n      zh_Hans: 提示字符串\n      pt_BR: Prompt string\n    human_description:\n      en_US: used for searching\n      zh_Hans: 用于搜索网页内容\n      pt_BR: used for searching\n    llm_description: key words for searching\n    form: llm\n  - name: model\n    type: model-selector\n    scope: llm\n    required: true\n    label:\n      en_US: Model\n      zh_Hans: 使用的模型\n      pt_BR: Model\n    human_description:\n      en_US: Model\n      zh_Hans: 使用的模型\n      pt_BR: Model\n    llm_description: which Model to invoke\n    form: form\nextra:\n  python:\n    source: tools/llm.py\n\n\nこの例では、モデルのスコープがllmとして指定されているため、ユーザーはllmタイプのパラメータのみを選択できることに注意してください。これにより、上記の例のコードを以下のように変更できます：\n\nCopy\nfrom collections.abc import Generator\nfrom typing import Any\n\nfrom dify_plugin import Tool\nfrom dify_plugin.entities.model.llm import LLMModelConfig\nfrom dify_plugin.entities.tool import ToolInvokeMessage\nfrom dify_plugin.entities.model.message import SystemPromptMessage, UserPromptMessage\n\nclass LLMTool(Tool):\n    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage]:\n        response = self.session.model.llm.invoke(\n            model_config=tool_parameters.get('model'),\n            prompt_messages=[\n                SystemPromptMessage(\n                    content='you are a helpful assistant'\n                ),\n                UserPromptMessage(\n                    content=tool_parameters.get('query')\n                )\n            ],\n            stream=True\n        )\n\n        for chunk in response:\n            if chunk.delta.message:\n                assert isinstance(chunk.delta.message.content, str)\n                yield self.create_text_message(text=chunk.delta.message.content)\n\n​\n要約のリクエスト\n\nこのエンドポイントを使用してテキストを要約することができます。現在のワークスペースのシステムモデルを使用してテキストを要約します。\n\nエントリー：\n\nCopy\nself.session.model.summary\n\n\nエンドポイント：\n\ntext: 要約するテキスト\ninstruction: 追加の指示。要約のスタイルをカスタマイズできます\nCopy\ndef invoke(\n    self, text: str, instruction: str,\n) -> str:\n\n\nテキスト埋め込みのリクエスト\n\nエントリー\n\nCopy\nself.session.model.text_embedding\n\n\nエンドポイント\n\nCopy\ndef invoke(\n    self, model_config: TextEmbeddingResult, texts: list[str]\n) -> TextEmbeddingResult:\n    pass\n\n​\nRerankのリクエスト\n​\nエントリー\nCopy\nself.session.model.rerank\n\n​\nエンドポイント\nCopy\ndef invoke(\n    self, model_config: RerankModelConfig, docs: list[str], query: str\n) -> RerankResult:\n    pass\n\n​\nTTSのリクエスト\n​\nエントリー\nCopy\nself.session.model.tts\n\n​\nエンドポイント\nCopy\ndef invoke(\n    self, model_config: TTSModelConfig, content_text: str\n) -> Generator[bytes, None, None]:\n    pass\n\n\n注意：TTSエンドポイントが返すバイトストリームはmp3オーディオバイトストリームで、各イテレーションで完全なオーディオを返します。より高度な処理タスクを実行したい場合は、適切なライブラリを選択してください。\n\n​\n音声認識のリクエスト\n\nエントリー：\n\nCopy\nself.session.model.speech2text\n\n\nエンドポイント：\n\nCopy\ndef invoke(\n    self, model_config: Speech2TextModelConfig, file: IO[bytes]\n) -> str:\n    pass\n\n\nここで、fileはmp3エンコードされたオーディオファイルです。\n\n​\nモデレーションのリクエスト\n\nエントリー：\n\nCopy\nself.session.model.moderation\n\n\nエンドポイント：\n\nCopy\ndef invoke(self, model_config: ModerationModelConfig, text: str) -> bool:\n    pass\n\n\nこのエンドポイントがtrueを返す場合、textに機密コンテンツが含まれていることを示します。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nアプリ\nツール\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nLLMのリクエスト\nエントリー\nエンドポイント：\n例\nベストプラクティス\n要約のリクエスト\nRerankのリクエスト\nエントリー\nエンドポイント\nTTSのリクエスト\nエントリー\nエンドポイント\n音声認識のリクエスト\nモデレーションのリクエスト",
        "error": null
      },
      {
        "link_index": 27,
        "link_text": "ツール",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/reverse-invocation-of-the-dify-service/tool",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nReverse invocation of the dify service\nアプリ\nモデル\nツール\nノード\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nDifyサービスの逆呼び出し\nツール\nCopy page\n\n以下のようなシナリオに遭遇した場合：\n\nツールタイププラグインが機能を実装したが、期待を満たしておらずデータの再処理が必要な場合\nタスクがWebクローリングを必要とし、クローリングサービスの選択に柔軟性が必要な場合\n複数のツールの戻り値を組み合わせる必要があるが、Workflowアプリケーションでの処理が困難な場合\n\nこれらの場合、プラグイン内の他の実装済みツールをリクエストする必要があります。これらのツールは、マーケットプレイスのツールプラグイン、自作のWorkflow as Tool、またはカスタムツールである可能性があります。\n\n上記の要件は、プラグインのself.session.toolフィールドを使用することで達成できます。\n\n​\nインストール済みツールのリクエスト\n\nプラグインが現在のWorkspaceにインストールされている様々なツール（他のツールタイププラグインを含む）をリクエストすることができます。\n\nエントリー：\n\nCopy\nself.session.tool\n\n\nエンドポイント：\n\nCopy\ndef invoke_builtin_tool(\n    self, provider: str, tool_name: str, parameters: dict[str, Any]\n) -> Generator[ToolInvokeMessage, None, None]:\n    pass\n\n\nここで、providerはプラグインIDとツールプロバイダー名を組み合わせたもので、langgenius/google/googleのような形式です。tool_nameは具体的なツール名、parametersはそのツールに渡すパラメータです。\n\n​\nWorkflow as Toolのリクエスト\n\nWorkflow as Toolの詳細については、このドキュメントを参照してください。\n\nエントリー：\n\nCopy\nself.session.tool\n\n\nエンドポイント：\n\nCopy\ndef invoke_workflow_tool(\n    self, provider: str, tool_name: str, parameters: dict[str, Any]\n) -> Generator[ToolInvokeMessage, None, None]:\n    pass\n\n\nここで、providerはツールのID、tool_nameはツール作成時に必要となります。\n\n​\nカスタムツールのリクエスト\n\nエントリー：\n\nCopy\nself.session.tool\n\n\nエンドポイント：\n\nCopy\ndef invoke_api_tool(\n    self, provider: str, tool_name: str, parameters: dict[str, Any]\n) -> Generator[ToolInvokeMessage, None, None]:\n    pass\n\n\nここで、providerはツールのID、tool_nameはOpenAPIのoperation_idです。存在しない場合は、Difyによって自動生成されたtool_nameで、ツール管理ページで確認できます。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nモデル\nノード\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nインストール済みツールのリクエスト\nWorkflow as Toolのリクエスト\nカスタムツールのリクエスト",
        "error": null
      },
      {
        "link_index": 28,
        "link_text": "ノード",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/reverse-invocation-of-the-dify-service/node",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nReverse invocation of the dify service\nアプリ\nモデル\nツール\nノード\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nDifyサービスの逆呼び出し\nノード\nCopy page\n\nリバースノードリクエストとは、プラグインがDifyのChatflow/Workflowアプリケーション内の特定のノードにアクセスする能力を指します。\n\nWorkflowのParameterExtractorとQuestionClassifierノードは、複雑なPromptとコードロジックをカプセル化しており、LLMを通じたハードコーディングでは解決が困難な多くのタスクを実行できます。プラグインはこれら2つのノードをリクエストすることができます。\n\n​\nパラメータ抽出ノードのリクエスト\n​\nエントリー\nCopy\nself.session.workflow_node.parameter_extractor\n\n​\nエンドポイント\nCopy\ndef invoke(\n    self,\n    parameters: list[ParameterConfig],\n    model: ModelConfig,\n    query: str,\n    instruction: str = \"\",\n) -> NodeResponse\n    pass\n\n\nここで、parametersは抽出するパラメータのリスト、modelはLLMModelConfig仕様に従い、queryはパラメータ抽出のソーステキスト、instructionはLLMへの追加指示を含み、NodeResponse構造はドキュメントで参照できます。\n\n​\n例\n\n会話から人の名前を抽出したい場合は、以下のコードを参照してください：\n\nCopy\nfrom collections.abc import Generator\nfrom dify_plugin.entities.tool import ToolInvokeMessage\nfrom dify_plugin import Tool\nfrom dify_plugin.entities.workflow_node import ModelConfig, ParameterConfig\n\nclass ParameterExtractorTool(Tool):\n    def _invoke(\n        self, tool_parameters: dict\n    ) -> Generator[ToolInvokeMessage, None, None]:\n        response = self.session.workflow_node.parameter_extractor.invoke(\n            parameters=[\n                ParameterConfig(\n                    name=\"name\",\n                    description=\"name of the person\",\n                    required=True,\n                    type=\"string\",\n                )\n            ],\n            model=ModelConfig(\n                provider=\"langgenius/openai/openai\",\n                name=\"gpt-4o-mini\",\n                completion_params={},\n            ),\n            query=\"My name is John Doe\",\n            instruction=\"Extract the name of the person\",\n        )\n        yield self.create_text_message(response.outputs[\"name\"])\n\n​\n質問分類ノードのリクエスト\n​\nエントリー\nCopy\nself.session.workflow_node.question_classifier\n\n​\nエンドポイント\nCopy\ndef invoke(\n    self,\n    classes: list[ClassConfig],\n    model: ModelConfig,\n    query: str,\n    instruction: str = \"\",\n) -> NodeResponse:\n    pass\n\n\nこのエンドポイントのパラメータはParameterExtractorと一致しており、最終結果はNodeResponse.outputs['class_name']に格納されます。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nツール\nBest practice\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nパラメータ抽出ノードのリクエスト\nエントリー\nエンドポイント\n例\n質問分類ノードのリクエスト\nエントリー\nエンドポイント",
        "error": null
      },
      {
        "link_index": 31,
        "link_text": "​",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/reverse-invocation-of-the-dify-service/README#%E5%91%BC%E3%81%B3%E5%87%BA%E3%81%97%E5%8F%AF%E8%83%BD%E3%81%AAdify%E3%83%A2%E3%82%B8%E3%83%A5%E3%83%BC%E3%83%AB",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nTermbase\nDifyサービスへのバックコール\nCopy page\n\nプラグインは、Difyメインプラットフォーム内の特定のサービスを自由に呼び出し、プラグインの機能を拡張できます。\n\n​\n呼び出し可能なDifyモジュール\n\nApp\n\nプラグインは、Difyプラットフォーム内のAppデータにアクセスできます。\n\nModel\n\nプラグインは、Difyプラットフォーム内のLLM機能をバックコールできます。これには、プラットフォーム内のすべてのモデルタイプと機能（TTS、Rerankなど）が含まれます。\n\nTool\n\nプラグインは、Difyプラットフォーム内の他のツールタイプのプラグインを呼び出すことができます。\n\nNode\n\nプラグインは、Difyプラットフォーム内の特定のChatflow/Workflowアプリケーション内のノードを呼び出すことができます。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\n呼び出し可能なDifyモジュール",
        "error": null
      },
      {
        "link_index": 14,
        "link_text": "Best practice",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/best-practice",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nTermbase\nベストプラクティス\nCopy page\n\n高度な機能を持つプラグイン開発に関する、より詳しいベストプラクティスは、拡張プラグイン開発ガイドラインをご覧ください。\n\ndevelop-a-slack-bot-plugin.md\n\ndevelop-a-slack-bot-plugin.md\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify",
        "error": null
      },
      {
        "link_index": 15,
        "link_text": "Slack ボットプラグインの開発",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/best-practice/develop-a-slack-bot-plugin",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nBest practice\nSlack ボットプラグインの開発\nDify MCPプラグインガイド：Zapierへのワンクリック接続と自動メール送信\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nベストプラクティス\nSlack ボットプラグインの開発\nCopy page\n\nこの記事では、以下の内容を理解できます。\n\nSlack Bot の構築方法を深く理解し、AI を活用した Slack チャットボットを作成して、Slack プラットフォーム上でユーザーの質問にインテリジェントに応答する方法を学びます。\n\n​\nプロジェクトの背景\n\nDify プラグインエコシステムは、よりシンプルで使いやすいアクセス方法のサポートに注力しています。この記事では、Slack を例に、Slack Bot プラグインの開発方法を詳しく紹介し、チームメンバーが Slack プラットフォーム内で直接 LLM と対話できるようにすることで、AI サービスの利用効率を向上させます。\n\nDify プラグインエコシステムは、よりシンプルで便利なアクセス方法を提供することを目指しています。この記事では、Slack を例に、Slack Bot プラグインの開発方法を詳しく解説し、チームメンバーが Slack プラットフォームで直接 AI アプリを利用できるようにすることで、業務効率を向上させます。\n\nSlack は、豊富な API を備えた自由でオープンなリアルタイムオフィスコミュニプラットフォームです。特に、イベントメカニズムに基づいた Webhook 機能は、簡単に開発を始めることができます。このメカニズムを利用して Slack Bot プラグインを作成します。その原理は以下の図に示すとおりです。\n\n混乱を避けるため、以下に概念の説明をします。\n\nSlack Bot は、Slack プラットフォーム上のチャットボットであり、仮想的な役割と見なすことができ、チャットを通じてインタラクションできます。\nSlack Bot プラグイン は、Dify Marketplace のプラグインであり、Dify アプリと Slack プラットフォームを接続するために使用されます。この記事では、主にこのプラグインの開発について説明します。\n\n原理の概要：\n\nSlack Bot にメッセージを送信\n\nユーザーが Slack で Bot にメッセージを送信すると、Slack Bot は Dify プラットフォームに Webhook リクエストを送信します。\n\nメッセージを Slack Bot プラグインに転送\n\nユーザーが Slack Bot と対話する際、メッセージを Dify アプリに転送する必要があります。メールシステムで受信者のメールアドレスが必要なように、Slack の API を使用して Slack Webhook のアドレスを設定し、それを Slack Bot プラグインに入力して接続を確立します。\n\nプラグインがメッセージを受信した後、特定の Dify アプリに送信\n\nSlack Bot プラグインは Slack リクエストを処理し、Dify のアプリに送信します。LLM がユーザーの入力を分析し、応答を提供します。\n\nDify アプリが応答した後、メッセージを Slack Bot に返し、ユーザーに応答\n\nSlack Bot は Dify アプリからの応答を取得した後、プラグインを介してメッセージを Slack Bot に返します。これにより、ユーザーは Dify アプリと直接やり取りできます。\n\n​\n事前準備\nDify プラグインスキャフォールディングツール。詳細については、開発ツールの初期化を参照してください。\nPython 環境。バージョンは 3.12 以上である必要があります。詳細については、Pythonインストールチュートリアルを参照するか、LLM に完全なインストールチュートリアルを問い合わせてください。\nSlack App を作成し、OAuth トークンを取得します。\n\nSlack API プラットフォームにアクセスし、scratch 方式で Slack App を作成し、アプリをデプロイする Slack ワークスペースを選択します。\n\n;Webhooks 機能を有効にします。\n\nApp を Slack ワークスペースにインストールします。\n\n今後のプラグイン開発に使用する OAuth トークンを取得します。\n\n​\n1. プラグイン開発\n\nそれでは、実際にプラグインのコーディング作業を始めましょう。その前に、クイックスタート：Extensionプラグインの開発 をお読みいただくか、Difyプラグインの開発経験があることをご確認ください。\n\n​\nプロジェクトの初期化\n\n以下のコマンドを実行して、プラグイン開発プロジェクトを初期化します。\n\nCopy\ndify plugin init\n\n\nプロンプトに従い、プロジェクトの基本情報を入力し、extension テンプレートを選択してください。そして、Apps と Endpoints の2つの権限を付与します。\n\nプラグインからDifyプラットフォームの機能を呼び出す方法については、逆呼び出し：App を参照してください。\n\n​\n1. 設定フォームの編集\n\nこのプラグインでは、どのDifyのAppを使って応答するかを指定する必要があり、さらに、応答時にSlackのAppトークンを使用する必要があるため、プラグインフォームにこれらの2つのフィールドを追加します。\n\ngroup ディレクトリにあるyamlファイルを編集します。例：group/slack.yaml。フォーム設定ファイルの名前は、プラグイン作成時に入力した基本情報によって決まります。対応するyamlファイルを変更してください。\n\nサンプルコード：\n\nslack.yaml\n\nCopy\nsettings:\n  - name: bot_token\n    type: secret-input\n    required: true\n    label:\n      en_US: Bot Token\n      zh_Hans: Bot Token\n      pt_BR: Token do Bot\n      ja_JP: Bot Token\n    placeholder:\n      en_US: Please input your Bot Token\n      zh_Hans: 请输入你的 Bot Token\n      pt_BR: Por favor, insira seu Token do Bot\n      ja_JP: ボットトークンを入力してください\n  - name: allow_retry\n    type: boolean\n    required: false\n    label:\n      en_US: Allow Retry\n      zh_Hans: 允许重试\n      pt_BR: Permitir Retentativas\n      ja_JP: 再試行を許可\n    default: false\n  - name: app\n    type: app-selector\n    required: true\n    label:\n      en_US: App\n      zh_Hans: 应用\n      pt_BR: App\n      ja_JP: アプリ\n    placeholder:\n      en_US: the app you want to use to answer Slack messages\n      zh_Hans: 你想要用来回答 Slack 消息的应用\n      pt_BR: o app que você deseja usar para responder mensagens do Slack\n      ja_JP: あなたが Slack メッセージに回答するために使用するアプリ\nendpoints:\n  - endpoints/slack.yaml\n\n\nコードデータ構造の説明：\n\nCopy\n  - name: app\n    type: app-selector\n    scope: chat\n\n\ntype フィールドは、app-selector フィールドとして設定してください。\n\nこれにより、ユーザーはプラグイン利用時に特定の Dify アプリにアクセスし、メッセージ転送を行えるようになります。\n\nscope フィールドは、chat フィールドとして設定してください。\n\nagent、chatbot、chatflow などのタイプのアプリのみが利用可能です。\n\n最後に、endpoints/slack.yaml ファイルのリクエストパスとリクエストメソッドを修正し、method を POST に変更する必要があります。\n\nサンプルコード：\n\nendpoints/slack.yaml\n\nCopy\npath: \"/\"\nmethod: \"POST\"\nextra:\n  python:\n    source: \"endpoints/slack.py\"\n\n​\n2. 機能コードの編集\n\nendpoints/slack.py ファイルを修正し、以下のコードを追加してください：\n\nCopy\nimport json\nimport traceback\nfrom typing import Mapping\nfrom werkzeug import Request, Response\nfrom dify_plugin import Endpoint\nfrom slack_sdk import WebClient\nfrom slack_sdk.errors import SlackApiError\n\n\nclass SlackEndpoint(Endpoint):\n    def _invoke(self, r: Request, values: Mapping, settings: Mapping) -> Response:\n        \"\"\"\n        Invokes the endpoint with the given request.\n        \"\"\"\n        retry_num = r.headers.get(\"X-Slack-Retry-Num\")\n        if (not settings.get(\"allow_retry\") and (r.headers.get(\"X-Slack-Retry-Reason\") == \"http_timeout\" or ((retry_num is not None and int(retry_num) > 0)))):\n            return Response(status=200, response=\"ok\")\n        data = r.get_json()\n\n        # Slack URL検証チャレンジを処理する\n        if data.get(\"type\") == \"url_verification\":\n            return Response(\n                response=json.dumps({\"challenge\": data.get(\"challenge\")}),\n                status=200,\n                content_type=\"application/json\"\n            )\n        \n        if (data.get(\"type\") == \"event_callback\"):\n            event = data.get(\"event\")\n            if (event.get(\"type\") == \"app_mention\"):\n                message = event.get(\"text\", \"\")\n                if message.startswith(\"<@\"):\n                    message = message.split(\"> \", 1)[1] if \"> \" in message else message\n                    channel = event.get(\"channel\", \"\")\n                    blocks = event.get(\"blocks\", [])\n                    blocks[0][\"elements\"][0][\"elements\"] = blocks[0].get(\"elements\")[0].get(\"elements\")[1:]\n                    token = settings.get(\"bot_token\")\n                    client = WebClient(token=token)\n                    try: \n                        response = self.session.app.chat.invoke(\n                            app_id=settings[\"app\"][\"app_id\"],\n                            query=message,\n                            inputs={},\n                            response_mode=\"blocking\",\n                        )\n                        try:\n                            blocks[0][\"elements\"][0][\"elements\"][0][\"text\"] = response.get(\"answer\")\n                            result = client.chat_postMessage(\n                                channel=channel,\n                                text=response.get(\"answer\"),\n                                blocks=blocks\n                            )\n                            return Response(\n                                status=200,\n                                response=json.dumps(result),\n                                content_type=\"application/json\"\n                            )\n                        except SlackApiError as e:\n                            raise e\n                    except Exception as e:\n                        err = traceback.format_exc()\n                        return Response(\n                            status=200,\n                            response=\"Sorry, I'm having trouble processing your request. Please try again later.\" + str(err),\n                            content_type=\"text/plain\",\n                        )\n                else:\n                    return Response(status=200, response=\"ok\")\n            else:\n                return Response(status=200, response=\"ok\")\n        else:\n            return Response(status=200, response=\"ok\")\n\n\n\nプラグインのテストを容易にするため、現在はユーザーの入力をそのまま返すだけで、Difyアプリは呼び出さない設定になっています。\n\n​\n2. プラグインのデバッグ\n\nDifyプラットフォームにアクセスし、Difyプラグインのリモートデバッグに必要な接続アドレスとキーを取得します。\n\nプラグインプロジェクトに戻り、.env.exampleファイルをコピーして.envにリネームします。\n\nCopy\nINSTALL_METHOD=remote\nREMOTE_INSTALL_HOST=remote\nREMOTE_INSTALL_PORT=5003\nREMOTE_INSTALL_KEY=****-****-****-****-****\n\n\npython -m mainコマンドを実行してプラグインを起動します。プラグインページで、ワークスペースにこのプラグインがインストールされていることを確認できます。他のチームメンバーもこのプラグインを利用できます。\n\nCopy\npython -m main\n\n​\nプラグインのエンドポイントを設定する\n\nDifyのプラグイン管理ページで、自動インストールされたテストプラグインを見つけます。次に、新しいエンドポイントを作成し、名前、Botトークンを入力し、接続するアプリを選択します。\n\n保存すると、POSTリクエストアドレスが生成されます。\n\n次に、Slack Appの設定を完了する必要があります。\n\nイベントサブスクリプションを有効にする\n\nここに、上記で生成したプラグインのPOSTリクエストアドレスを貼り付けます。\n\nSlack Appに必要な権限にチェックを入れます。\n\n​\n3. プラグインの効果を検証する\n\nコードでは、self.session.app.chat.invokeを使ってDifyプラットフォーム内のAppを呼び出し、app_idやqueryなどの情報を渡します。そして、レスポンスの内容をSlack Botに返します。python -m mainコマンドを実行してプラグインを再起動し、デバッグを行います。Slack BotがDify Appからの応答メッセージを正しく出力できるか確認します。\n\n​\n4. プラグインのパッケージ化（オプション）\n\nプラグインが正常に動作することを確認したら、次のコマンドラインツールを使ってプラグインをパッケージ化して名前を付けることができます。実行すると、現在のフォルダにslack_bot.difypkgファイルが作成されます。これが最終的なプラグインパッケージです。\n\nCopy\n# Replace ./slack_bot with your actual plugin project path.\n\ndify plugin package ./slack_bot\n\n\nおめでとうございます！プラグインの完全な開発、テスト、パッケージ化のプロセスが完了しました。\n\n​\n5. プラグインの公開（オプション）\n\n作成したプラグインを Dify Marketplace リポジトリ にアップロードして公開できます。ただし、公開する前に、プラグインがプラグイン公開仕様に準拠しているか確認してください。\n\n​\n参考資料\n\nDifyプラグインの完全なプロジェクトコードを確認するには、Githubコードリポジトリにアクセスしてください。他のプラグインの完全なコードや詳細も確認できます。\n\nプラグインの詳細については、以下を参照してください。\n\nクイックスタート：\n\n拡張タイププラグインの開発\nモデルタイププラグインの開発\nバンドルタイププラグイン：複数のプラグインをパッケージ化\n\nプラグインインターフェースドキュメント：\n\nマニフェスト\nエンドポイント\nDifyサービスの逆呼び出し\nツール\nモデル\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nBest practice\nDify MCPプラグインガイド：Zapierへのワンクリック接続と自動メール送信\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nプロジェクトの背景\n事前準備\n1. プラグイン開発\nプロジェクトの初期化\n1. 設定フォームの編集\n2. 機能コードの編集\n2. プラグインのデバッグ\nプラグインのエンドポイントを設定する\n3. プラグインの効果を検証する\n4. プラグインのパッケージ化（オプション）\n5. プラグインの公開（オプション）\n参考資料",
        "error": null
      },
      {
        "link_index": 16,
        "link_text": "Dify MCPプラグインガイド：Zapierへのワンクリック接続と自動メール送信",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/best-practice/how-to-use-mcp-zapier",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nBest practice\nSlack ボットプラグインの開発\nDify MCPプラグインガイド：Zapierへのワンクリック接続と自動メール送信\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nベストプラクティス\nDify MCPプラグインガイド：Zapierへのワンクリック接続と自動メール送信\nCopy page\n\nこのガイドでは DifyワークスペースにMCP SSEプラグインをインストールし、ZapierのMCPサービスと連携するように設定することで、シームレスな自動メール送信ワークフローを実現する方法を解説します。\n\n​\nプロジェクト背景\n\nAnthropicは2024年末にMCP（モデルコンテキストプロトコル）をリリースしました。MCPは、AIのための「USB-C」インターフェースのように機能する新興のオープンプロトコルです。LLM（大規模言語モデル）と外部アプリケーション間に双方向の通信チャネルを構築し、モデルが様々な外部ツールやAPIを発見・理解し、呼び出すことを支援します。\n\nこれにより、開発者が外部サービスごとに複雑なカスタム統合を構築する必要がなくなります。ユーザーは、日常のオフィス業務処理、データ分析、マーケティングオートメーションの実行など、AIが膨大な数のサードパーティ製アプリを簡単に呼び出す能力を体験できます。AIは「インテリジェントな対話」から「効率的なアクション」へと進化を遂げつつあります。\n\nDifyコミュニティにおいてもMCPは大きな注目を集めており、コミュニティ開発者はプラグインマーケットプレイスに複数のMCPプラグインを提供しています。これにより、外部のMCPサービスをDifyのエージェントアプリやワークフローに簡単に接続できるようになりました。\n\n本ガイドでは、MCP SSEプラグインを例に、Dify内でMCPプラグインを使用してZapierに接続し、自動メール送信プロセスを完了する方法を詳しく説明します。\n\n​\n前提条件\nDify クラウド版 / Dify コミュニティ版 ≥ v1.0.0\nZapier アカウント\n​\nDify で Zapier MCP サービスを初期化する\n\nZapier の MCP Server は、7000以上のアプリと30,000以上のアクション（Action）を単一の MCP Server URL にまとめています。メール送信、CRMへのレコード作成、Slackでの通知送信など、必要なツールやアクションはZapierの管理画面で選択・設定可能です。このMCPサーバーURLをDifyのMCPプラグイン設定に入力するだけで、LLMは会話中やプロセス実行中にこれらのツールを自動的に呼び出し、様々なタスクを完了させることができます。\n\n​\nステップ1：Zapier MCP Server URL を取得する\nZapier MCP 設定ページにアクセスします。\nMCP Server URL を取得し、後で Difyのプラグインの設定に使用します。\n\nURL の下にある “Edit MCP Actions（MCPアクションを編集）” をクリックして、ツールとアクションの追加ページに移動します。\n\n“Add a new action（新たなアクションを増加）” をクリックし、Gmail: Send Email を検索します。実際のニーズに応じて異なるメールアクションを選択することもできます。\n\n「Send Email（メールを送る）」を例に説明します：\n\nGmail アカウントの下にある 「Connect（連結）」 をクリックし、Gmail アカウントにログインして認証します。\n\n宛先（To）、件名（Subject）、本文（Body）などのフィールドについては、「Have AI guess a value for this field（このフィールドの値をAIに推測させる）」 を選択できます。具体的な内容は、エージェントが会話の文脈に基づいて動的に内容を生成します。\n\n設定完了後、さらに異なるアクションを追加して、エージェントが使用できるツールセットを充実させることができます。\n​\nステップ2：MCP SSE プラグインをインストールする\nDifyプラグインマーケットプレイスで「MCP SSE」プラグインを検索・インストールしてください。\n\n安定性を最優先する場合はプラグインバージョンv0.0.4の使用を推奨します。バージョンは詳細設定ページで変更可能。\n\nプラグインページの「認証する」ボタンをクリックし、取得したZapier MCPサーバーURLを設定してください：\nCopy\n{\n  \"server_name\": {\n    \"url\": \"https://actions.zapier.com/mcp/*******/sse\",\n    \"headers\": {},\n    \"timeout\": 5,\n    \"sse_read_timeout\": 300\n  }\n}\n\n\n​\nステップ3：Difyエージェントアプリを作成し、MCP SSE サービスを有効にする\nエージェントタイプのアプリを作成する\n\nナビゲーションから「ワークスタジオ」を選択し、アプリリストで「空白から作成」を選択してエージェントアプリタイプを選びます。アプリ名を入力して作成を完了します。\n\nMCP ツールを追加する\n\nアプリツールバーで Fetch MCP Tools と Call MCP Tool をそれぞれ追加します。\n\nLLM を設定する\n\nMCP の使用時には多くのトークンが消費される可能性があるため、よりコストパフォーマンスの高い LLM を使用することをお勧めします。このガイドでは、deepseek-chat モデルを例として使用します。DeepSeek Platform で API キーを申請し、「設定」→「モデルプロバイダー」→「DeepSeek」に入力してください。\n\nモデルプロバイダーで DeepSeek モデルが見つからない場合は、Dify プラグインマーケットプレイスで DeepSeek プラグインをインストールしてください。\n\n​\n使用シナリオ1：MCP サービスを使用して単一のメールを自動送信する\n\n設定が完了したら、エージェントとの会話を通じて、メールドラフトを自動生成し、指定した受信者に送信できます。\n\n会話ボックスで LLM にメール送信タスクを完了するよう指示します。MCP の実行が完了すると、メールは自動的に受信者に送信されます。\n\n​\n使用シナリオ2：ワークフローで MCPエージェントStrategy を設定する\n\nMCP SSE プラグインをツールとしてエージェントに追加するだけでなく、ワークフローでも MCPエージェント戦略プラグインを使用できます。インストール完了後、対応するエージェントノード内で設定します。具体的な手順は以下の通りです：\n\n以下の JSON 構造をテンプレートとして使用し、url の値を MCP Server アドレスに置き換えます。修正後の完全な JSON を MCP SERVER URL 設定ボックスにコピー＆ペーストします：\n\nCopy\n{\n  \"server_name\": {\n    \"url\": \"https://actions.zapier.com/mcp/*******/sse\",\n    \"headers\": {},\n    \"timeout\": 5,\n    \"sse_read_timeout\": 300\n  }\n}\n\n\n設定完了後、ワークフローがこのエージェントノードに到達すると、プロンプト指示に従って、設定された Zapier MCP Server を利用してタスクを実行できます。下図のように、Gmail を呼び出してメールを送信します：\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nSlack ボットプラグインの開発\nPublish plugins\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nプロジェクト背景\n前提条件\nDify で Zapier MCP サービスを初期化する\nステップ1：Zapier MCP Server URL を取得する\nステップ2：MCP SSE プラグインをインストールする\nステップ3：Difyエージェントアプリを作成し、MCP SSE サービスを有効にする\n使用シナリオ1：MCP サービスを使用して単一のメールを自動送信する\n使用シナリオ2：ワークフローで MCPエージェントStrategy を設定する",
        "error": null
      },
      {
        "link_index": 19,
        "link_text": "develop-a-slack-bot-plugin.mddevelop-a-slack-bot-plugin.md",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/best-practice/develop-a-slack-bot-plugin.md",
        "extract_target": "body",
        "extracted_data": "# Slack ボットプラグインの開発\n\n**この記事では、以下の内容を理解できます。**\n\nSlack Bot の構築方法を深く理解し、AI を活用した Slack チャットボットを作成して、Slack プラットフォーム上でユーザーの質問にインテリジェントに応答する方法を学びます。\n\n### プロジェクトの背景\n\nDify プラグインエコシステムは、よりシンプルで使いやすいアクセス方法のサポートに注力しています。この記事では、Slack を例に、Slack Bot プラグインの開発方法を詳しく紹介し、チームメンバーが Slack プラットフォーム内で直接 LLM と対話できるようにすることで、AI サービスの利用効率を向上させます。\n\nDify プラグインエコシステムは、よりシンプルで便利なアクセス方法を提供することを目指しています。この記事では、Slack を例に、Slack Bot プラグインの開発方法を詳しく解説し、チームメンバーが Slack プラットフォームで直接 AI アプリを利用できるようにすることで、業務効率を向上させます。\n\nSlack は、豊富な API を備えた自由でオープンなリアルタイムオフィスコミュニプラットフォームです。特に、イベントメカニズムに基づいた Webhook 機能は、簡単に開発を始めることができます。このメカニズムを利用して Slack Bot プラグインを作成します。その原理は以下の図に示すとおりです。\n\n![Slack Bot の原理図](https://assets-docs.dify.ai/2025/01/a0865d18f1ca4051601ca53fa6f92db2.png)\n\n> 混乱を避けるため、以下に概念の説明をします。\n>\n> * **Slack Bot** は、Slack プラットフォーム上のチャットボットであり、仮想的な役割と見なすことができ、チャットを通じてインタラクションできます。\n> * **Slack Bot プラグイン** は、Dify Marketplace のプラグインであり、Dify アプリと Slack プラットフォームを接続するために使用されます。この記事では、主にこのプラグインの開発について説明します。\n\n**原理の概要：**\n\n1. **Slack Bot にメッセージを送信**\n\n   ユーザーが Slack で Bot にメッセージを送信すると、Slack Bot は Dify プラットフォームに Webhook リクエストを送信します。\n2. **メッセージを Slack Bot プラグインに転送**\n\n   ユーザーが Slack Bot と対話する際、メッセージを Dify アプリに転送する必要があります。メールシステムで受信者のメールアドレスが必要なように、Slack の API を使用して Slack Webhook のアドレスを設定し、それを Slack Bot プラグインに入力して接続を確立します。\n3. **プラグインがメッセージを受信した後、特定の Dify アプリに送信**\n\n   Slack Bot プラグインは Slack リクエストを処理し、Dify のアプリに送信します。LLM がユーザーの入力を分析し、応答を提供します。\n4. **Dify アプリが応答した後、メッセージを Slack Bot に返し、ユーザーに応答**\n\n   Slack Bot は Dify アプリからの応答を取得した後、プラグインを介してメッセージを Slack Bot に返します。これにより、ユーザーは Dify アプリと直接やり取りできます。\n\n### 事前準備\n\n* Dify プラグインスキャフォールディングツール。詳細については、[開発ツールの初期化](/ja-jp/plugins/quick-start/develop-plugins/initialize-development-tools)を参照してください。\n* Python 環境。バージョンは 3.12 以上である必要があります。詳細については、[Pythonインストールチュートリアル](https://pythontest.com/python/installing-python-3-11/)を参照するか、LLM に完全なインストールチュートリアルを問い合わせてください。\n* Slack App を作成し、OAuth トークンを取得します。\n\n[Slack API](https://api.slack.com/apps) プラットフォームにアクセスし、scratch 方式で Slack App を作成し、アプリをデプロイする Slack ワークスペースを選択します。\n\n![Slack APIトークン](https://assets-docs.dify.ai/2025/01/8217c23ee16c47c586a1387a442ea6f0.png)\n\n;Webhooks 機能を有効にします。\n\n![Webhooks機能を有効にする](https://assets-docs.dify.ai/2025/01/fc9d7797608422219a01248f7151fc81.png)\n\nApp を Slack ワークスペースにインストールします。\n\n![ワークスペースにインストール](https://assets-docs.dify.ai/2025/01/6ab7226078f88853fc7f4d3520245d63.png)\n\n今後のプラグイン開発に使用する OAuth トークンを取得します。\n\n![OAuthトークンを取得](https://assets-docs.dify.ai/2025/01/f08052044c8c17eebbffacdc9b2558e6.png)\n\n### 1. プラグイン開発\n\nそれでは、実際にプラグインのコーディング作業を始めましょう。その前に、[クイックスタート：Extensionプラグインの開発](/ja-jp/plugins/quick-start/develop-plugins/extension-plugin) をお読みいただくか、Difyプラグインの開発経験があることをご確認ください。\n\n#### プロジェクトの初期化\n\n以下のコマンドを実行して、プラグイン開発プロジェクトを初期化します。\n\n```bash\ndify plugin init\n```\n\nプロンプトに従い、プロジェクトの基本情報を入力し、`extension` テンプレートを選択してください。そして、`Apps` と `Endpoints` の2つの権限を付与します。\n\nプラグインからDifyプラットフォームの機能を呼び出す方法については、[逆呼び出し：App](/ja-jp/plugins/schema-definition/reverse-invocation-of-the-dify-service/app) を参照してください。\n\n![Plugins permission](https://assets-docs.dify.ai/2024/12/d89a6282c5584fc43a9cadeddf09c0de.png)\n\n#### 1. 設定フォームの編集\n\nこのプラグインでは、どのDifyのAppを使って応答するかを指定する必要があり、さらに、応答時にSlackのAppトークンを使用する必要があるため、プラグインフォームにこれらの2つのフィールドを追加します。\n\n`group` ディレクトリにあるyamlファイルを編集します。例：`group/slack.yaml`。フォーム設定ファイルの名前は、プラグイン作成時に入力した基本情報によって決まります。対応するyamlファイルを変更してください。\n\n**サンプルコード：**\n\n`slack.yaml`\n\n```yaml\nsettings:\n  - name: bot_token\n    type: secret-input\n    required: true\n    label:\n      en_US: Bot Token\n      zh_Hans: Bot Token\n      pt_BR: Token do Bot\n      ja_JP: Bot Token\n    placeholder:\n      en_US: Please input your Bot Token\n      zh_Hans: 请输入你的 Bot Token\n      pt_BR: Por favor, insira seu Token do Bot\n      ja_JP: ボットトークンを入力してください\n  - name: allow_retry\n    type: boolean\n    required: false\n    label:\n      en_US: Allow Retry\n      zh_Hans: 允许重试\n      pt_BR: Permitir Retentativas\n      ja_JP: 再試行を許可\n    default: false\n  - name: app\n    type: app-selector\n    required: true\n    label:\n      en_US: App\n      zh_Hans: 应用\n      pt_BR: App\n      ja_JP: アプリ\n    placeholder:\n      en_US: the app you want to use to answer Slack messages\n      zh_Hans: 你想要用来回答 Slack 消息的应用\n      pt_BR: o app que você deseja usar para responder mensagens do Slack\n      ja_JP: あなたが Slack メッセージに回答するために使用するアプリ\nendpoints:\n  - endpoints/slack.yaml\n```\n\nコードデータ構造の説明：\n\n```\n  - name: app\n    type: app-selector\n    scope: chat\n```\n\n* `type` フィールドは、`app-selector` フィールドとして設定してください。\n\n  これにより、ユーザーはプラグイン利用時に特定の Dify アプリにアクセスし、メッセージ転送を行えるようになります。\n* `scope` フィールドは、`chat` フィールドとして設定してください。\n\n  `agent`、`chatbot`、`chatflow` などのタイプのアプリのみが利用可能です。\n\n最後に、`endpoints/slack.yaml` ファイルのリクエストパスとリクエストメソッドを修正し、`method` を `POST` に変更する必要があります。\n\n**サンプルコード：**\n\n`endpoints/slack.yaml`\n\n```yaml\npath: \"/\"\nmethod: \"POST\"\nextra:\n  python:\n    source: \"endpoints/slack.py\"\n```\n\n#### 2. 機能コードの編集\n\n`endpoints/slack.py` ファイルを修正し、以下のコードを追加してください：\n\n```python\nimport json\nimport traceback\nfrom typing import Mapping\nfrom werkzeug import Request, Response\nfrom dify_plugin import Endpoint\nfrom slack_sdk import WebClient\nfrom slack_sdk.errors import SlackApiError\n\n\nclass SlackEndpoint(Endpoint):\n    def _invoke(self, r: Request, values: Mapping, settings: Mapping) -> Response:\n        \"\"\"\n        Invokes the endpoint with the given request.\n        \"\"\"\n        retry_num = r.headers.get(\"X-Slack-Retry-Num\")\n        if (not settings.get(\"allow_retry\") and (r.headers.get(\"X-Slack-Retry-Reason\") == \"http_timeout\" or ((retry_num is not None and int(retry_num) > 0)))):\n            return Response(status=200, response=\"ok\")\n        data = r.get_json()\n\n        # Slack URL検証チャレンジを処理する\n        if data.get(\"type\") == \"url_verification\":\n            return Response(\n                response=json.dumps({\"challenge\": data.get(\"challenge\")}),\n                status=200,\n                content_type=\"application/json\"\n            )\n        \n        if (data.get(\"type\") == \"event_callback\"):\n            event = data.get(\"event\")\n            if (event.get(\"type\") == \"app_mention\"):\n                message = event.get(\"text\", \"\")\n                if message.startswith(\"<@\"):\n                    message = message.split(\"> \", 1)[1] if \"> \" in message else message\n                    channel = event.get(\"channel\", \"\")\n                    blocks = event.get(\"blocks\", [])\n                    blocks[0][\"elements\"][0][\"elements\"] = blocks[0].get(\"elements\")[0].get(\"elements\")[1:]\n                    token = settings.get(\"bot_token\")\n                    client = WebClient(token=token)\n                    try: \n                        response = self.session.app.chat.invoke(\n                            app_id=settings[\"app\"][\"app_id\"],\n                            query=message,\n                            inputs={},\n                            response_mode=\"blocking\",\n                        )\n                        try:\n                            blocks[0][\"elements\"][0][\"elements\"][0][\"text\"] = response.get(\"answer\")\n                            result = client.chat_postMessage(\n                                channel=channel,\n                                text=response.get(\"answer\"),\n                                blocks=blocks\n                            )\n                            return Response(\n                                status=200,\n                                response=json.dumps(result),\n                                content_type=\"application/json\"\n                            )\n                        except SlackApiError as e:\n                            raise e\n                    except Exception as e:\n                        err = traceback.format_exc()\n                        return Response(\n                            status=200,\n                            response=\"Sorry, I'm having trouble processing your request. Please try again later.\" + str(err),\n                            content_type=\"text/plain\",\n                        )\n                else:\n                    return Response(status=200, response=\"ok\")\n            else:\n                return Response(status=200, response=\"ok\")\n        else:\n            return Response(status=200, response=\"ok\")\n\n```\n\nプラグインのテストを容易にするため、現在はユーザーの入力をそのまま返すだけで、Difyアプリは呼び出さない設定になっています。\n\n### 2. プラグインのデバッグ\n\nDifyプラットフォームにアクセスし、Difyプラグインのリモートデバッグに必要な接続アドレスとキーを取得します。\n\n<img src=\"https://assets-docs.dify.ai/2025/01/8d24006f0cabf5bf61640a9023c45db8.png\" className=\"mx-auto\" alt=\"\" />\n\nプラグインプロジェクトに戻り、`.env.example`ファイルをコピーして`.env`にリネームします。\n\n```bash\nINSTALL_METHOD=remote\nREMOTE_INSTALL_HOST=remote\nREMOTE_INSTALL_PORT=5003\nREMOTE_INSTALL_KEY=****-****-****-****-****\n```\n\n`python -m main`コマンドを実行してプラグインを起動します。プラグインページで、ワークスペースにこのプラグインがインストールされていることを確認できます。他のチームメンバーもこのプラグインを利用できます。\n\n```bash\npython -m main\n```\n\n#### プラグインのエンドポイントを設定する\n\nDifyのプラグイン管理ページで、自動インストールされたテストプラグインを見つけます。次に、新しいエンドポイントを作成し、名前、Botトークンを入力し、接続するアプリを選択します。\n\n![テストプラグイン](https://assets-docs.dify.ai/2025/01/07f87e8a2786d6f5f05195961c5630c3.png)\n\n保存すると、POSTリクエストアドレスが生成されます。\n\n![POSTリクエストアドレスの生成](https://assets-docs.dify.ai/2025/01/e6952a5798a7ae793b3fe7df6f76ea73.png)\n\n次に、Slack Appの設定を完了する必要があります。\n\n1. イベントサブスクリプションを有効にする\n\n![](https://assets-docs.dify.ai/2025/01/1d33bb9cde78a1b5656ad6a0b8350195.png)\n\nここに、上記で生成したプラグインのPOSTリクエストアドレスを貼り付けます。\n\n![](https://assets-docs.dify.ai/2025/01/65aa41f37c3800af49e944f9ff28e121.png)\n\nSlack Appに必要な権限にチェックを入れます。\n\n![](https://assets-docs.dify.ai/2025/01/25c38a2cf10ec6c55ae54970d790f37e.png)\n\n### 3. プラグインの効果を検証する\n\nコードでは、`self.session.app.chat.invoke`を使ってDifyプラットフォーム内のAppを呼び出し、`app_id`や`query`などの情報を渡します。そして、レスポンスの内容をSlack Botに返します。`python -m main`コマンドを実行してプラグインを再起動し、デバッグを行います。Slack BotがDify Appからの応答メッセージを正しく出力できるか確認します。\n\n![](https://assets-docs.dify.ai/2025/01/6fc872d1343ce8503d63c5222f7f26f9.png)\n\n### 4. プラグインのパッケージ化（オプション）\n\nプラグインが正常に動作することを確認したら、次のコマンドラインツールを使ってプラグインをパッケージ化して名前を付けることができます。実行すると、現在のフォルダに`slack_bot.difypkg`ファイルが作成されます。これが最終的なプラグインパッケージです。\n\n```bash\n# Replace ./slack_bot with your actual plugin project path.\n\ndify plugin package ./slack_bot\n```\n\nおめでとうございます！プラグインの完全な開発、テスト、パッケージ化のプロセスが完了しました。\n\n### 5. プラグインの公開（オプション）\n\n作成したプラグインを [Dify Marketplace リポジトリ](https://github.com/langgenius/dify-plugins) にアップロードして公開できます。ただし、公開する前に、プラグインが[プラグイン公開仕様](/ja-jp/plugins/publish-plugins/publish-to-dify-marketplace/README)に準拠しているか確認してください。\n\n### 参考資料\n\nDifyプラグインの完全なプロジェクトコードを確認するには、[Githubコードリポジトリ](https://github.com/langgenius/dify-plugins)にアクセスしてください。他のプラグインの完全なコードや詳細も確認できます。\n\nプラグインの詳細については、以下を参照してください。\n\n**クイックスタート：**\n\n* [拡張タイププラグインの開発](/ja-jp/plugins/quick-start/develop-plugins/extension-plugin)\n* [モデルタイププラグインの開発](/ja-jp/plugins/manage-plugins)\n* [バンドルタイププラグイン：複数のプラグインをパッケージ化](/ja-jp/plugins/quick-start/develop-plugins/bundle)\n\n**プラグインインターフェースドキュメント：**\n\n* [マニフェスト](/ja-jp/plugins/schema-definition/manifest)\n* [エンドポイント](/ja-jp/plugins/schema-definition/endpoint)\n* [Difyサービスの逆呼び出し](/ja-jp/plugins/schema-definition/reverse-invocation-of-the-dify-service/app)\n* [ツール](/ja-jp/guides/workflow/nodes/tools)\n* [モデル](/ja-jp/plugins/schema-definition/model/model-schema)\n\n{/*\n  Contributing Section\n  DO NOT edit this section!\n  It will be automatically generated by the script.\n  */}\n\n<CardGroup cols=\"2\">\n  <Card title=\"このページを編集する\" icon=\"pen-to-square\" href=\"https://github.com/langgenius/dify-docs-mintlify/edit/main/ja-jp/plugins/best-practice/develop-a-slack-bot-plugin.mdx\">\n    直接貢献することでドキュメントの改善にご協力ください\n  </Card>\n\n  <Card title=\"問題を報告する\" icon=\"github\" href=\"https://github.com/langgenius/dify-docs-mintlify/issues/new?title=ドキュメントの問題%3A%20op-a-slack-bot-plu&body=%23%23%20問題の説明%0A%3C%21--%20発見した問題について簡単に説明してください%20--%3E%0A%0A%23%23%20ページリンク%0Ahttps%3A%2F%2Fgithub.com%2Flanggenius%2Fdify-docs-mintlify%2Fblob%2Fmain%2Fja-jp/plugins/best-practice%2Fdevelop-a-slack-bot-plugin.mdx%0A%0A%23%23%20提案される変更%0A%3C%21--%20特定の変更案がある場合は、ここで説明してください%20--%3E%0A%0A%3C%21--%20ドキュメントの品質向上にご協力いただきありがとうございます！%20--%3E\">\n    エラーを見つけたり提案がありますか？お知らせください\n  </Card>\n</CardGroup>",
        "error": null
      },
      {
        "link_index": 14,
        "link_text": "Publish plugins",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/publish-plugins",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nTermbase\nプラグインの公開\nCopy page\n​\n公開方法\n\n異なる開発者のニーズに対応するため、Difyでは以下の3つのプラグイン公開方法を提供しています：\n\n​\nマーケットプレイス\n\n概要： Dify公式のプラグインマーケットプレイスです。ユーザーは各種プラグインの閲覧、検索、ワンクリックでのインストールが可能です。\n\n特徴：\n\n審査を経て公開される安全で信頼性の高いプラグイン。\n個人またはチームのWorkspaceに直接インストール可能。\n\n公開手順：\n\nプラグインプロジェクトをDify Marketplaceのリポジトリに提出。\n公式審査を経て、マーケットプレイスで公開され、他のユーザーがインストール可能になります。\n\n詳細については以下をご参照ください：\n\nDify Marketplaceへの公開\n\n​\nGitHubリポジトリ\n\n概要： プラグインをGitHub上でオープンソース化または管理し、他者が閲覧、ダウンロード、インストールしやすくします。\n\n特徴：\n\nバージョン管理とオープンソース共有が容易。\nプラットフォームの審査なしで、プラグインリンクから直接インストール可能。\n\n公開手順：\n\nプラグインコードをGitHubリポジトリにプッシュ。\nリポジトリリンクを共有し、ユーザーはリンクからDify Workspaceにプラグインを統合可能。\n\n詳細については以下をご参照ください：\n\n個人GitHubリポジトリへの公開\n\n​\nプラグインファイル（ローカルインストール）\n\n概要： プラグインをローカルファイル（.difypkg形式など）にパッケージ化し、ファイル共有形式で他者にインストールを提供します。\n\n特徴：\n\nオンラインプラットフォームに依存せず、迅速かつ柔軟なプラグイン共有が可能。\nプライベートプラグインや内部テスト用に適しています。\n\n公開手順：\n\nプラグインプロジェクトをローカルファイルにパッケージ化。\nDifyプラグインページでプラグインのアップロードをクリックし、ローカルファイルを選択してインストール。\n\nプラグインプロジェクトをローカルファイルにパッケージ化して他者と共有し、プラグインページでファイルをアップロードすることで、Dify Workspaceにインストールできます。\n\n詳細については以下をご参照ください：\n\nローカルでの公開と共有\n\n​\n公開に関する推奨事項\nプラグインを広く普及させたい場合 → Marketplaceの利用を推奨。公式審査によりプラグインの品質を保証し、露出度を高めます。\nオープンソースプロジェクトの共有 → GitHubの利用を推奨。バージョン管理とコミュニティコラボレーションが容易です。\n迅速な配布や内部テスト → プラグインファイルの利用を推奨。簡単かつ効率的なインストールと共有が可能です。\n\nDifyマーケットプレイス以外のプラグインをインストールする際、サードパーティの署名検証に関する問題が発生する可能性があります。対処方法については、第三者署名検証のためにプラグインに署名するをご参照ください。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\n公開方法\nマーケットプレイス\nGitHubリポジトリ\nプラグインファイル（ローカルインストール）\n公開に関する推奨事項",
        "error": null
      },
      {
        "link_index": 15,
        "link_text": "PRを通じてプラグインを自動的に公開する",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/publish-plugins/plugin-auto-publish-pr",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nPublish plugins\nPRを通じてプラグインを自動的に公開する\nDifyマーケットプレイスへの公開\n個人GitHubリポジトリへの公開\nローカルでの公開と共有\n第三者署名検証のためにプラグインに署名する\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nプラグインの公開\nPRを通じてプラグインを自動的に公開する\nCopy page\n​\n背景\n\nプラグイン貢献者が他のユーザーにすでに使用されているDifyプラグインを更新する必要がある場合、そのプロセスは非常に煩雑です：貢献者はまずプラグインのソースコードを修正してバージョン番号を更新し、変更をプラグインソースリポジトリにプッシュし、フォークしたdify-pluginリポジトリに新しいブランチを作成する必要があります。その後、プラグインを手動でパッケージ化し、パッケージファイルをアップロードし、元のdify-pluginリポジトリにマージするためのPRを作成する必要があります。このプロセスはプラグインコードが変更されるたびに繰り返す必要があり、時間がかかり非効率的です。\n\nこのワークフローを簡素化するために、Plugin Auto-PRと呼ばれるGitHub Actionsベースの自動化ワークフローを構築しました。このツールを使用すると、プラグイン貢献者はプラグインのパッケージ化、ブランチのプッシュ、PRの作成を一度の操作で完了できます。\n\n​\n概念紹介\n​\nGitHub Actions\n\nGitHub Actionsは、GitHubが提供する組み込みのCI/CDサービスで、様々なビルド、テスト、デプロイタスクを自動化します。\n\n動作原理：トリガー条件（コードのプッシュなど）が満たされると、GitHubは自動的に仮想マシンを割り当ててワークフローを実行します。すべての操作はGitHubクラウドで完了します。\n\n無料枠の制限：\n\n公開リポジトリ：無制限\nプライベートリポジトリ：月2000分\n​\nPlugin Auto-PR\n\n動作原理：\n\nプラグインソースリポジトリのmainブランチにコードをプッシュすると、ワークフローがトリガーされます\nワークフローはmanifest.yamlファイルからプラグイン情報を読み取ります\nプラグインを自動的に.difypkgファイルとしてパッケージ化します\nパッケージファイルをフォークしたdify-pluginsリポジトリにプッシュします\n新しいブランチを作成して変更をコミットします\n上流リポジトリへのマージを自動的にPRで要求します\n​\n環境準備\n​\nリポジトリ要件\nすでに独自のプラグインソースコードリポジトリがある（例：your-name/plugin-source）\nすでに独自のフォークしたプラグインリポジトリがある（例：your-name/dify-plugins）\nCopy\ndify-plugins/\n└── your-author-name\n    └── plugin-name\n\n​\n権限要件\n\nこのワークフローが正常に機能するには、適切な権限が必要です：\n\n十分な権限を持つGitHub Personal Access Token（PAT）を作成する必要があります\nそのPATはフォークしたリポジトリにコードをプッシュする権限が必要です\nそのPATは上流リポジトリにPRを作成する権限が必要です\n​\nパラメータと設定の詳細\n​\n必須パラメータ\n\nプラグイン自動公開ワークフローでは、以下の重要な要素を正しく設定する必要があります：\n\nmanifest.yamlファイル：これは自動化プロセス全体の中核となる設定ソースです。以下のフィールドが正しいことを確認する必要があります：\n\nname：プラグイン名（パッケージ名とブランチ名の生成に使用）\nversion：バージョン番号（更新のたびに増分する必要あり）\nauthor：GitHubユーザー名（ターゲットリポジトリパスの決定に使用）\n\nPLUGIN_ACTION Secret：プラグインソースリポジトリにこのシークレットを正しく設定する必要があります。\n\n値の要件：十分な権限を持つPersonal Access Token（PAT）である必要があります\n権限要件：フォークしたリポジトリにブランチをプッシュし、上流リポジトリにPRを作成する能力\n​\n自動生成されるパラメータ\n\nワークフローは以下を自動的に処理し、手動介入は不要です：\n\nGitHubユーザー名：manifest.yamlのauthorフィールドから読み取り\n作者フォルダ名：authorフィールドと一致\nプラグイン名：manifest.yamlのnameフィールドから読み取り\nブランチ名：bump-{plugin-name}-plugin-{version}\nパッケージファイル名：{plugin-name}-{version}.difypkg\nPRのタイトルと内容：プラグイン名とバージョンに基づいて自動生成\n​\nインストールと設定手順\n1\n\nリポジトリの準備\n\n公式のdify-pluginsリポジトリをフォークし、独自のプラグインソースリポジトリがあることを確認します。\n\n2\n\nシークレットの設定\n\nプラグインソースリポジトリに移動し、Settings > Secrets and variables > Actions > New repository secretをクリックして、GitHubシークレットを作成します：\n\n名前：PLUGIN_ACTION\n値：ターゲットリポジトリ（your-name/dify-plugins）への書き込み権限を持つGitHub Personal Access Token（PAT）\n3\n\nワークフローファイルの作成\n\nリポジトリに.github/workflows/ディレクトリを作成し、このディレクトリにplugin-publish.ymlという名前のファイルを作成し、以下の内容をファイルにコピーします：\n\nCopy\n# .github/workflows/auto-pr.yml\nname: Auto Create PR on Main Push\n\non:\n  push:\n    branches: [ main ]  # Trigger on push to main\n\njobs:\n  create_pr: # Renamed job for clarity\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: Print working directory # Kept for debugging\n        run: |\n          pwd\n          ls -la\n\n      - name: Download CLI tool\n        run: |\n          # Create bin directory in runner temp\n          mkdir -p $RUNNER_TEMP/bin\n          cd $RUNNER_TEMP/bin\n\n          # Download CLI tool\n          wget https://github.com/langgenius/dify-plugin-daemon/releases/download/0.0.6/dify-plugin-linux-amd64\n          chmod +x dify-plugin-linux-amd64\n\n          # Show download location and file\n          echo \"CLI tool location:\"\n          pwd\n          ls -la dify-plugin-linux-amd64\n\n      - name: Get basic info from manifest # Changed step name and content\n        id: get_basic_info\n        run: |\n          PLUGIN_NAME=$(grep \"^name:\" manifest.yaml | cut -d' ' -f2)\n          echo \"Plugin name: $PLUGIN_NAME\"\n          echo \"plugin_name=$PLUGIN_NAME\" >> $GITHUB_OUTPUT\n\n          VERSION=$(grep \"^version:\" manifest.yaml | cut -d' ' -f2)\n          echo \"Plugin version: $VERSION\"\n          echo \"version=$VERSION\" >> $GITHUB_OUTPUT\n\n          # If the author's name is not your github username, you can change the author here\n          AUTHOR=$(grep \"^author:\" manifest.yaml | cut -d' ' -f2)\n          echo \"Plugin author: $AUTHOR\"\n          echo \"author=$AUTHOR\" >> $GITHUB_OUTPUT\n\n      - name: Package Plugin\n        id: package\n        run: |\n          # Use the downloaded CLI tool to package\n          cd $GITHUB_WORKSPACE\n          # Use variables for package name\n          PACKAGE_NAME=\"${{ steps.get_basic_info.outputs.plugin_name }}-${{ steps.get_basic_info.outputs.version }}.difypkg\"\n          # Use CLI from runner temp\n          $RUNNER_TEMP/bin/dify-plugin-linux-amd64 plugin package . -o \"$PACKAGE_NAME\"\n\n          # Show packaging result\n          echo \"Package result:\"\n          ls -la \"$PACKAGE_NAME\"\n          echo \"package_name=$PACKAGE_NAME\" >> $GITHUB_OUTPUT\n\n          # Show full file path and directory structure (kept for debugging)\n          echo \"\\\\nFull file path:\"\n          pwd\n          echo \"\\\\nDirectory structure:\"\n          tree || ls -R\n\n      - name: Checkout target repo\n        uses: actions/checkout@v3\n        with:\n          # Use author variable for repository\n          repository: ${{steps.get_basic_info.outputs.author}}/dify-plugins\n          path: dify-plugins\n          token: ${{ secrets.PLUGIN_ACTION }}\n          fetch-depth: 1 # Fetch only the last commit to speed up checkout\n          persist-credentials: true # Persist credentials for subsequent git operations\n\n      - name: Prepare and create PR\n        run: |\n          # Debug info (kept)\n          echo \"Debug: Current directory $(pwd)\"\n          # Use variable for package name\n          PACKAGE_NAME=\"${{ steps.get_basic_info.outputs.plugin_name }}-${{ steps.get_basic_info.outputs.version }}.difypkg\"\n          echo \"Debug: Package name: $PACKAGE_NAME\"\n          ls -la\n\n          # Move the packaged file to the target directory using variables\n          mkdir -p dify-plugins/${{ steps.get_basic_info.outputs.author }}/${{ steps.get_basic_info.outputs.plugin_name }}\n          mv \"$PACKAGE_NAME\" dify-plugins/${{ steps.get_basic_info.outputs.author }}/${{ steps.get_basic_info.outputs.plugin_name }}/\n\n          # Enter the target repository directory\n          cd dify-plugins\n\n          # Configure git\n          git config user.name \"GitHub Actions\"\n          git config user.email \"actions@github.com\"\n\n          # Ensure we are on the latest main branch\n          git fetch origin main\n          git checkout main\n          git pull origin main\n\n          # Create and switch to a new branch using variables and new naming convention\n          BRANCH_NAME=\"bump-${{ steps.get_basic_info.outputs.plugin_name }}-plugin-${{ steps.get_basic_info.outputs.version }}\"\n          git checkout -b \"$BRANCH_NAME\"\n\n          # Add and commit changes (using git add .)\n          git add .\n          git status # for debugging\n          # Use variables in commit message\n          git commit -m \"bump ${{ steps.get_basic_info.outputs.plugin_name }} plugin to version ${{ steps.get_basic_info.outputs.version }}\"\n\n          # Push to remote (use force just in case the branch existed before from a failed run)\n          git push -u origin \"$BRANCH_NAME\" --force\n\n          # Confirm branch has been pushed and wait for sync (GitHub API might need a moment)\n          git branch -a\n          echo \"Waiting for branch to sync...\"\n          sleep 10  # Wait 10 seconds for branch sync\n\n      - name: Create PR via GitHub API\n        env:\n          GH_TOKEN: ${{ secrets.PLUGIN_ACTION }} # Use the provided token for authentication\n        run: |\n          gh pr create \\\n            --repo langgenius/dify-plugins \\\n            --head \"${{ steps.get_basic_info.outputs.author }}:${{ steps.get_basic_info.outputs.plugin_name }}-${{ steps.get_basic_info.outputs.version }}\" \\\n            --base main \\\n            --title \"bump ${{ steps.get_basic_info.outputs.plugin_name }} plugin to version ${{ steps.get_basic_info.outputs.version }}\" \\\n            --body \"bump ${{ steps.get_basic_info.outputs.plugin_name }} plugin package to version ${{ steps.get_basic_info.outputs.version }}\n\n            Changes:\n            - Updated plugin package file\" || echo \"PR already exists or creation skipped.\" # Handle cases where PR already exists\n\n      - name: Print environment info # Kept for debugging\n        run: |\n          echo \"GITHUB_WORKSPACE: $GITHUB_WORKSPACE\"\n          echo \"Current directory contents:\"\n          ls -R\n\n4\n\nmanifest.yamlの更新\n\nmanifest.yamlファイルが以下のフィールドを正しく設定していることを確認します：\n\nCopy\nversion: 0.0.x  # バージョン番号\nauthor: your-github-username  # GitHubユーザー名/作者名\nname: your-plugin-name  # プラグイン名\n\n​\n使用ガイド\n​\n初回セットアッププロセス\n\n自動公開ワークフローを初めて設定する場合は、次の手順を完了します：\n\n公式のdify-pluginsリポジトリをフォークしていることを確認します\nプラグインソースリポジトリの構造が正しいことを確認します\nプラグインソースリポジトリにPLUGIN_ACTION Secretを設定します\nワークフローファイル.github/workflows/plugin-publish.ymlを作成します\nmanifest.yamlファイルのnameとauthorフィールドが正しく設定されていることを確認します\n​\n以降の更新プロセス\n\nセットアップが完了したら、新しいバージョンを公開する必要がある場合は、以下を行うだけです：\n\nプラグインコードを修正します\nmanifest.yamlのversionフィールドを更新します\n\nすべての変更をmainブランチにプッシュします\nGitHub Actionsがパッケージング、ブランチ作成、PR提出を自動的に完了するのを待ちます\n​\n実行結果\n\nプラグインソースリポジトリのmainブランチにコードをプッシュすると、GitHub Actionsは自動的に公開プロセスを実行します：\n\nプラグインを{plugin-name}-{version}.difypkg形式で自動的にパッケージ化します\nパッケージファイルをターゲットリポジトリに自動的にプッシュします\nフォークリポジトリへのマージを自動的にPRで作成します\n\n​\nサンプルリポジトリ\n\n完全な設定の詳細とベストプラクティスを理解するために、サンプルリポジトリを参照してください。`\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nPublish plugins\nPublish to dify marketplace\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\n背景\n概念紹介\nGitHub Actions\nPlugin Auto-PR\n環境準備\nリポジトリ要件\n権限要件\nパラメータと設定の詳細\n必須パラメータ\n自動生成されるパラメータ\nインストールと設定手順\n使用ガイド\n初回セットアッププロセス\n以降の更新プロセス\n実行結果\nサンプルリポジトリ",
        "error": null
      },
      {
        "link_index": 16,
        "link_text": "Publish to dify marketplace",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/publish-plugins/publish-to-dify-marketplace",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nTermbase\nDify Marketplaceへの公開\nCopy page\n\nDify Marketplaceは、Difyプラットフォームを利用する世界中のユーザーにより強力で柔軟な機能拡張を提供することを目指しています。皆様の貢献は、このプラットフォームの可能性をさらに広げることにつながります。\n\n特徴：\n\n審査を経て公開される安全で信頼性の高いプラグイン。\n個人またはチームのWorkspaceに直接インストール可能。\n\n公開手順：\n\nプラグインプロジェクトをDify Marketplaceのリポジトリに提出。\n公式審査を経て、マーケットプレイスで公開され、他のユーザーがインストール可能に。\n\n初めてプラグインを提出する開発者の方も、経験豊富な貢献者の方も、このガイドラインを通じて明確な公開プロセスとベストプラクティスをご提供し、プラグインの円滑な公開とコミュニティへの価値提供を支援いたします。\n\nより開放的で革新的なプラグインエコシステムの構築に、ぜひご参加ください！\n\nプラグインの公開フロー図：\n\n​\nプラグイン公開プロセス\n\nDify Marketplaceへのプラグイン公開は、以下の手順で行います：\n\nDify Pluginリポジトリをフォーク\n新しいブランチを作成し、プラグインのコードとpkgファイルを該当カテゴリにアップロード\nPull Request (PR)を提出し、審査を待機\n審査通過後、プラグインコードがMainブランチにマージされ、自動的にDify Marketplaceに公開\n​\nプラグイン開発チェックリスト\n​\n1. Pull Request (PR)提出前の確認事項\n\n1.1 プラグインの機能性とドキュメントの完全性\n\nプラグインが正常に動作することを確認。\n包括的なREADMEファイルの提供：\nセットアップ手順と使用ガイド。\nサービス接続に必要なコード、API、認証情報などの情報。\nユーザー情報の収集はサービス接続とプラグイン機能の改善のみに使用。\n\n1.2 プラグインの価値提案の検証\n\nDifyユーザーに独自の価値を提供することを確認。\nDifyや他のプラグインにない機能やサービスを導入。\nコミュニティ基準の遵守：\n非暴力的なコンテンツ、グローバルユーザーへの配慮。\n統合サービスの関連ポリシーへの準拠。\n類似プラグインの確認方法：\n既存のプラグインやPRと重複する機能の提出を避ける（以下の場合を除く）：\n新機能の導入。\nパフォーマンスの改善。\nプラグインの独自性の判断基準：\n既存機能の軽微な調整（言語パラメータの追加など）の場合は、既存プラグインの拡張を推奨。\n大幅な機能変更（バッチ処理の最適化やエラー処理の改善など）の場合は、新規プラグインとして提出可能。\n不明な場合は、PRに新規プラグインが必要な理由を簡潔に説明してください。\n\n例：\n\nGoogle検索プラグインの場合、単一の検索クエリを受け取り、Google検索APIを使用して検索結果リストを出力します。\n\n類似の実装で言語パラメータの追加程度の変更であれば、既存プラグインの拡張を推奨します。\n\n一方、バッチ検索の最適化やエラー処理の改善など、新しい実装方法を導入する場合は、独立したプラグインとして審査対象となります。\n\n​\n2. Pull Request (PR)審査中の注意事項\n\nレビュアーからの質問やフィードバックへの積極的な対応：\n\n14日以内に未解決のPRコメントは期限切れとしてマーク（再開可能）。\n30日以内に未解決のPRコメントはクローズ（再開不可、新規PR必要）。\n​\n3. Pull Request (PR)審査通過後\n\n3.1 継続的なメンテナンス\n\nユーザーから報告された問題や機能リクエストへの対応。\n重要なAPI変更時のプラグイン移行： Difyは変更通知と移行手順を事前に公開。 Difyエンジニアが移行サポートを提供。\n\n3.2 Marketplace公開ベータテスト期間の制限 既存プラグインへの破壊的変更を避ける。\n\n​\n審査プロセス\n\n審査順序\n\n先着順でPRを処理。審査は1週間以内に開始。遅延がある場合、レビュアーがPR作成者にコメントで通知。\n\n審査のポイント\n\nプラグイン名、説明、設定手順の明確性と有用性の確認。\n\nManifestファイルのフォーマット規格への準拠と有効な作者連絡先情報の確認。\n\nプラグインの機能性と関連性\n\n提供された設定手順に基づくプラグインのテスト。\nDifyエコシステムにおけるプラグインの妥当性の確認。\n\nDify.aiはプラグイン提出の承認または却下の権利を有します。\n\n​\nよくある質問\n\nQ: プラグインの独自性をどのように判断すればよいですか？\n\nA: 例えば、Google検索プラグインに言語パラメータを追加する程度の変更は既存プラグインの拡張として提出すべきですが、バッチ処理の最適化やエラー処理の改善など、大幅な機能改善がある場合は新規プラグインとして提出可能です。\n\nQ: PRが期限切れまたはクローズされた場合はどうすればよいですか？\n\nA: 期限切れのPRはフィードバックを解決後に再開可能です。クローズされたPR（30日超過）は新規PRの作成が必要です。\n\nQ: ベータテスト期間中にプラグインを更新できますか？\n\nA: 可能ですが、破壊的な変更は避けてください。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nプラグイン公開プロセス\nプラグイン開発チェックリスト\n1. Pull Request (PR)提出前の確認事項\n2. Pull Request (PR)審査中の注意事項\n3. Pull Request (PR)審査通過後\n審査プロセス\nよくある質問",
        "error": null
      },
      {
        "link_index": 17,
        "link_text": "プラグイン開発者ガイドライン",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/publish-plugins/publish-to-dify-marketplace/plugin-developer-guidelines",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nPublish plugins\nPRを通じてプラグインを自動的に公開する\nDifyマーケットプレイスへの公開\nPublish to dify marketplace\nプラグイン開発者ガイドライン\nプラグインのプライバシー保護に関するガイドライン\n個人GitHubリポジトリへの公開\nローカルでの公開と共有\n第三者署名検証のためにプラグインに署名する\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nDifyマーケットプレイスへの公開\nプラグイン開発者ガイドライン\nCopy page\n​\nプルリクエスト（PR）を提出する前に\nプラグインの機能とドキュメントの完全性を確認する\nプラグインが意図どおりに動作するか確認してください。\n以下の内容を含むREADMEファイルを作成してください。\nセットアップと使用方法の説明\nプラグインをサービスに接続するためのコード、API、認証情報などの情報\n収集したユーザー情報は、サービスの接続とプラグインの改善のみに利用することを徹底してください。\nプラグインプライバシー保護ガイドラインに従って、プラグインのプライバシーポリシーファイルまたはURLを用意してください。\nプラグインの提案価値を検証する\nプラグインがDifyユーザーにとって独自の価値を持つことを確認してください。\nプラグインは、Difyや他のプラグインにはない機能やサービスを導入する必要があります。\nコミュニティ標準を遵守してください：\nグローバルなユーザーベースを尊重する非暴力的なコンテンツ\n統合されたサービスポリシーの遵守\n類似プラグインの確認方法\n以下のいずれかに該当する場合を除き、既存のプラグインやPRと機能が重複するものは提出しないでください。\n新機能の導入\nパフォーマンスの向上\nプラグインの独自性の判断:\nプラグインが既存の機能に言語パラメーターの追加のようなわずかな変更を加える場合は、既存プラグインの拡張を検討してください。\nプラグインが最適化されたバッチ処理やエラー処理の改善のような大幅な機能変更を行う場合は、新しいプラグインとして提出してください。\n判断に迷う場合は、新しいプラグインが必要な理由をPRに簡単に説明してください。\n\n例: Google検索APIを利用して、単一の入力クエリを受け取り、Google検索結果を出力するGoogle検索プラグインを考えてみましょう。\n\n同様の基盤実装で、わずかな入力調整（例：新しい言語パラメーターの追加）を加えた新しいGoogle検索プラグインを提案する場合は、既存のプラグインを拡張することをお勧めします。\n\nしかし、最適化されたバッチ検索機能とエラー処理を実装してプラグインを異なる方法で実装した場合は、別のプラグインとして審査される可能性があります。\n\nプライバシーデータ標準の遵守を確認する\n\n情報開示の要件:\n\n開発者は、アプリやツールを提出する際に、個人データを収集するかどうかを必ず申告する必要があります。\nデータを収集する場合は、収集するデータの種類（例：ユーザー名、メールアドレス、デバイスID、位置情報など）を簡潔に記載してください。詳細な説明は不要です。\n開発者は、収集する情報、その利用目的、第三者との共有情報、および第三者のプライバシーポリシーへのリンクを必ず提供してください。\n\n審査の焦点:\n\n形式的審査: データ収集が必須項目として申告されているかを確認します。\n高リスクのデータスクリーニング: 健康情報、財務情報、子供の個人情報などの機密データが収集されていないか確認します。機密データが収集されている場合は、利用目的とセキュリティ対策について追加の審査を行います。\n悪意のある行為のスクリーニング: ユーザーの同意なくデータを収集したり、ユーザーデータを不明なサーバーにアップロードしたりするなど、明らかな悪意のある行為がないか確認します。\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nPublish to dify marketplace\nプラグインのプライバシー保護に関するガイドライン\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nプルリクエスト（PR）を提出する前に",
        "error": null
      },
      {
        "link_index": 18,
        "link_text": "プラグインのプライバシー保護に関するガイドライン",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/publish-plugins/publish-to-dify-marketplace/plugin-privacy-protection-guidelines",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nPublish plugins\nPRを通じてプラグインを自動的に公開する\nDifyマーケットプレイスへの公開\nPublish to dify marketplace\nプラグイン開発者ガイドライン\nプラグインのプライバシー保護に関するガイドライン\n個人GitHubリポジトリへの公開\nローカルでの公開と共有\n第三者署名検証のためにプラグインに署名する\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nDifyマーケットプレイスへの公開\nプラグインのプライバシー保護に関するガイドライン\nCopy page\n\nDify Marketplaceにプラグインを提出する際には、ユーザーデータの取り扱いについて透明性を確保する必要があります。以下のガイドラインでは、プラグインに関するプライバシー関連の質問や、ユーザーデータ処理にどのように対応すべきかを重点的に説明します。\n\nプライバシーポリシーは、以下の点を中心に構成してください。\n\nプラグインはユーザーの個人データを収集・利用しますか？ もし収集・利用する場合は、収集するデータの種類をリストアップしてください。\n\n「個人データ」とは、単独で、または他のデータと組み合わせることで特定の個人を識別できる情報（特定の個人を特定、連絡、またはターゲットとするために使用される情報など）を指します。\n\n​\n1. 収集するデータの種類をリストアップする\n\n種類A：直接的な識別情報\n\n氏名（例：フルネーム、名、姓）\nメールアドレス\n電話番号\n自宅住所またはその他の物理的な住所\n政府発行の識別番号（例：社会保障番号、パスポート番号、運転免許証番号）\n\n種類B：間接的な識別情報\n\nデバイス識別子（例：IMEI、MACアドレス、デバイスID）\nIPアドレス\n位置データ（例：GPS座標、市区町村、地域）\nオンライン識別子（例：Cookie、広告ID）\nユーザー名\nプロフィール写真\n生体認証データ（例：指紋、顔認識データ）\nWeb閲覧履歴\n購入履歴\n健康情報\n財務情報\n\n種類C：他のデータと組み合わせることで個人を識別できるデータ\n\n年齢\n性別\n職業\n興味・関心\n\nプラグイン自体が個人情報を収集しない場合でも、プラグイン内でサードパーティサービスを利用する際に、データの収集や処理が行われる可能性がある点に注意が必要です。プラグイン開発者として、サードパーティサービスによって実行されるものを含め、プラグインに関連するすべてのデータ収集活動を開示する責任があります。したがって、サードパーティサービスのプライバシーポリシーをよく確認し、プラグインによって収集されるデータが提出時に適切に申告されていることを確認してください。\n\nたとえば、開発中のプラグインがSlackサービスを利用する場合、プラグインのプライバシーポリシーステートメントでSlackのプライバシーポリシーを参照し、データ収集の実態を明確に開示してください。\n\n​\n2. 最新のプラグインプライバシーポリシーを提出する\n\nプライバシーポリシーには、以下を含める必要があります。\n\n収集するデータの種類\n収集したデータの利用方法\nデータを第三者と共有するかどうか。共有する場合は、該当する第三者を特定し、そのプライバシーポリシーへのリンクを提供してください。\nプライバシーポリシーの作成方法が不明な場合は、Difyチームが発行するプラグインのプライバシーポリシーも参考にできます。\n​\n3. プラグインのマニフェストファイル内にプライバシーポリシーステートメントを記載する\n\n特定フィールドへの入力に関する詳細な手順については、マニフェストのドキュメントを参照してください。\n\nFAQ\n\nユーザーの個人データに関する「収集と利用」とは何を意味しますか？プラグインで個人データが収集および利用される一般的な例はありますか？\n\nユーザーデータの「収集と利用」とは、一般的にユーザーデータの収集、送信、利用、または共有を指します。プラグインが個人データまたは機密性の高いユーザーデータを処理する一般的な例としては、以下のようなものがあります。\n\n個人を特定できるあらゆる種類の情報を収集するフォームの使用。\nサードパーティの認証サービスを使用する場合でも、ログイン機能の実装。\n個人を特定できる情報が含まれている可能性のある入力やリソースに関する情報の収集。\nユーザーの行動、インタラクション、利用パターンを追跡するための分析機能の実装。\nメッセージ、チャットログ、メールアドレスなどの通信データの保存。\n接続されたソーシャルメディアアカウントからのユーザープロファイルやデータへのアクセス。\nアクティビティレベル、心拍数、医療情報などの健康およびフィットネスデータの収集。\n検索クエリの保存や閲覧行動の追跡。\n銀行口座の詳細、クレジットスコア、取引履歴を含む金融情報の処理。\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nプラグイン開発者ガイドライン\n個人GitHubリポジトリへの公開\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\n1. 収集するデータの種類をリストアップする\n2. 最新のプラグインプライバシーポリシーを提出する\n3. プラグインのマニフェストファイル内にプライバシーポリシーステートメントを記載する",
        "error": null
      },
      {
        "link_index": 19,
        "link_text": "個人GitHubリポジトリへの公開",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/publish-plugins/publish-plugin-on-personal-github-repo",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nPublish plugins\nPRを通じてプラグインを自動的に公開する\nDifyマーケットプレイスへの公開\n個人GitHubリポジトリへの公開\nローカルでの公開と共有\n第三者署名検証のためにプラグインに署名する\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nプラグインの公開\n個人GitHubリポジトリへの公開\nCopy page\n\nGitHubリポジトリリンクを通じたプラグインのインストールに対応しています。プラグイン開発完了後、公開GitHubリポジトリにプラグインを公開して、他のユーザーがダウンロードして使用できるようにすることができます。この方法には以下の利点があります：\n\n個人管理：プラグインのコードとアップデートを完全にコントロール可能\n迅速な共有：GitHubリンクを通じて他のユーザーやチームメンバーと簡単に共有でき、テストや使用が容易\nコラボレーションとフィードバック：プラグインをオープンソース化することで、GitHubの潜在的な協力者を引き付け、プラグインの迅速な改善が可能\n\nこのガイドでは、GitHubリポジトリへのプラグインの公開方法を説明します。\n\n​\n準備作業\nGitHubアカウント\n新規パブリックGitHubリポジトリの作成\nローカルにGitツールがインストール済み\n\nGitHubの基本知識については、GitHubドキュメントを参照してください。\n\n​\n1. プラグインプロジェクトの完成\n\nパブリックGitHubへのアップロードは、プラグインを公開することを意味します。プラグインのデバッグと検証が完了し、README.mdファイルが適切に作成されていることを確認してください。\n\n説明文書には以下の内容を含めることを推奨します：\n\nプラグインの概要と機能説明\nインストールと設定手順\n使用例\n連絡先または貢献ガイドライン\n​\n2. ローカルリポジトリの初期化\n\nプラグインを公開アップロードする前に、デバッグと検証作業が完了していることを確認してください。ターミナルでプラグインプロジェクトフォルダに移動し、以下のコマンドを実行します：\n\nCopy\ngit init\ngit add .\ngit commit -m \"Initial commit: Add plugin files\"\n\n\nGitを初めて使用する場合は、Gitのユーザー名とメールアドレスの設定が必要な場合があります：\n\nCopy\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"your.email@example.com\"\n\n​\n3. リモートリポジトリの接続\n\n以下のコマンドを使用して、ローカルリポジトリをGitHubリポジトリに接続します：\n\nCopy\ngit remote add origin https://github.com/<your-username>/<repository-name>.git\n\n​\n4. プラグインファイルのアップロード\n\nプラグインプロジェクトをプッシュする前に、manifest.yamlファイルのauthorフィールドがGitHub IDと一致していることを確認してください。\n\nプラグインプロジェクトをGitHubリポジトリにプッシュします：\n\nCopy\ngit branch -M main\ngit push -u origin main\n\n\nコードのアップロード時には、後のパッケージング用にタグを付けることを推奨します：\n\nCopy\ngit tag -a v0.0.1 -m \"Release version 0.0.1\"\ngit push origin v0.0.1\n\n​\n5. プラグインコードのパッケージング\n\nGitHubリポジトリのReleasesページで新しいバージョンリリースを作成します。リリース時にはプラグインファイルをアップロードする必要があります。プラグインファイルのパッケージング方法の詳細については、プラグインのパッケージングをご覧ください。\n\n​\nGitHubからのプラグインインストール\n\n他のユーザーは、GitHubリポジトリアドレスを通じてプラグインをインストールできます。Difyプラットフォームのプラグイン管理ページにアクセスし、GitHubからのインストールを選択し、リポジトリアドレスを入力後、バージョン番号とパッケージファイルを選択してインストールを完了します。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nプラグインのプライバシー保護に関するガイドライン\nローカルでの公開と共有\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\n準備作業\n1. プラグインプロジェクトの完成\n2. ローカルリポジトリの初期化\n3. リモートリポジトリの接続\n4. プラグインファイルのアップロード\n5. プラグインコードのパッケージング\nGitHubからのプラグインインストール",
        "error": null
      },
      {
        "link_index": 20,
        "link_text": "ローカルでの公開と共有",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/publish-plugins/package-plugin-file-and-publish",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nPublish plugins\nPRを通じてプラグインを自動的に公開する\nDifyマーケットプレイスへの公開\n個人GitHubリポジトリへの公開\nローカルでの公開と共有\n第三者署名検証のためにプラグインに署名する\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nプラグインの公開\nローカルでの公開と共有\nCopy page\n\nプラグイン開発完了後、プラグインプロジェクトをローカルファイルとしてパッケージ化し、他のユーザーと共有することができます。プラグインファイルを使用してDify Workspaceにインストールすることが可能です。\n\n特徴：\n\nバージョン管理とオープンソース共有が容易\nユーザーはプラグインリンクから直接インストール可能（プラットフォームの審査不要）\n\n公開手順：\n\nプラグインコードをGitHubリポジトリにプッシュ\nリポジトリリンクを共有し、ユーザーはそのリンクを通じてDify Workspaceに統合可能\n\n本文では、プラグインプロジェクトをローカルファイルにパッケージ化する方法と、そのローカルファイルを使用してプラグインをインストールする方法について説明します。\n\n​\n前提条件\n\nDify プラグイン開発ツールが必要です。詳細は開発ツールの初期化ガイドをご参照ください。\n\n設定完了後、ターミナルでdify versionコマンドを実行し、バージョン情報が表示されることを確認して、必要な開発ツールがインストールされていることを確認してください。\n\n​\nプラグインのパッケージ化\n\nパッケージ化の前に、プラグインのmanifest.yamlファイル内のauthorフィールドがGitHub IDと一致していることを確認してください。\n\nプラグインプロジェクトの開発完了後、リモート接続テストが完了していることを確認してください。プラグインプロジェクトの上位ディレクトリに移動し、以下のパッケージ化コマンドを実行します：\n\ndify plugin package ./your_plugin_project\n\nコマンド実行後、現在のパスに.difypkg拡張子のファイルが生成されます。\n\n​\nプラグインのインストール\n\nDifyプラグイン管理ページにアクセスし、右上の「プラグインをインストール」→「ローカルファイルからインストール」を選択するか、プラグインファイルをページの空白部分にドラッグ＆ドロップしてインストールできます。\n\n​\nプラグインの公開\n\nパッケージ化したプラグインファイルを他のユーザーと直接共有するか、インターネット上にアップロードして公開することができます。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\n個人GitHubリポジトリへの公開\n第三者署名検証のためにプラグインに署名する\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\n前提条件\nプラグインのパッケージ化\nプラグインのインストール\nプラグインの公開",
        "error": null
      },
      {
        "link_index": 21,
        "link_text": "第三者署名検証のためにプラグインに署名する",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/publish-plugins/signing-plugins-for-third-party-signature-verification",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nPublish plugins\nPRを通じてプラグインを自動的に公開する\nDifyマーケットプレイスへの公開\n個人GitHubリポジトリへの公開\nローカルでの公開と共有\n第三者署名検証のためにプラグインに署名する\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nプラグインの公開\n第三者署名検証のためにプラグインに署名する\nCopy page\nこの機能はコミュニティ版でのみ利用できます。クラウドサービスでは、現時点では第三者署名検証はサポートされていません。\n\n第三者署名検証により、Dify の管理者は、Dify Marketplace にリストされていないプラグインのインストールを、署名の検証を完全に無効化することなく、安全に許可できるようになります。これにより、例えば次のようなシナリオがサポートされます。\n\nDify の管理者は、開発者から送信されたプラグインを承認したら、プラグインに署名を追加して公開できます\nプラグインの開発者は、署名の検証の無効化が許容されない Dify の管理者のために、プラグインに署名を追加し、公開鍵とともに公開できます\n\nDify の管理者やプラグインの開発者は、事前に準備した秘密鍵でプラグインに署名を追加できます。また、Dify の管理者は、プラグインのインストール時に、特定の公開鍵による署名の検証を強制するように Dify を構成できます。\n\n​\n署名の追加と検証に利用する鍵ペアの生成\n\n次のコマンドで、プラグインの署名の追加と検証に使用する新しい鍵ペアを生成します：\n\nCopy\ndify signature generate -f your_key_pair\n\n\nコマンド実行後、現在のパスに次の 2 つのファイルが生成されます：\n\n秘密鍵： your_key_pair.private.pem\n公開鍵： your_key_pair.public.pem\n\n秘密鍵は、プラグインに署名を追加するために使用され、公開鍵はプラグインの署名を検証するために使用されます。\n\n秘密鍵は充分に秘匿された状態で安全に保管してください。秘密鍵が漏洩すると、攻撃者が任意のプラグインに正規の署名を追加できるようになり、Dify の安全性が脅かされます。\n​\nプラグインへの署名の追加と確認\n\n次のコマンドで、プラグインに署名を追加します。引数で 署名したいプラグインファイル と 秘密鍵 を指定していることに注意してください：\n\nCopy\ndify signature sign your_plugin_project.difypkg -p your_key_pair.private.pem\n\n\nコマンド実行後、元のファイルと同じパスに、ファイル名に signed が追加された新しいプラグインファイルが生成されます： your_plugin_project.signed.difypkg\n\nプラグインファイルが正しく署名されていることは、次のコマンドで確認できます。このコマンドでは、引数で 署名済みのプラグインファイル と 公開鍵 を指定していることに注意してください：\n\nCopy\ndify signature verify your_plugin_project.signed.difypkg -p your_key_pair.public.pem\n\n公開鍵の指定を省略すると、Dify Marketplace 用の公開鍵での検証が行われます。この場合、Dify Marketplace からダウンロードしたプラグインファイル以外は、署名の検証に失敗します。\n​\n第三者署名検証の有効化\n\nDify の管理者は、プラグインのインストール前に、事前に許可した公開鍵よる署名の検証を強制できます。\n\n​\n公開鍵の配置\n\nプラグインの署名に利用した秘密鍵に対応する 公開鍵 を、プラグインデーモンが参照できる場所に配置します。\n\n例えば、docker/volumes/plugin_daemon の下に public_keys ディレクトリを作成し、公開鍵ファイルを配置します。\n\nCopy\nmkdir docker/volumes/plugin_daemon/public_keys\ncp your_key_pair.public.pem docker/volumes/plugin_daemon/public_keys\n\n​\n環境変数の設定\n\nコンテナ plugin_daemon で、次の環境変数を構成します。\n\nTHIRD_PARTY_SIGNATURE_VERIFICATION_ENABLED\n第三者署名検証の有効化を行う環境変数です\ntrue に設定すると、第三者署名検証が有効化されます\nTHIRD_PARTY_SIGNATURE_VERIFICATION_PUBLIC_KEYS\n第三者署名検証に使用する公開鍵ファイルのパスを指定する環境変数です\nカンマ区切りで複数の公開鍵ファイルを指定できます\n\nこれらを構成するための Docker Compose 用のオーバーライドファイル（docker-compose.override.yaml）の例を以下に示します：\n\nCopy\nservices:\n  plugin_daemon:\n    environment:\n      FORCE_VERIFYING_SIGNATURE: true\n      THIRD_PARTY_SIGNATURE_VERIFICATION_ENABLED: true\n      THIRD_PARTY_SIGNATURE_VERIFICATION_PUBLIC_KEYS: /app/storage/public_keys/your_key_pair.public.pem\n\ndocker/volumes/plugin_daemon は、コンテナ plugin_daemon の /app/storageにマウントされています。環境変数 THIRD_PARTY_SIGNATURE_VERIFICATION_PUBLIC_KEYS で指定するパスは、コンテナ内のパスであることに注意してください。\n\n設定を反映させるため、最後に、Dify サービスを再起動します。\n\nCopy\ncd docker\ndocker compose down\ndocker compose up -d\n\n\nサービスを再起動すると、現在のコミュニティ版環境でサードパーティ署名の検証機能が有効になります。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nローカルでの公開と共有\nよくある質問\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\n署名の追加と検証に利用する鍵ペアの生成\nプラグインへの署名の追加と確認\n第三者署名検証の有効化\n公開鍵の配置\n環境変数の設定",
        "error": null
      },
      {
        "link_index": 24,
        "link_text": "​",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/publish-plugins/publish-to-dify-marketplace/README#%E3%83%97%E3%83%A9%E3%82%B0%E3%82%A4%E3%83%B3%E5%85%AC%E9%96%8B%E3%83%97%E3%83%AD%E3%82%BB%E3%82%B9",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nTermbase\nDify Marketplaceへの公開\nCopy page\n\nDify Marketplaceは、Difyプラットフォームを利用する世界中のユーザーにより強力で柔軟な機能拡張を提供することを目指しています。皆様の貢献は、このプラットフォームの可能性をさらに広げることにつながります。\n\n特徴：\n\n審査を経て公開される安全で信頼性の高いプラグイン。\n個人またはチームのWorkspaceに直接インストール可能。\n\n公開手順：\n\nプラグインプロジェクトをDify Marketplaceのリポジトリに提出。\n公式審査を経て、マーケットプレイスで公開され、他のユーザーがインストール可能に。\n\n初めてプラグインを提出する開発者の方も、経験豊富な貢献者の方も、このガイドラインを通じて明確な公開プロセスとベストプラクティスをご提供し、プラグインの円滑な公開とコミュニティへの価値提供を支援いたします。\n\nより開放的で革新的なプラグインエコシステムの構築に、ぜひご参加ください！\n\nプラグインの公開フロー図：\n\n​\nプラグイン公開プロセス\n\nDify Marketplaceへのプラグイン公開は、以下の手順で行います：\n\nDify Pluginリポジトリをフォーク\n新しいブランチを作成し、プラグインのコードとpkgファイルを該当カテゴリにアップロード\nPull Request (PR)を提出し、審査を待機\n審査通過後、プラグインコードがMainブランチにマージされ、自動的にDify Marketplaceに公開\n​\nプラグイン開発チェックリスト\n​\n1. Pull Request (PR)提出前の確認事項\n\n1.1 プラグインの機能性とドキュメントの完全性\n\nプラグインが正常に動作することを確認。\n包括的なREADMEファイルの提供：\nセットアップ手順と使用ガイド。\nサービス接続に必要なコード、API、認証情報などの情報。\nユーザー情報の収集はサービス接続とプラグイン機能の改善のみに使用。\n\n1.2 プラグインの価値提案の検証\n\nDifyユーザーに独自の価値を提供することを確認。\nDifyや他のプラグインにない機能やサービスを導入。\nコミュニティ基準の遵守：\n非暴力的なコンテンツ、グローバルユーザーへの配慮。\n統合サービスの関連ポリシーへの準拠。\n類似プラグインの確認方法：\n既存のプラグインやPRと重複する機能の提出を避ける（以下の場合を除く）：\n新機能の導入。\nパフォーマンスの改善。\nプラグインの独自性の判断基準：\n既存機能の軽微な調整（言語パラメータの追加など）の場合は、既存プラグインの拡張を推奨。\n大幅な機能変更（バッチ処理の最適化やエラー処理の改善など）の場合は、新規プラグインとして提出可能。\n不明な場合は、PRに新規プラグインが必要な理由を簡潔に説明してください。\n\n例：\n\nGoogle検索プラグインの場合、単一の検索クエリを受け取り、Google検索APIを使用して検索結果リストを出力します。\n\n類似の実装で言語パラメータの追加程度の変更であれば、既存プラグインの拡張を推奨します。\n\n一方、バッチ検索の最適化やエラー処理の改善など、新しい実装方法を導入する場合は、独立したプラグインとして審査対象となります。\n\n​\n2. Pull Request (PR)審査中の注意事項\n\nレビュアーからの質問やフィードバックへの積極的な対応：\n\n14日以内に未解決のPRコメントは期限切れとしてマーク（再開可能）。\n30日以内に未解決のPRコメントはクローズ（再開不可、新規PR必要）。\n​\n3. Pull Request (PR)審査通過後\n\n3.1 継続的なメンテナンス\n\nユーザーから報告された問題や機能リクエストへの対応。\n重要なAPI変更時のプラグイン移行： Difyは変更通知と移行手順を事前に公開。 Difyエンジニアが移行サポートを提供。\n\n3.2 Marketplace公開ベータテスト期間の制限 既存プラグインへの破壊的変更を避ける。\n\n​\n審査プロセス\n\n審査順序\n\n先着順でPRを処理。審査は1週間以内に開始。遅延がある場合、レビュアーがPR作成者にコメントで通知。\n\n審査のポイント\n\nプラグイン名、説明、設定手順の明確性と有用性の確認。\n\nManifestファイルのフォーマット規格への準拠と有効な作者連絡先情報の確認。\n\nプラグインの機能性と関連性\n\n提供された設定手順に基づくプラグインのテスト。\nDifyエコシステムにおけるプラグインの妥当性の確認。\n\nDify.aiはプラグイン提出の承認または却下の権利を有します。\n\n​\nよくある質問\n\nQ: プラグインの独自性をどのように判断すればよいですか？\n\nA: 例えば、Google検索プラグインに言語パラメータを追加する程度の変更は既存プラグインの拡張として提出すべきですが、バッチ処理の最適化やエラー処理の改善など、大幅な機能改善がある場合は新規プラグインとして提出可能です。\n\nQ: PRが期限切れまたはクローズされた場合はどうすればよいですか？\n\nA: 期限切れのPRはフィードバックを解決後に再開可能です。クローズされたPR（30日超過）は新規PRの作成が必要です。\n\nQ: ベータテスト期間中にプラグインを更新できますか？\n\nA: 可能ですが、破壊的な変更は避けてください。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nプラグイン公開プロセス\nプラグイン開発チェックリスト\n1. Pull Request (PR)提出前の確認事項\n2. Pull Request (PR)審査中の注意事項\n3. Pull Request (PR)審査通過後\n審査プロセス\nよくある質問",
        "error": null
      },
      {
        "link_index": 25,
        "link_text": "​",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/publish-plugins/publish-to-dify-marketplace/README#%E3%83%97%E3%83%A9%E3%82%B0%E3%82%A4%E3%83%B3%E9%96%8B%E7%99%BA%E3%83%81%E3%82%A7%E3%83%83%E3%82%AF%E3%83%AA%E3%82%B9%E3%83%88",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nTermbase\nDify Marketplaceへの公開\nCopy page\n\nDify Marketplaceは、Difyプラットフォームを利用する世界中のユーザーにより強力で柔軟な機能拡張を提供することを目指しています。皆様の貢献は、このプラットフォームの可能性をさらに広げることにつながります。\n\n特徴：\n\n審査を経て公開される安全で信頼性の高いプラグイン。\n個人またはチームのWorkspaceに直接インストール可能。\n\n公開手順：\n\nプラグインプロジェクトをDify Marketplaceのリポジトリに提出。\n公式審査を経て、マーケットプレイスで公開され、他のユーザーがインストール可能に。\n\n初めてプラグインを提出する開発者の方も、経験豊富な貢献者の方も、このガイドラインを通じて明確な公開プロセスとベストプラクティスをご提供し、プラグインの円滑な公開とコミュニティへの価値提供を支援いたします。\n\nより開放的で革新的なプラグインエコシステムの構築に、ぜひご参加ください！\n\nプラグインの公開フロー図：\n\n​\nプラグイン公開プロセス\n\nDify Marketplaceへのプラグイン公開は、以下の手順で行います：\n\nDify Pluginリポジトリをフォーク\n新しいブランチを作成し、プラグインのコードとpkgファイルを該当カテゴリにアップロード\nPull Request (PR)を提出し、審査を待機\n審査通過後、プラグインコードがMainブランチにマージされ、自動的にDify Marketplaceに公開\n​\nプラグイン開発チェックリスト\n​\n1. Pull Request (PR)提出前の確認事項\n\n1.1 プラグインの機能性とドキュメントの完全性\n\nプラグインが正常に動作することを確認。\n包括的なREADMEファイルの提供：\nセットアップ手順と使用ガイド。\nサービス接続に必要なコード、API、認証情報などの情報。\nユーザー情報の収集はサービス接続とプラグイン機能の改善のみに使用。\n\n1.2 プラグインの価値提案の検証\n\nDifyユーザーに独自の価値を提供することを確認。\nDifyや他のプラグインにない機能やサービスを導入。\nコミュニティ基準の遵守：\n非暴力的なコンテンツ、グローバルユーザーへの配慮。\n統合サービスの関連ポリシーへの準拠。\n類似プラグインの確認方法：\n既存のプラグインやPRと重複する機能の提出を避ける（以下の場合を除く）：\n新機能の導入。\nパフォーマンスの改善。\nプラグインの独自性の判断基準：\n既存機能の軽微な調整（言語パラメータの追加など）の場合は、既存プラグインの拡張を推奨。\n大幅な機能変更（バッチ処理の最適化やエラー処理の改善など）の場合は、新規プラグインとして提出可能。\n不明な場合は、PRに新規プラグインが必要な理由を簡潔に説明してください。\n\n例：\n\nGoogle検索プラグインの場合、単一の検索クエリを受け取り、Google検索APIを使用して検索結果リストを出力します。\n\n類似の実装で言語パラメータの追加程度の変更であれば、既存プラグインの拡張を推奨します。\n\n一方、バッチ検索の最適化やエラー処理の改善など、新しい実装方法を導入する場合は、独立したプラグインとして審査対象となります。\n\n​\n2. Pull Request (PR)審査中の注意事項\n\nレビュアーからの質問やフィードバックへの積極的な対応：\n\n14日以内に未解決のPRコメントは期限切れとしてマーク（再開可能）。\n30日以内に未解決のPRコメントはクローズ（再開不可、新規PR必要）。\n​\n3. Pull Request (PR)審査通過後\n\n3.1 継続的なメンテナンス\n\nユーザーから報告された問題や機能リクエストへの対応。\n重要なAPI変更時のプラグイン移行： Difyは変更通知と移行手順を事前に公開。 Difyエンジニアが移行サポートを提供。\n\n3.2 Marketplace公開ベータテスト期間の制限 既存プラグインへの破壊的変更を避ける。\n\n​\n審査プロセス\n\n審査順序\n\n先着順でPRを処理。審査は1週間以内に開始。遅延がある場合、レビュアーがPR作成者にコメントで通知。\n\n審査のポイント\n\nプラグイン名、説明、設定手順の明確性と有用性の確認。\n\nManifestファイルのフォーマット規格への準拠と有効な作者連絡先情報の確認。\n\nプラグインの機能性と関連性\n\n提供された設定手順に基づくプラグインのテスト。\nDifyエコシステムにおけるプラグインの妥当性の確認。\n\nDify.aiはプラグイン提出の承認または却下の権利を有します。\n\n​\nよくある質問\n\nQ: プラグインの独自性をどのように判断すればよいですか？\n\nA: 例えば、Google検索プラグインに言語パラメータを追加する程度の変更は既存プラグインの拡張として提出すべきですが、バッチ処理の最適化やエラー処理の改善など、大幅な機能改善がある場合は新規プラグインとして提出可能です。\n\nQ: PRが期限切れまたはクローズされた場合はどうすればよいですか？\n\nA: 期限切れのPRはフィードバックを解決後に再開可能です。クローズされたPR（30日超過）は新規PRの作成が必要です。\n\nQ: ベータテスト期間中にプラグインを更新できますか？\n\nA: 可能ですが、破壊的な変更は避けてください。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nプラグイン公開プロセス\nプラグイン開発チェックリスト\n1. Pull Request (PR)提出前の確認事項\n2. Pull Request (PR)審査中の注意事項\n3. Pull Request (PR)審査通過後\n審査プロセス\nよくある質問",
        "error": null
      },
      {
        "link_index": 26,
        "link_text": "​",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/publish-plugins/publish-to-dify-marketplace/README#1-pull-request-pr-%E6%8F%90%E5%87%BA%E5%89%8D%E3%81%AE%E7%A2%BA%E8%AA%8D%E4%BA%8B%E9%A0%85",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nTermbase\nDify Marketplaceへの公開\nCopy page\n\nDify Marketplaceは、Difyプラットフォームを利用する世界中のユーザーにより強力で柔軟な機能拡張を提供することを目指しています。皆様の貢献は、このプラットフォームの可能性をさらに広げることにつながります。\n\n特徴：\n\n審査を経て公開される安全で信頼性の高いプラグイン。\n個人またはチームのWorkspaceに直接インストール可能。\n\n公開手順：\n\nプラグインプロジェクトをDify Marketplaceのリポジトリに提出。\n公式審査を経て、マーケットプレイスで公開され、他のユーザーがインストール可能に。\n\n初めてプラグインを提出する開発者の方も、経験豊富な貢献者の方も、このガイドラインを通じて明確な公開プロセスとベストプラクティスをご提供し、プラグインの円滑な公開とコミュニティへの価値提供を支援いたします。\n\nより開放的で革新的なプラグインエコシステムの構築に、ぜひご参加ください！\n\nプラグインの公開フロー図：\n\n​\nプラグイン公開プロセス\n\nDify Marketplaceへのプラグイン公開は、以下の手順で行います：\n\nDify Pluginリポジトリをフォーク\n新しいブランチを作成し、プラグインのコードとpkgファイルを該当カテゴリにアップロード\nPull Request (PR)を提出し、審査を待機\n審査通過後、プラグインコードがMainブランチにマージされ、自動的にDify Marketplaceに公開\n​\nプラグイン開発チェックリスト\n​\n1. Pull Request (PR)提出前の確認事項\n\n1.1 プラグインの機能性とドキュメントの完全性\n\nプラグインが正常に動作することを確認。\n包括的なREADMEファイルの提供：\nセットアップ手順と使用ガイド。\nサービス接続に必要なコード、API、認証情報などの情報。\nユーザー情報の収集はサービス接続とプラグイン機能の改善のみに使用。\n\n1.2 プラグインの価値提案の検証\n\nDifyユーザーに独自の価値を提供することを確認。\nDifyや他のプラグインにない機能やサービスを導入。\nコミュニティ基準の遵守：\n非暴力的なコンテンツ、グローバルユーザーへの配慮。\n統合サービスの関連ポリシーへの準拠。\n類似プラグインの確認方法：\n既存のプラグインやPRと重複する機能の提出を避ける（以下の場合を除く）：\n新機能の導入。\nパフォーマンスの改善。\nプラグインの独自性の判断基準：\n既存機能の軽微な調整（言語パラメータの追加など）の場合は、既存プラグインの拡張を推奨。\n大幅な機能変更（バッチ処理の最適化やエラー処理の改善など）の場合は、新規プラグインとして提出可能。\n不明な場合は、PRに新規プラグインが必要な理由を簡潔に説明してください。\n\n例：\n\nGoogle検索プラグインの場合、単一の検索クエリを受け取り、Google検索APIを使用して検索結果リストを出力します。\n\n類似の実装で言語パラメータの追加程度の変更であれば、既存プラグインの拡張を推奨します。\n\n一方、バッチ検索の最適化やエラー処理の改善など、新しい実装方法を導入する場合は、独立したプラグインとして審査対象となります。\n\n​\n2. Pull Request (PR)審査中の注意事項\n\nレビュアーからの質問やフィードバックへの積極的な対応：\n\n14日以内に未解決のPRコメントは期限切れとしてマーク（再開可能）。\n30日以内に未解決のPRコメントはクローズ（再開不可、新規PR必要）。\n​\n3. Pull Request (PR)審査通過後\n\n3.1 継続的なメンテナンス\n\nユーザーから報告された問題や機能リクエストへの対応。\n重要なAPI変更時のプラグイン移行： Difyは変更通知と移行手順を事前に公開。 Difyエンジニアが移行サポートを提供。\n\n3.2 Marketplace公開ベータテスト期間の制限 既存プラグインへの破壊的変更を避ける。\n\n​\n審査プロセス\n\n審査順序\n\n先着順でPRを処理。審査は1週間以内に開始。遅延がある場合、レビュアーがPR作成者にコメントで通知。\n\n審査のポイント\n\nプラグイン名、説明、設定手順の明確性と有用性の確認。\n\nManifestファイルのフォーマット規格への準拠と有効な作者連絡先情報の確認。\n\nプラグインの機能性と関連性\n\n提供された設定手順に基づくプラグインのテスト。\nDifyエコシステムにおけるプラグインの妥当性の確認。\n\nDify.aiはプラグイン提出の承認または却下の権利を有します。\n\n​\nよくある質問\n\nQ: プラグインの独自性をどのように判断すればよいですか？\n\nA: 例えば、Google検索プラグインに言語パラメータを追加する程度の変更は既存プラグインの拡張として提出すべきですが、バッチ処理の最適化やエラー処理の改善など、大幅な機能改善がある場合は新規プラグインとして提出可能です。\n\nQ: PRが期限切れまたはクローズされた場合はどうすればよいですか？\n\nA: 期限切れのPRはフィードバックを解決後に再開可能です。クローズされたPR（30日超過）は新規PRの作成が必要です。\n\nQ: ベータテスト期間中にプラグインを更新できますか？\n\nA: 可能ですが、破壊的な変更は避けてください。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nプラグイン公開プロセス\nプラグイン開発チェックリスト\n1. Pull Request (PR)提出前の確認事項\n2. Pull Request (PR)審査中の注意事項\n3. Pull Request (PR)審査通過後\n審査プロセス\nよくある質問",
        "error": null
      },
      {
        "link_index": 27,
        "link_text": "​",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/publish-plugins/publish-to-dify-marketplace/README#2-pull-request-pr-%E5%AF%A9%E6%9F%BB%E4%B8%AD%E3%81%AE%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A0%85",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nTermbase\nDify Marketplaceへの公開\nCopy page\n\nDify Marketplaceは、Difyプラットフォームを利用する世界中のユーザーにより強力で柔軟な機能拡張を提供することを目指しています。皆様の貢献は、このプラットフォームの可能性をさらに広げることにつながります。\n\n特徴：\n\n審査を経て公開される安全で信頼性の高いプラグイン。\n個人またはチームのWorkspaceに直接インストール可能。\n\n公開手順：\n\nプラグインプロジェクトをDify Marketplaceのリポジトリに提出。\n公式審査を経て、マーケットプレイスで公開され、他のユーザーがインストール可能に。\n\n初めてプラグインを提出する開発者の方も、経験豊富な貢献者の方も、このガイドラインを通じて明確な公開プロセスとベストプラクティスをご提供し、プラグインの円滑な公開とコミュニティへの価値提供を支援いたします。\n\nより開放的で革新的なプラグインエコシステムの構築に、ぜひご参加ください！\n\nプラグインの公開フロー図：\n\n​\nプラグイン公開プロセス\n\nDify Marketplaceへのプラグイン公開は、以下の手順で行います：\n\nDify Pluginリポジトリをフォーク\n新しいブランチを作成し、プラグインのコードとpkgファイルを該当カテゴリにアップロード\nPull Request (PR)を提出し、審査を待機\n審査通過後、プラグインコードがMainブランチにマージされ、自動的にDify Marketplaceに公開\n​\nプラグイン開発チェックリスト\n​\n1. Pull Request (PR)提出前の確認事項\n\n1.1 プラグインの機能性とドキュメントの完全性\n\nプラグインが正常に動作することを確認。\n包括的なREADMEファイルの提供：\nセットアップ手順と使用ガイド。\nサービス接続に必要なコード、API、認証情報などの情報。\nユーザー情報の収集はサービス接続とプラグイン機能の改善のみに使用。\n\n1.2 プラグインの価値提案の検証\n\nDifyユーザーに独自の価値を提供することを確認。\nDifyや他のプラグインにない機能やサービスを導入。\nコミュニティ基準の遵守：\n非暴力的なコンテンツ、グローバルユーザーへの配慮。\n統合サービスの関連ポリシーへの準拠。\n類似プラグインの確認方法：\n既存のプラグインやPRと重複する機能の提出を避ける（以下の場合を除く）：\n新機能の導入。\nパフォーマンスの改善。\nプラグインの独自性の判断基準：\n既存機能の軽微な調整（言語パラメータの追加など）の場合は、既存プラグインの拡張を推奨。\n大幅な機能変更（バッチ処理の最適化やエラー処理の改善など）の場合は、新規プラグインとして提出可能。\n不明な場合は、PRに新規プラグインが必要な理由を簡潔に説明してください。\n\n例：\n\nGoogle検索プラグインの場合、単一の検索クエリを受け取り、Google検索APIを使用して検索結果リストを出力します。\n\n類似の実装で言語パラメータの追加程度の変更であれば、既存プラグインの拡張を推奨します。\n\n一方、バッチ検索の最適化やエラー処理の改善など、新しい実装方法を導入する場合は、独立したプラグインとして審査対象となります。\n\n​\n2. Pull Request (PR)審査中の注意事項\n\nレビュアーからの質問やフィードバックへの積極的な対応：\n\n14日以内に未解決のPRコメントは期限切れとしてマーク（再開可能）。\n30日以内に未解決のPRコメントはクローズ（再開不可、新規PR必要）。\n​\n3. Pull Request (PR)審査通過後\n\n3.1 継続的なメンテナンス\n\nユーザーから報告された問題や機能リクエストへの対応。\n重要なAPI変更時のプラグイン移行： Difyは変更通知と移行手順を事前に公開。 Difyエンジニアが移行サポートを提供。\n\n3.2 Marketplace公開ベータテスト期間の制限 既存プラグインへの破壊的変更を避ける。\n\n​\n審査プロセス\n\n審査順序\n\n先着順でPRを処理。審査は1週間以内に開始。遅延がある場合、レビュアーがPR作成者にコメントで通知。\n\n審査のポイント\n\nプラグイン名、説明、設定手順の明確性と有用性の確認。\n\nManifestファイルのフォーマット規格への準拠と有効な作者連絡先情報の確認。\n\nプラグインの機能性と関連性\n\n提供された設定手順に基づくプラグインのテスト。\nDifyエコシステムにおけるプラグインの妥当性の確認。\n\nDify.aiはプラグイン提出の承認または却下の権利を有します。\n\n​\nよくある質問\n\nQ: プラグインの独自性をどのように判断すればよいですか？\n\nA: 例えば、Google検索プラグインに言語パラメータを追加する程度の変更は既存プラグインの拡張として提出すべきですが、バッチ処理の最適化やエラー処理の改善など、大幅な機能改善がある場合は新規プラグインとして提出可能です。\n\nQ: PRが期限切れまたはクローズされた場合はどうすればよいですか？\n\nA: 期限切れのPRはフィードバックを解決後に再開可能です。クローズされたPR（30日超過）は新規PRの作成が必要です。\n\nQ: ベータテスト期間中にプラグインを更新できますか？\n\nA: 可能ですが、破壊的な変更は避けてください。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nプラグイン公開プロセス\nプラグイン開発チェックリスト\n1. Pull Request (PR)提出前の確認事項\n2. Pull Request (PR)審査中の注意事項\n3. Pull Request (PR)審査通過後\n審査プロセス\nよくある質問",
        "error": null
      },
      {
        "link_index": 28,
        "link_text": "​",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/publish-plugins/publish-to-dify-marketplace/README#3-pull-request-pr-%E5%AF%A9%E6%9F%BB%E9%80%9A%E9%81%8E%E5%BE%8C",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nTermbase\nDify Marketplaceへの公開\nCopy page\n\nDify Marketplaceは、Difyプラットフォームを利用する世界中のユーザーにより強力で柔軟な機能拡張を提供することを目指しています。皆様の貢献は、このプラットフォームの可能性をさらに広げることにつながります。\n\n特徴：\n\n審査を経て公開される安全で信頼性の高いプラグイン。\n個人またはチームのWorkspaceに直接インストール可能。\n\n公開手順：\n\nプラグインプロジェクトをDify Marketplaceのリポジトリに提出。\n公式審査を経て、マーケットプレイスで公開され、他のユーザーがインストール可能に。\n\n初めてプラグインを提出する開発者の方も、経験豊富な貢献者の方も、このガイドラインを通じて明確な公開プロセスとベストプラクティスをご提供し、プラグインの円滑な公開とコミュニティへの価値提供を支援いたします。\n\nより開放的で革新的なプラグインエコシステムの構築に、ぜひご参加ください！\n\nプラグインの公開フロー図：\n\n​\nプラグイン公開プロセス\n\nDify Marketplaceへのプラグイン公開は、以下の手順で行います：\n\nDify Pluginリポジトリをフォーク\n新しいブランチを作成し、プラグインのコードとpkgファイルを該当カテゴリにアップロード\nPull Request (PR)を提出し、審査を待機\n審査通過後、プラグインコードがMainブランチにマージされ、自動的にDify Marketplaceに公開\n​\nプラグイン開発チェックリスト\n​\n1. Pull Request (PR)提出前の確認事項\n\n1.1 プラグインの機能性とドキュメントの完全性\n\nプラグインが正常に動作することを確認。\n包括的なREADMEファイルの提供：\nセットアップ手順と使用ガイド。\nサービス接続に必要なコード、API、認証情報などの情報。\nユーザー情報の収集はサービス接続とプラグイン機能の改善のみに使用。\n\n1.2 プラグインの価値提案の検証\n\nDifyユーザーに独自の価値を提供することを確認。\nDifyや他のプラグインにない機能やサービスを導入。\nコミュニティ基準の遵守：\n非暴力的なコンテンツ、グローバルユーザーへの配慮。\n統合サービスの関連ポリシーへの準拠。\n類似プラグインの確認方法：\n既存のプラグインやPRと重複する機能の提出を避ける（以下の場合を除く）：\n新機能の導入。\nパフォーマンスの改善。\nプラグインの独自性の判断基準：\n既存機能の軽微な調整（言語パラメータの追加など）の場合は、既存プラグインの拡張を推奨。\n大幅な機能変更（バッチ処理の最適化やエラー処理の改善など）の場合は、新規プラグインとして提出可能。\n不明な場合は、PRに新規プラグインが必要な理由を簡潔に説明してください。\n\n例：\n\nGoogle検索プラグインの場合、単一の検索クエリを受け取り、Google検索APIを使用して検索結果リストを出力します。\n\n類似の実装で言語パラメータの追加程度の変更であれば、既存プラグインの拡張を推奨します。\n\n一方、バッチ検索の最適化やエラー処理の改善など、新しい実装方法を導入する場合は、独立したプラグインとして審査対象となります。\n\n​\n2. Pull Request (PR)審査中の注意事項\n\nレビュアーからの質問やフィードバックへの積極的な対応：\n\n14日以内に未解決のPRコメントは期限切れとしてマーク（再開可能）。\n30日以内に未解決のPRコメントはクローズ（再開不可、新規PR必要）。\n​\n3. Pull Request (PR)審査通過後\n\n3.1 継続的なメンテナンス\n\nユーザーから報告された問題や機能リクエストへの対応。\n重要なAPI変更時のプラグイン移行： Difyは変更通知と移行手順を事前に公開。 Difyエンジニアが移行サポートを提供。\n\n3.2 Marketplace公開ベータテスト期間の制限 既存プラグインへの破壊的変更を避ける。\n\n​\n審査プロセス\n\n審査順序\n\n先着順でPRを処理。審査は1週間以内に開始。遅延がある場合、レビュアーがPR作成者にコメントで通知。\n\n審査のポイント\n\nプラグイン名、説明、設定手順の明確性と有用性の確認。\n\nManifestファイルのフォーマット規格への準拠と有効な作者連絡先情報の確認。\n\nプラグインの機能性と関連性\n\n提供された設定手順に基づくプラグインのテスト。\nDifyエコシステムにおけるプラグインの妥当性の確認。\n\nDify.aiはプラグイン提出の承認または却下の権利を有します。\n\n​\nよくある質問\n\nQ: プラグインの独自性をどのように判断すればよいですか？\n\nA: 例えば、Google検索プラグインに言語パラメータを追加する程度の変更は既存プラグインの拡張として提出すべきですが、バッチ処理の最適化やエラー処理の改善など、大幅な機能改善がある場合は新規プラグインとして提出可能です。\n\nQ: PRが期限切れまたはクローズされた場合はどうすればよいですか？\n\nA: 期限切れのPRはフィードバックを解決後に再開可能です。クローズされたPR（30日超過）は新規PRの作成が必要です。\n\nQ: ベータテスト期間中にプラグインを更新できますか？\n\nA: 可能ですが、破壊的な変更は避けてください。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nプラグイン公開プロセス\nプラグイン開発チェックリスト\n1. Pull Request (PR)提出前の確認事項\n2. Pull Request (PR)審査中の注意事項\n3. Pull Request (PR)審査通過後\n審査プロセス\nよくある質問",
        "error": null
      },
      {
        "link_index": 29,
        "link_text": "​",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/publish-plugins/publish-to-dify-marketplace/README#%E5%AF%A9%E6%9F%BB%E3%83%97%E3%83%AD%E3%82%BB%E3%82%B9",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nTermbase\nDify Marketplaceへの公開\nCopy page\n\nDify Marketplaceは、Difyプラットフォームを利用する世界中のユーザーにより強力で柔軟な機能拡張を提供することを目指しています。皆様の貢献は、このプラットフォームの可能性をさらに広げることにつながります。\n\n特徴：\n\n審査を経て公開される安全で信頼性の高いプラグイン。\n個人またはチームのWorkspaceに直接インストール可能。\n\n公開手順：\n\nプラグインプロジェクトをDify Marketplaceのリポジトリに提出。\n公式審査を経て、マーケットプレイスで公開され、他のユーザーがインストール可能に。\n\n初めてプラグインを提出する開発者の方も、経験豊富な貢献者の方も、このガイドラインを通じて明確な公開プロセスとベストプラクティスをご提供し、プラグインの円滑な公開とコミュニティへの価値提供を支援いたします。\n\nより開放的で革新的なプラグインエコシステムの構築に、ぜひご参加ください！\n\nプラグインの公開フロー図：\n\n​\nプラグイン公開プロセス\n\nDify Marketplaceへのプラグイン公開は、以下の手順で行います：\n\nDify Pluginリポジトリをフォーク\n新しいブランチを作成し、プラグインのコードとpkgファイルを該当カテゴリにアップロード\nPull Request (PR)を提出し、審査を待機\n審査通過後、プラグインコードがMainブランチにマージされ、自動的にDify Marketplaceに公開\n​\nプラグイン開発チェックリスト\n​\n1. Pull Request (PR)提出前の確認事項\n\n1.1 プラグインの機能性とドキュメントの完全性\n\nプラグインが正常に動作することを確認。\n包括的なREADMEファイルの提供：\nセットアップ手順と使用ガイド。\nサービス接続に必要なコード、API、認証情報などの情報。\nユーザー情報の収集はサービス接続とプラグイン機能の改善のみに使用。\n\n1.2 プラグインの価値提案の検証\n\nDifyユーザーに独自の価値を提供することを確認。\nDifyや他のプラグインにない機能やサービスを導入。\nコミュニティ基準の遵守：\n非暴力的なコンテンツ、グローバルユーザーへの配慮。\n統合サービスの関連ポリシーへの準拠。\n類似プラグインの確認方法：\n既存のプラグインやPRと重複する機能の提出を避ける（以下の場合を除く）：\n新機能の導入。\nパフォーマンスの改善。\nプラグインの独自性の判断基準：\n既存機能の軽微な調整（言語パラメータの追加など）の場合は、既存プラグインの拡張を推奨。\n大幅な機能変更（バッチ処理の最適化やエラー処理の改善など）の場合は、新規プラグインとして提出可能。\n不明な場合は、PRに新規プラグインが必要な理由を簡潔に説明してください。\n\n例：\n\nGoogle検索プラグインの場合、単一の検索クエリを受け取り、Google検索APIを使用して検索結果リストを出力します。\n\n類似の実装で言語パラメータの追加程度の変更であれば、既存プラグインの拡張を推奨します。\n\n一方、バッチ検索の最適化やエラー処理の改善など、新しい実装方法を導入する場合は、独立したプラグインとして審査対象となります。\n\n​\n2. Pull Request (PR)審査中の注意事項\n\nレビュアーからの質問やフィードバックへの積極的な対応：\n\n14日以内に未解決のPRコメントは期限切れとしてマーク（再開可能）。\n30日以内に未解決のPRコメントはクローズ（再開不可、新規PR必要）。\n​\n3. Pull Request (PR)審査通過後\n\n3.1 継続的なメンテナンス\n\nユーザーから報告された問題や機能リクエストへの対応。\n重要なAPI変更時のプラグイン移行： Difyは変更通知と移行手順を事前に公開。 Difyエンジニアが移行サポートを提供。\n\n3.2 Marketplace公開ベータテスト期間の制限 既存プラグインへの破壊的変更を避ける。\n\n​\n審査プロセス\n\n審査順序\n\n先着順でPRを処理。審査は1週間以内に開始。遅延がある場合、レビュアーがPR作成者にコメントで通知。\n\n審査のポイント\n\nプラグイン名、説明、設定手順の明確性と有用性の確認。\n\nManifestファイルのフォーマット規格への準拠と有効な作者連絡先情報の確認。\n\nプラグインの機能性と関連性\n\n提供された設定手順に基づくプラグインのテスト。\nDifyエコシステムにおけるプラグインの妥当性の確認。\n\nDify.aiはプラグイン提出の承認または却下の権利を有します。\n\n​\nよくある質問\n\nQ: プラグインの独自性をどのように判断すればよいですか？\n\nA: 例えば、Google検索プラグインに言語パラメータを追加する程度の変更は既存プラグインの拡張として提出すべきですが、バッチ処理の最適化やエラー処理の改善など、大幅な機能改善がある場合は新規プラグインとして提出可能です。\n\nQ: PRが期限切れまたはクローズされた場合はどうすればよいですか？\n\nA: 期限切れのPRはフィードバックを解決後に再開可能です。クローズされたPR（30日超過）は新規PRの作成が必要です。\n\nQ: ベータテスト期間中にプラグインを更新できますか？\n\nA: 可能ですが、破壊的な変更は避けてください。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nプラグイン公開プロセス\nプラグイン開発チェックリスト\n1. Pull Request (PR)提出前の確認事項\n2. Pull Request (PR)審査中の注意事項\n3. Pull Request (PR)審査通過後\n審査プロセス\nよくある質問",
        "error": null
      },
      {
        "link_index": 32,
        "link_text": "​",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/publish-plugins/publish-to-dify-marketplace/README#%E3%82%88%E3%81%8F%E3%81%82%E3%82%8B%E8%B3%AA%E5%95%8F",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nTermbase\nDify Marketplaceへの公開\nCopy page\n\nDify Marketplaceは、Difyプラットフォームを利用する世界中のユーザーにより強力で柔軟な機能拡張を提供することを目指しています。皆様の貢献は、このプラットフォームの可能性をさらに広げることにつながります。\n\n特徴：\n\n審査を経て公開される安全で信頼性の高いプラグイン。\n個人またはチームのWorkspaceに直接インストール可能。\n\n公開手順：\n\nプラグインプロジェクトをDify Marketplaceのリポジトリに提出。\n公式審査を経て、マーケットプレイスで公開され、他のユーザーがインストール可能に。\n\n初めてプラグインを提出する開発者の方も、経験豊富な貢献者の方も、このガイドラインを通じて明確な公開プロセスとベストプラクティスをご提供し、プラグインの円滑な公開とコミュニティへの価値提供を支援いたします。\n\nより開放的で革新的なプラグインエコシステムの構築に、ぜひご参加ください！\n\nプラグインの公開フロー図：\n\n​\nプラグイン公開プロセス\n\nDify Marketplaceへのプラグイン公開は、以下の手順で行います：\n\nDify Pluginリポジトリをフォーク\n新しいブランチを作成し、プラグインのコードとpkgファイルを該当カテゴリにアップロード\nPull Request (PR)を提出し、審査を待機\n審査通過後、プラグインコードがMainブランチにマージされ、自動的にDify Marketplaceに公開\n​\nプラグイン開発チェックリスト\n​\n1. Pull Request (PR)提出前の確認事項\n\n1.1 プラグインの機能性とドキュメントの完全性\n\nプラグインが正常に動作することを確認。\n包括的なREADMEファイルの提供：\nセットアップ手順と使用ガイド。\nサービス接続に必要なコード、API、認証情報などの情報。\nユーザー情報の収集はサービス接続とプラグイン機能の改善のみに使用。\n\n1.2 プラグインの価値提案の検証\n\nDifyユーザーに独自の価値を提供することを確認。\nDifyや他のプラグインにない機能やサービスを導入。\nコミュニティ基準の遵守：\n非暴力的なコンテンツ、グローバルユーザーへの配慮。\n統合サービスの関連ポリシーへの準拠。\n類似プラグインの確認方法：\n既存のプラグインやPRと重複する機能の提出を避ける（以下の場合を除く）：\n新機能の導入。\nパフォーマンスの改善。\nプラグインの独自性の判断基準：\n既存機能の軽微な調整（言語パラメータの追加など）の場合は、既存プラグインの拡張を推奨。\n大幅な機能変更（バッチ処理の最適化やエラー処理の改善など）の場合は、新規プラグインとして提出可能。\n不明な場合は、PRに新規プラグインが必要な理由を簡潔に説明してください。\n\n例：\n\nGoogle検索プラグインの場合、単一の検索クエリを受け取り、Google検索APIを使用して検索結果リストを出力します。\n\n類似の実装で言語パラメータの追加程度の変更であれば、既存プラグインの拡張を推奨します。\n\n一方、バッチ検索の最適化やエラー処理の改善など、新しい実装方法を導入する場合は、独立したプラグインとして審査対象となります。\n\n​\n2. Pull Request (PR)審査中の注意事項\n\nレビュアーからの質問やフィードバックへの積極的な対応：\n\n14日以内に未解決のPRコメントは期限切れとしてマーク（再開可能）。\n30日以内に未解決のPRコメントはクローズ（再開不可、新規PR必要）。\n​\n3. Pull Request (PR)審査通過後\n\n3.1 継続的なメンテナンス\n\nユーザーから報告された問題や機能リクエストへの対応。\n重要なAPI変更時のプラグイン移行： Difyは変更通知と移行手順を事前に公開。 Difyエンジニアが移行サポートを提供。\n\n3.2 Marketplace公開ベータテスト期間の制限 既存プラグインへの破壊的変更を避ける。\n\n​\n審査プロセス\n\n審査順序\n\n先着順でPRを処理。審査は1週間以内に開始。遅延がある場合、レビュアーがPR作成者にコメントで通知。\n\n審査のポイント\n\nプラグイン名、説明、設定手順の明確性と有用性の確認。\n\nManifestファイルのフォーマット規格への準拠と有効な作者連絡先情報の確認。\n\nプラグインの機能性と関連性\n\n提供された設定手順に基づくプラグインのテスト。\nDifyエコシステムにおけるプラグインの妥当性の確認。\n\nDify.aiはプラグイン提出の承認または却下の権利を有します。\n\n​\nよくある質問\n\nQ: プラグインの独自性をどのように判断すればよいですか？\n\nA: 例えば、Google検索プラグインに言語パラメータを追加する程度の変更は既存プラグインの拡張として提出すべきですが、バッチ処理の最適化やエラー処理の改善など、大幅な機能改善がある場合は新規プラグインとして提出可能です。\n\nQ: PRが期限切れまたはクローズされた場合はどうすればよいですか？\n\nA: 期限切れのPRはフィードバックを解決後に再開可能です。クローズされたPR（30日超過）は新規PRの作成が必要です。\n\nQ: ベータテスト期間中にプラグインを更新できますか？\n\nA: 可能ですが、破壊的な変更は避けてください。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nプラグイン公開プロセス\nプラグイン開発チェックリスト\n1. Pull Request (PR)提出前の確認事項\n2. Pull Request (PR)審査中の注意事項\n3. Pull Request (PR)審査通過後\n審査プロセス\nよくある質問",
        "error": null
      }
    ],
    "errors": []
  }
]