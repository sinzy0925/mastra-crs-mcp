[
  {
    "source_page": "https://docs.dify.ai/ja-jp/plugins/schema-definition/reverse-invocation-of-the-dify-service/README",
    "mode": "loop-links",
    "link_selector": "a",
    "target_index_requested": -1,
    "extract_target": "body",
    "item_selector_for_links": "",
    "processed_links": [
      {
        "link_index": 0,
        "link_text": "Dify Docs home page",
        "target_url": "https://docs.dify.ai/",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nGetting Started\nWelcome to Dify\nIntroduction\nFeatures and Specifications\nList of Model Providers\nDify Community\nDify Cloud\nDify Premium on AWS\nDify for Education\nGuide\nModel Configuration\nApplication Orchestration\nWorkflow\nKnowledge\nPublishing\nAnnotation\nMonitoring\nExtensions\nCollaboration\nManagement\nWorkshop\nWorkshop\nBasic\nIntermediate\nCommunity\nSeek Support\nBecome a Contributor\nContributing to Dify Documentation\nPlugins\nIntroduction\nQuick Start\nManage Plugins\nSchema Specification\nBest Practice\nPublish Plugins\nFAQ\nDevelopment\nBackend\nModels Integration\nMigration\nLearn More\nUse Cases\nExtended Reading\nFAQ\nPolicies\nLicense\nUser Agreement\nWelcome to Dify\nIntroduction\nCopy page\n\nDify is an open-source platform for building AI applications. We combine Backend-as-a-Service and LLMOps to streamline the development of generative AI solutions, making it accessible to both developers and non-technical innovators.\n\nOur platform integrates:\n\nSupport for mainstream LLMs\nAn intuitive Prompt orchestration interface\nHigh-quality RAG engines\nA flexible AI Agent framework\nAn Intuitive Low-code Workflow\nEasy-to-use interfaces and APIs\n\nWith Dify, you can skip the complexity and focus on what matters most - creating innovative AI applications that solve real-world problems.\n\n​\nThe Advantage of Dify\n\nWhile many AI development tools offer individual components, Dify provides a comprehensive, production-ready solution. Think of Dify as a well-designed scaffolding system, not just a toolbox.\n\nAs an open-source platform, Dify is co-created by a dedicated professional team and a vibrant community. This collaboration ensures rapid iteration, robust features, and a user-friendly interface.\n\nWith Dify, you can:\n\nDeploy capabilities similar to Assistants API and GPTs using any model\nMaintain full control over your data with flexible security options\nLeverage an intuitive interface for easy management and deployment\n​\nDify\n\nThe name Dify comes from “Define + Modify”, referring to defining and continuously improving your AI applications. It’s made for you.\n\nHere’s how various groups are leveraging Dify:\n\nStartups: Rapidly prototype and iterate on AI ideas, accelerating both successes and failures. Numerous teams have used Dify to build MVPs, secure funding, and win customer contracts.\nEstablished Businesses: Enhance existing applications with LLM capabilities. Use Dify’s RESTful APIs to separate prompts from business logic, while utilizing our management interface to track data, costs, and usage.\nEnterprise AI infrastructure: Banks and tech companies are deploying Dify as an internal LLM gateway, facilitating GenAI adoption with centralized governance.\nAI Enthusiasts and Learners: Practice prompt engineering and explore agent technologies with ease. Over 60,000 developers built their first AI app on Dify even before GPTs were introduced. Since then, our community has grown significantly, now boasting over 180,000 developers and supporting 59,000+ end users.\n\nWhether you’re a startup founder, an enterprise developer, or an AI enthusiast, Dify is designed to meet your needs and accelerate your AI journey!\n\n​\nNext Steps\nRead Quick Start for an overview of Dify’s application building workflow.\nLearn how to self-deploy Dify to your servers and integrate open source models.\nUnderstand Dify’s specifications and roadmap.\nStar us on GitHub and read our Contributor Guidelines.\nEdit this page\n\nHelp improve our documentation by contributing directly\n\nReport an issue\n\nFound an error or have suggestions? Let us know\n\nWas this page helpful?\n\nYes\nNo\nFeatures and Specifications\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nThe Advantage of Dify\nDify\nNext Steps",
        "error": null
      },
      {
        "link_index": 1,
        "link_text": "Blog",
        "target_url": "https://dify.ai/blog",
        "extract_target": "body",
        "extracted_data": "Dify.ai\n\nInsights\n\nProduct\n\nProduct\n\nProduct\n\nPricing\n\nPricing\n\nPricing\n\nMarketplace\n\nMarketplace\n\nMarketplace\n\nDocs\n\nDocs\n\nDocs\n\nBlog\n\nBlog\n\nBlog\n\n95.8k\n95.8k\n95.8k\n\nGet Started\n\nGet Started\n\nGet Started\n\nRELEASE\n\nDify v1.0.0: Building a Vibrant Plugin Ecosystem\n\nDify v1.0.0 sets the foundation for a thriving, open plugin ecosystem, enabling developers and enterprises to build, scale, and innovate with ease.\n\nGRACE\n\n·\n\nFEB 17, 2025\n\nRELEASE\n\nDify v0.15.0: Introducing Parent-child Retrieval for Enhanced Knowledge\n\nDify v0.15.0 introduces Parent-child Retrieval to refine RAG by matching queries with small child chunks and enhancing context with larger parent chunks, to provide more precise and context-rich AI responses.\n\nYAWEN\n\n·\n\nDEC 26, 2024\n\nRELEASE\n\nDify v0.14.0: Boost AI Workflow Resilience with Error Handling\n\nDify’s new error management provides greater control and flexibility, enabling workflows to gracefully handle exceptions, prevent disruptions, and ensure reliable AI applications.\n\nLEILEI\n\n·\n\nDEC 16, 2024\n\nAll\nProduct\nRelease\nHow to\nDeveloper\nCompany\n\nPRODUCT\n\nDify Integrates Palo Alto Networks Plugin for Enhanced AI Application Security\n\nThe addition of the PANW AI Security plugin enriches the Dify Marketplace ecosystem and provides Dify users with a crucial layer of enterprise-grade security. \n\nLEILEI\n\n·\n\nAPR 30, 2025\n\nHOW TO\n\nLevel Up Your Dify Chatbot: Integrating InfraNodus for Advanced Q&A and Idea Generation\n\nInfraNodus analyzes knowledge graphs to generate questions from structural gaps, enhancing Dify apps for insightful Q&A and idea generation.\n\nDMITRY PARANYUSHKIN\n\n&\n\nLEILEI\n\n·\n\nAPR 17, 2025\n\nHOW TO\n\nTurn Your Dify App into an MCP Server\n\nWith the mcp-server plugin, any Dify app can be turned into an MCP-compliant server endpoint, directly accessible by external MCP clients.\n\nLEILEI\n\n·\n\nAPR 14, 2025\n\nPRODUCT\n\nDify MCP Plugin Hands-On Guide: Integrating Zapier for Effortless Agent Tool Calls\n\nIntegrate Zapier's thousands of apps into Dify AI agents using the Model Context Protocol (MCP). \n\nLEILEI\n\n·\n\nAPR 1, 2025\n\nCOMPANY\n\nMeet Dify for Education\n\nMake AI accessible and affordable to every campus worldwide.\n\nDIFY.AI\n\n·\n\nAPR 2, 2025\n\nPRODUCT\n\nDupDub Plugins Land on Dify Marketplace with Advanced Audio AI Capabilities\n\nThe DupDub AI audio plug-in is now available in the Dify Marketplace, providing voice translation, voice cloning, speaker recognition, and text-to-speech capabilities to help users build more engaging AI applications.\n\nDIFY.AI\n\n&\n\nDUPDUB\n\n·\n\nMAR 27, 2025\n\nPRODUCT\n\nEnhance Dify RAG with InfraNodus: Expand Your LLM’s Context\n\nIntegrating InfraNodus with Dify RAG enhances AI responses by providing contextual insights, improving retrieval accuracy, and enabling better handling of broad queries through topic mapping and metadata enrichment.\n\nDMITRY PARANYUSHKIN\n\n&\n\nLEILEI\n\n·\n\nMAR 26, 2025\n\nHOW TO\n\nBuilding SSH Plugin with Cursor: A Codeless Approach to Server Management\n\nThe new SSH plugin enables AI-driven server management, automating deployments, file handling, script execution, and troubleshooting via secure remote access.\n\nSTEVEN\n\n·\n\nMAR 26, 2025\n\nPRODUCT\n\nDify x Open Audio: Expand Your AI with the Fish Audio Plugin — TTS and Voice Cloning Made Easy\n\nDify integrates Fish Audio from Open Audio, enabling AI apps with text-to-speech and voice cloning. \n\nEVAN CHEN\n\n&\n\nLEILEI\n\n·\n\nMAR 26, 2025\n\nPRODUCT\n\nReal-Time Interactive Voice AI Made Simple: Agora’s Conversational AI Extension Lands on Dify Marketplace\n\nAgora’s Conversational AI Extension is now on Dify Marketplace, enabling developers to easily build real-time, low-latency voice AI agents. \n\nGRACE\n\n·\n\nMAR 24, 2025\n\nRELEASE\n\nDify v1.1.0: Filtering Knowledge Retrieval with Customized Metadata\n\nToday, we’re launching Dify v1.1.0 featuring Metadata as a Knowledge Filter, which enhances accuracy, security, and efficiency by allowing precise filtering and access control of data, crucial for effective retrieval-augmented generation (RAG) management.\n\n\nYAWEN\n\n·\n\nMAR 18, 2025\n\nCOMPANY\n\nDify.AI Showcases AI Innovation at NVIDIA GTC 2025\n\nDify will be at NVIDIA GTC 2025 from March 17th to March 21st at booth 3226 to showcase our latest innovations. \n\nDIFY.AI\n\n·\n\nMAR 13, 2025\n\nRELEASE\n\nDify Agent Node Introduction – When Workflows Learn “Autonomous Reasoning”\n\nDify's Agent Node acts like a brain within workflows, letting LLMs make decisions and handle tasks autonomously. Customizable \"Agent Strategies\" are plug-in logic modules that dictate how the LLM thinks and uses tools. This setup offers both flexibility and control.\n\nEVAN CHEN\n\n·\n\nMAR 12, 2025\n\nHOW TO\n\nBeyond Translation: An AI Workflow for High-Quality Chinese Technical Content\n\nTraditional translation struggles with technical articles, often producing unnatural \"translationese.\" This article introduces an AI-driven workflow using multi-round reviews and rewriting techniques. It uses multiple LLMs to create high-quality, accessible Chinese technical content.\n\nGINO\n\n·\n\nMAR 12, 2025\n\nRELEASE\n\nExtension Plugin Endpoint: Bringing Serverless Flexibility to Dify\n\nIntroducing Dify’s new Endpoint, which lets Extension plugins handle custom HTTP requests and leverage reverse calls for greater flexibility. It enables features like custom web interfaces, OpenAI-compatible APIs, and asynchronous event triggers, expanding what’s possible within the Dify ecosystem.\n\nYEUOLY\n\n·\n\nMAR 10, 2025\n\nHOW TO\n\nDify x Brave Search: Supercharging AI Apps with Real-Time Search\n\nLearn how to effortlessly integrate real-time search into your AI apps using the new Brave Search API plugin. Build intelligent agents, sophisticated workflows, and autonomous search capabilities—making your applications smarter and more responsive with Dify v1.0.0.\n\nLEILEI\n\n·\n\nMAR 6, 2025\n\nCOMPANY\n\nDify to Showcase at 2025 AWS Summit Japan!\n\nDify will sponsor AWS Summit Japan 2025 at Makuhari Messe, demonstrating our latest features, including plugin system, Workflow Agent Node, and seamless AWS integration. \n\nDIFY.AI\n\n·\n\nMAR 5, 2025\n\nPRODUCT\n\nDify Plugin System: Design and Implementation\n\nDify's new plugin system enhances flexibility and customization by decoupling modules, enabling independent operation and external integrations. It addresses prior limitations with features like a plugin marketplace, \"Endpoint\" plugins, reverse calls, diverse runtimes (local, SaaS, enterprise), and robust security, improving both user and developer experiences.\n\nYEUOLY\n\n·\n\nMAR 4, 2025\n\nHOW TO\n\nDeepResearch: Building a Research Automation App with Dify \n\nDeepResearch automates multi-step searches and summarizes findings using LLMs. Built within Dify, \"DeepResearch\" uses nodes for iteration, search, and summarization, creating a workflow for efficient information gathering and report generation, saving time and effort.\n\nTAKASHI KISHIDA\n\n·\n\nFEB 19, 2025\n\nHOW TO\n\nBuilding a Multilingual Document Translation Tool with  Dify\n\nThis article will leverage DeepSeek R1, combined with Dify, an open-source low-code development platform, to demonstrate how to quickly build an enterprise-level multilingual document translation tool. \n\nSTEVEN\n\n·\n\nFEB 13, 2025\n\nHOW TO\n\nAdding MultiModal Capabilities to Deepseek R1 using Dify\n\nOn Dify, you can quickly build a bidirectional collaborative system based on DeepSeek R1 and multi-modal models through visual workflow design.\n\nSTEVEN\n\n·\n\nFEB 8, 2025\n\nHOW TO\n\nDeepSeek API Issues? Dify Keeps Your R1 Apps Running\n\nDify provides robust access to DeepSeek-R1, even with API instability. Integrate via the official API, multiple MaaS options, or local deployment for reliable, flexible LLM application development and consistent performance.\n\nLEILEI\n\n·\n\nFEB 7, 2025\n\nHOW TO\n\nDify x DeepSeek: Deploy a Private AI Assistant & Build a Local DeepSeek R1 + Web Search App\n\nIn this guide, we’ll show you how to deploy a private AI assistant using Dify and DeepSeek, and build a local DeepSeek R1 + Web Search AI app on your own infrastructure.\n\nALLEN\n\n·\n\nFEB 6, 2025\n\nHOW TO\n\nDify work with Microsoft AI Search\n\nDify’s custom tool makes it easy to add Azure’s fast, AI-driven search via REST API.\n\nXINYU WEI\n\n·\n\nJAN 22, 2025\n\nCOMPANY\n\nDify Official Statement: Clarification Regarding Recent Misinformation\n\nWe have detected impersonators engaging in illegal activities unrelated to us; please rely on official channels and stay vigilant.\n\nDIFY.AI\n\n·\n\nJAN 21, 2025\n\nRELEASE\n\nIntroducing Dify Plugins\n\nWe're excited to announce the beta release of Dify Plugins - modular components that seamlessly extend your AI applications.\n\nGRACE\n\n·\n\nJAN 9, 2025\n\nRELEASE\n\nBuilding a Twitter MBTI Analyzer: A No-Code Journey with Dify and Windsurf\n\nThis article explores how to build an AI-powered product, “Twitter MBTI Receipt,” using Dify and Windsurf to analyze Twitter profiles and generate MBTI personality reports.\n\nSTEVEN\n\n·\n\nDEC 10, 2024\n\nHOW TO\n\nEnhancing GPT-Researcher with Parallel and Advanced Iterative Features\n\nBy automating research tasks through problem decomposition, parallel processing, and error handling, we can create faster, more reliable, and structured research reports. \n\nEVAN CHEN\n\n·\n\nNOV 5, 2024\n\nCOMPANY\n\nDify.AI x TechCrunch Disrupt 2024 Recap\n\nWe were selected for TechCrunch Disrupt 2024's Startup Battlefield 200 in SF. Our team showcased our enterprise AI development platform for three days, presented on the Builder Stage, and engaged with global developers to share our vision of simplifying LLM integration.\n\nDIFY.AI\n\n·\n\nNOV 1, 2024\n\nCOMPANY\n\nHow Dify.AI powers the company that's powering the world\n\nA leading consumer electronics company leverages Dify.AI to bridge technical and non-technical teams, streamlining AI integration. With Dify.AI, employees across all levels can create AI applications, boosting efficiency, enhancing customer insights, and driving real-world impact.\n\nGU\n\n·\n\nOCT 29, 2024\n\nRELEASE\n\nIntroducing Workflow File Upload: Google NotebookLM Podcast Demo\n\nWe’re launching the file upload feature today, with a demo on using it in an AI podcast application.\n\nLEILEI\n\n&\n\nEVAN CHEN\n\n·\n\nOCT 21, 2024\n\nHOW TO\n\nCross-Platform Copywriting with Dify\n\nIn Dify, not all nodes have a low entry threshold. Some nodes may be overlooked during the process of orchestrating flows, but combining them will unlock more possibilities for Dify in complex tasks. This blog will use the scenario of Cross-Platform Copywriting to demonstrate how to use template conversion nodes for type conversion, write session variables during iterations, accelerate flow processing in parallel, optimize streaming output experiences with multiple answer nodes, and explore more uses of code nodes.\n\nEVAN CHEN\n\n&\n\nLYSON\n\n·\n\nSEP 14, 2024\n\nHOW TO\n\nHow to configure and use OpenAI o1 models in Dify.AI? \n\nOpenAI launches the o1 series models, excelling in complex reasoning. Dify.AI enables seamless integration of these models within an hour, offering developers efficient solutions. Check our documentation for detailed integration steps.\n\n·\n\nSEP 13, 2024\n\nRELEASE\n\nDify v0.8.0: Accelerating Workflow Processing with Parallel Branch\n\nWe’ve enhanced Workflow with parallel processing capabilities in Dify v0.8.0. It can now run multiple branches simultaneously, enabling the parallel execution of various tasks. This new model significantly improves execution efficiency, helping LLM applications handle complex tasks more quickly and flexibly.\n\nLEILEI\n\n·\n\nSEP 10, 2024\n\nCOMPANY\n\nDify.AI Selected for Startup Battlefield 200 at TechCrunch Disrupt 2024\n\nWe’re thrilled to share that Dify.AI has been selected to showcase at TechCrunch Disrupt 2024 as part of the Startup Battlefield 200, a preeminent competition for startups worldwide.\n\nDIFY.AI\n\n·\n\nSEP 6, 2024\n\nCOMPANY\n\nPartners with Takin.ai to Deliver Easier GenAI Education\n\nWe're excited to welcome Takin.ai, an innovative GenAI education startup, to be our education partner.\n\nDIFY.AI\n\n·\n\nAUG 20, 2024\n\nHOW TO\n\nDify Conversation Variables: Building a Simplified OpenAI Memory\n\nConversation Variables are short-term memory units employed by Dify to provide temporary storage in multi-turn conversations within chatflows. These variables enable us to retain important details between chat interactions, resulting in more contextually relevant responses. In the following section, I will demonstrate how to utilize Conversation Variables to emulate OpenAI's Memory Features.\n\nEVAN CHEN\n\n·\n\nAUG 16, 2024\n\nRELEASE\n\nDify v0.7.0: Enhancing LLM Memory with Conversation Variables and Variable Assigners\n\nDify v0.7.0 tackles LLM memory limitations with Conversation Variables and Variable Assigner nodes. These features give Chatflow-built apps precise memory control, boosting LLMs' ability to handle complex scenarios in production.\n\nLEILEI\n\n·\n\nAUG 14, 2024\n\nRELEASE\n\nPhasing Out N-to-1: Upgrading Multi-path Knowledge Retrieval\n\nWe're phasing out the N-to-1 retrieval strategy on September 1, 2024, and introducing a more flexible Multi-path retrieval strategy. We recommend switching to this new approach to boost your application's retrieval efficiency.\n\nPAN\n\n&\n\nLEILEI\n\n·\n\nAUG 1, 2024\n\nRELEASE\n\nDifySandbox Goes Open Source: Secure Execution of Code\n\nToday, we're proud to announce that we've made DifySandbox open source for greater code transparency.\n\nLEILEI\n\n·\n\nJUL 10, 2024\n\nPRODUCT\n\nIntroduction to DifySandbox\n\nThis blog thoroughly outlines the rationale, design principles, and implementation mechanisms that guided the development of DifySandbox.\n\nYEUOLY\n\n·\n\nJUL 10, 2024\n\nRELEASE\n\nEnhance LLM Application observability on Dify with LangSmith and Langfuse\n\nWith simple configuration, you can now access detailed application data, making it easier to evaluate the cost, latency, and quality of LLM applications created on Dify. \n\nLEILEI\n\n·\n\nJUL 2, 2024\n\nRELEASE\n\nDify.AI x Firecrawl: A Top-Notch Solution for Web Data Knowledge Base\n\nDify v0.6.11 has just been released! We've integrated Firecrawl as our web data source solution, which greatly enhances the knowledge base of Dify. \n\nLEILEI\n\n·\n\nJUN 17, 2024\n\nPRODUCT\n\nDify vs. LangChain\n\nCompare Dify.AI and LangChain for enterprise AI application development. Learn about their scalability, flexibility, and efficiency to choose the best platform for your needs. \n\n·\n\nJUN 5, 2024\n\nRELEASE\n\nWorkflow Major Update: Iteration, Parameter Extractor and Publish Workflow as a Tool\n\nSince launching workflow v0.6.0, it has been popular among our users, with over 90% needing it for AI applications in business scenarios. Dify v0.6.9 introduces publishing workflows as tools, iteration nodes, parameter extractors, and enhanced node capabilities. We also offer a showcase to demonstrate their use, automating batch processing of your emails.\n\nXIAOYI\n\n·\n\nMAY 31, 2024\n\nRELEASE\n\nIntroducing Dify Workflow\n\nWe’re thrilled to launch our new feature: AI Workflow. It enables predictable outputs with multi-step logic through an intuitive, drag-and-drop interface.\n\nGU\n\n·\n\nAPR 8, 2024\n\nRELEASE\n\nDify.AI is now available on the AWS Marketplace\n\nPerfect for small teams & service providers needing custom branding & flexible deployment.\n\nGU\n\n·\n\nMAR 12, 2024\n\nDEVELOPER\n\nHow to run open source model Gemma on Dify? \n\nExplore how to leverage Google's Gemma, an open-source LLM, for integration with Dify. Discover tips for enhancing AI applications responsibly. \n\nXIAOYI\n\n·\n\nFEB 22, 2024\n\nHOW TO\n\nYour Guide to Building an AI Travel Consultant \n\nEver wondered how to leverage the latest AI technology for travel planning? This comprehensive guide on Dify.AI showcases how to build an AI travel consultant, making your trip planning effortless and efficient.\n\nXIAOYI\n\n·\n\nFEB 4, 2024\n\nHOW TO\n\nUnleashing AI in Finance: Building an AI Investment Analysis Assistant with Dify\n\nDiscover the step-by-step guide on constructing a sophisticated AI investment analysis assistant with Dify. Master the art of integrating AI into your financial analysis for smarter, data-driven decisions.\n\nXIAOYI\n\n·\n\nJAN 26, 2024\n\nRELEASE\n\nDify.AI Unveils AI Agent: Creating GPTs and Assistants with Various LLMs\n\nWith Dify, you can create an AI Agent using any LLMs. Simply use instructions and combine various tools with additional knowledge bases to create a custom Assistant that's just right for you.\n\nPAN\n\n·\n\nJAN 24, 2024\n\nRELEASE\n\nDify Rolls Out New Architecture, Enhancing Flexibility and Scalability\n\nWe've totally revamped Dify's core architecture, moving to a more modular approach. Our latest Beehive architecture allows each module to stand on its own, enabling developers to adjust parts without affecting the overall structure.\n\nLEVI TIAN\n\n·\n\nJAN 10, 2024\n\nRELEASE\n\nDify.AI v0.4.1 Release: The Model Runtime Restructure\n\nWe're rolling out a brand new Model Runtime architecture, replacing the pre-existing model interface built on LangChain.\n\nGU\n\n·\n\nJAN 3, 2024\n\nHOW TO\n\nBoosting Chatbot Quality & Cutting Costs with Dify.AI's Annotation Reply\n\nThis article introduces how to use Dify.AI's Annotation Reply feature to improve Chatbot reply quality and Reduce LLM token Costs. \n\n·\n\nDEC 26, 2023\n\nRELEASE\n\nDify.AI Update v0.3.34 \n\nDify.AI‘s v0.3.34 introduces features such as Annotation Reply, providing enhanced Q&A capabilities and more.\n\nLEILEI\n\n·\n\nDEC 20, 2023\n\nCOMPANY\n\nDify.AI x Jina AI：Dify now Integrates Jina Embedding Model\n\nJina AI's jina-embeddings-v2, with a unique 8,192 token context, enhances RAG applications in Dify.AI's platform. It outperforms standard 512-token models, enabling richer, context-aware AI solutions and simplified development.\n\nDIFY.AI\n\n&\n\nJINA\n\n·\n\nDEC 5, 2023\n\nDEVELOPER\n\nDify.AI: Open-source Assistants API based on any LLM\n\nOpenAI's Assistants API marks a shift in application engineering towards advanced AI use, emphasizing orchestration services. Dify, an open-source leader in this field, offers self-hosting for data security, multi-model support, and a flexible RAG engine. It enables privacy, compliance, customizable data processing, and team collaboration, enhancing AI application development and integration.\n\nDIFY.AI\n\n·\n\nNOV 25, 2023\n\nRELEASE\n\nDify.AI v0.3.31: Surpassing the Assistants API – Dify's RAG Demonstrates an Impressive 20% Improvement\n\nDify.AI's latest update enhances its RAG technology, boosting QA efficiency in LLMs. It introduces hybrid search, a semantic rerank model, and multi-path retrieval, demonstrating significant performance improvements and a notable edge over OpenAI's Assistants API.\n\nLEILEI\n\n·\n\nNOV 21, 2023\n\nDEVELOPER\n\nIntroducing Hybrid Search and Rerank to Improve the Retrieval Accuracy of the RAG System\n\nThis article discusses enhancing RAG systems with Hybrid Search and Rerank technologies, focusing on improving retrieval accuracy and efficiency using LLMs for more comprehensive and precise search results.\n\nVINCE\n\n·\n\nNOV 21, 2023\n\nRELEASE\n\nDify.AI v0.3.30 is here! Explore the Exciting GPT4-Vision Multimodal Model\n\nThis update officially supports the multimodal capabilities of the GPT4-Vision model, integrating images into conversations to create a unique interactive experience, making conversations more engaging.\n\nDIFY.AI\n\n·\n\nNOV 13, 2023\n\nRELEASE\n\nDify.AI v0.3.29: Support for GPT-4 Turbo & Vision - The Gateway to Multimodal Interactions\n\nv0.3.29 Feature Highlights:\n- GPT-4 Turbo & Vision model support\n- External data API tools\n- Moderation for sensitive content\n\nDIFY.AI\n\n·\n\nNOV 8, 2023\n\nRELEASE\n\nFrom Basic to Expert: Mastering the New Prompt Orchestration in Dify.AI\n\nDify.AI introduces a new \"Expert Mode\" in its prompt orchestration page, offering advanced customization and control for professional developers and prompt engineers over prompt orchestration. While \"Basic Mode\" simplifies application creation, \"Expert Mode\" provides a wide range of tools and options for designing complex prompt orchestrations, enabling users to fine-tune AI applications for optimal performance. It includes features like customized prompts, different models (CHAT and COMPLETE) for various requirements, and a 'Log View' feature for debugging.\n\nDIFY.AI\n\n·\n\nOCT 23, 2023\n\nRELEASE\n\nDify.AI's New Dataset Feature Enhancements\n\nThe recent updates to Dify.AI's dataset management tools introduce a \"Citations and Attributions\" feature for easier documentation referencing, and a new Dataset API for efficient data management. Support for multiple file formats and document segmentation enhances data handling. Additionally, integration with GPT-3.5-turbo-instruct and various Hugging Face embedding models provides users with more model options for specific applications, improving overall user experience.\n\nDIFY.AI\n\n·\n\nOCT 12, 2023\n\nRELEASE\n\nDify.AI v0.3.13 Release: Effortlessly Leverage Top Open-Source LLMs like Llama2 and ChatGLM\n\nDify now supports popular open-sourced large language models like Llama2 and Qwen. Users can easily access these cutting-edge models by entering API keys on Dify, and build high-performance AI applications within minutes. Dify opens the gateway to the latest innovations in natural language processing. Try out top-notch models like Llama2 for free on Dify today, and unleash their power to enhance your AI solutions.\n\nDIFY.AI\n\n·\n\nAUG 15, 2023\n\nDEVELOPER\n\nText Embedding: Basic Concepts and Implementation Principles\n\nEmbedding is a vital technique in AI applications, representing concepts as numerical sequences to enable better comprehension of relationships.\n\nVINCE\n\n·\n\nAUG 1, 2023\n\nRELEASE\n\nMajor Update: AI Online Search Capability Now Available, Significantly Enhancing Dataset Hit Rate!\n\nDify.AI V0.3.12 introduces improved data retrieval with Q2Q matching and 'Chat' capability for online interactions with AI. Chat supports web browsing, Google search, and Wikipedia queries, enhancing productivity. Join our collaborative exploration of large model capabilities.\n\nDIFY.AI\n\n·\n\nAUG 1, 2023\n\nRELEASE\n\nDify.AI Integrates Claude2 Model: Supports 100K Token Context, Get 1000 Free Message Credits upon Sign-up\n\nDify V0.3.9 Release: Integration of Antropic's Claude2 and Claude-instant models, supporting ultra-long conversations with up to 100K tokens. Now, you can embed AI applications on your web pages, swiftly creating personalized AI customer support for your official website. Additional features include bulk result exporting for text-based applications and the community version supporting member invitations through invitation links. Moreover, the Service API now includes conversation deletion functionality. Experience the superpowers of Dify today!\n\nDIFY.AI\n\n·\n\nJUL 17, 2023\n\nCOMPANY\n\nDify.AI: 46,558 Lines of Code, Fully Open Source\n\nSince the official launch of the Cloud version on May 9th, Dify.AI has been well-received and widely shared by developers. In less than a week, over 4,000 applications have been created, and even before we went open source, our GitHub Star count had exceeded 700+. This makes us deeply feel the power of the community! At the same time, we are extremely honored and excited that Dify can bring such powerful creativity to developers.\n\nDIFY.AI\n\n·\n\nMAY 15, 2023\n\nRELEASE\n\nDify.AI: Easy-to-Use LLMOps Platform for Visually Creating and Operating Your AI Native Applications\n\nWith the emergence of various capabilities of large language models (LLMs), the scenarios for AI applications have become much broader. However, for most developers, developing AI applications based on large language models such as GPT and technology frameworks like Langchain is still a challenging task. Developers must spend a lot of time learning various obscure concepts and technical research, and they cannot carry out continuous operations of AI applications.\n\nDIFY.AI\n\n·\n\nMAY 10, 2023\n\nRELEASE\n\nBuilding Effective GPT-based Applications: A Step-by-Step Guide\n\nDevelopers utilizing OpenAI's GPT API may often find that the AI doesn't produce the desired output or seems \"uncooperative.\" To address these challenges and improve GPT's performance, there are three crucial steps to follow：\n\nDIFY.AI\n\n·\n\nAPR 12, 2023\n\nHOW TO\n\nWhat is Ops in LLMOps?\n\nLLMOps is a specialized area within the broader MLOps landscape, focusing on the deployment, management, and improvement of AI applications built on top of Large Language Models (LLMs) like GPT-4. In this article, we will explore the concept of \"Ops\" in LLMOps and how Dify caters to this space.\n\nDIFY.AI\n\n·\n\nAPR 11, 2023\n\nDEVELOPER\n\nIntroducing Dify WebApp: Unlocking AI-Native Applications with Ease\n\nAt Dify, we are dedicated to providing our users with seamless and flexible solutions for creating and deploying AI-native applications. We understand the importance of a user-friendly and open platform to foster innovation, and that's where Dify WebApp and Dify WebApp Template come into play.\n\n\nDIFY.AI\n\n·\n\nAPR 10, 2023\n\nCOMPANY\n\nWhy Did We Create Dify?\n\nAt Dify, we are passionate about making AI technology more accessible and user-friendly. As we began our journey, we identified several key challenges that developers and users face when working with AI-native applications, especially with the advanced large language models provided by OpenAI. In this blog post, we will discuss the reasons behind the creation of Dify and our mission to simplify the AI development process.\n\nDIFY.AI\n\n·\n\nAPR 9, 2023\n\nPRODUCT\n\nUnleashing the Power of LLM Embeddings with Datasets: Revolutionizing MLOps\n\nThe combination of LLM embeddings and datasets has dramatically transformed the MLOps landscape, unlocking new capabilities and driving innovation in AI applications. Dify's dataset functionality simplifies the process of integrating proprietary data with LLMs, empowering developers to build more intelligent, domain-specific AI solutions. As LLMs continue to evolve, we can expect even more exciting possibilities and advancements in the world of AI and MLOps.\n\nDIFY.AI\n\n·\n\nAPR 12, 2022\n\nHOW TO\n\nDeveloping a ChatGPT Plugin: A Comprehensive Guide\n\nChatGPT plugins provide a powerful way to extend the capabilities of AI clients by integrating additional functionalities through APIs. In this blog post, we'll guide you through the process of creating a ChatGPT plugin and discuss some potential business use cases. Finally, we'll touch upon how Dify supports the integration of both in-house and third-party plugins for seamless AI application orchestration.\n\nDIFY.AI\n\n·\n\nMAR 15, 2022\n\nThe Innovation Engine for Generative AI Applications\n\nGet Started\n\nGet Started\n\nGet Started\n\nGitHub\n\nGitHub\n\nGitHub\n\nDify.ai\n\nDify.AI aims to become a leading \n\ngenerative AI application development platform.\n\nEN\n中文\n日本語\n© 2025 LangGenius, Inc.\n\nProducts\n\nLLM Agent\n\nAI Workflow\n\nPrompt IDE\n\nRAG Pipeline\n\nEnterprise LLMOps\n\nResource\n\nMarketplace\n\nDocs\n\nBlog\n\nEducation\n\nSupport\n\nFeedback\n\nRoadmap\n\nCompany\n\nTalk to Us\n\nTerms of Service\n\nPrivacy Policy\n\nCookie Settings\n\nSecurity\n\nSOC2 Type I &  Type II Certified\nISO 27001:2022 Certified\n\nData Protection Agreement",
        "error": null
      },
      {
        "link_index": 3,
        "link_text": "Dify.AI",
        "target_url": "https://cloud.dify.ai",
        "extract_target": "body",
        "extracted_data": "",
        "error": null
      },
      {
        "link_index": 4,
        "link_text": "ドキュメント",
        "target_url": "https://docs.dify.ai/ja-jp/introduction",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nDifyエンタプライス版へようこそ\n特徴と技術仕様\nモデルプロバイダーリスト\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nDifyへようこそ\nDifyエンタプライス版へようこそ\nCopy page\n\nDify エンタープライズ版は、大規模な組織やチーム向けのプライベートデプロイメントAIミドルウェアソリューションであり、企業内でのAI+時代への移行を促進することを目的としています。\n\nDify はノーコード設計理念を採用しており、ビジネス担当者が深いプログラミング知識を必要とせずに直接AIアプリケーションを構築およびデプロイできるようにします。 エンタープライズ版サービスには強力な管理バックエンドが装備されており、詳細な権限管理とワークスペース管理をサポートし、チームの協力効率とデータセキュリティを確保します。また、包括的なデータ監視サービスも提供しており、管理人がAIアプリケーションのパフォーマンスとデータ使用状況をリアルタイムで把握し、意思決定のためのデータサポートを提供します。\n\nプライベートデプロイメントオプションと企業レベルのセキュリティ標準に準拠した設計により、Dify エンタープライズ版はデータセキュリティを確保しながら、組織に安定した信頼性のある拡張可能なAIインフラストラクチャを提供し、AI時代において競争優位性を維持するのに役立ちます。\n\n​\n製品の利点\n\n私たちの企業向けソリューションには以下の利点があります：\n\n高度なチーム管理: 企業のDifyプラットフォーム内の「ワークスペース」と「チームメンバー」を柔軟に管理し、管理人はアクセス権とチーム構造を簡単に制御できます。\n企業レベルのアクセスセキュリティ: 企業内のSSO（シングルサインオン）システムと統合し、安全で信頼性のある認証を確保し、潜在的なデータリスクを回避します。\nブランド変更が可能です：製品のロゴやブランド情報を自由に変更し、あなた専用のプラットフォームとして利用できます。\n複数テナントの作成が可能です：複数のワークスペースを作成・所有でき、異なる部署やアクショングループのニーズを効果的にサポートします。\nモデルの負荷分散機能を提供します：適切なモデルに対して負荷分散を行い、モデルのQPS制限を超えて、より広範囲なシーンにサービスを提供します。\n​\n適用シナリオ\n高データセキュリティ要件: 金融、医療部門など、データセキュリティに非常に高い要件を持つ業界や企業向け。Dify エンタープライズ版は以下を提供します：\nエンドツーエンドの暗号化伝送\n厳格なデータアクセス制御\nローカルデプロイメントオプション、機密データが企業内ネットワークを離れないことを確保\n大規模なAIアプリケーションのデプロイメントと管理: 企業内で大規模にAIアプリケーションをデプロイおよび管理する必要がある組織向け。\n中央集権的なAI資産管理、モデル、データセット、アプリケーションを含む。管理人は企業内の複数のAIアプリケーションの運用状況を簡単に確認および監視できます。\nモデルニュートラル、管理人がオープンソース/クローズドソースのAI大規模モデルを自分で接続し、ビジネスシナリオに迅速に適用できる\n使いやすく、ビジネス担当者が迅速に製品プロトタイプの開発とテストを行うことをサポート\n権限管理システム、リソース共有を確保しながら機密情報を保護\n広範なAI能力統合シナリオ: AI能力を既存のビジネスプロセスやシステムにシームレスに統合する必要がある企業向け。\n豊富なAPIポートを提供し、企業システムとの統合をサポート\nカスタムワークフローエンジン、複雑なビジネスロジックを実現\n多言語サポート、国際化ニーズを満たす\n高並列性、高可用性の要件: システムの安定性とパフォーマンスに高い要求がある大規模企業やインターネット企業向け。\n分散アーキテクチャ、水平スケーリングをサポート\n負荷分散とフェイルオーバーメカニズム、サービスの高可用性を確保\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\n特徴と技術仕様\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\n製品の利点\n適用シナリオ",
        "error": null
      },
      {
        "link_index": 5,
        "link_text": "用語ベース",
        "target_url": "https://docs.dify.ai/ja-jp/termbase/termbase",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n用語集\n用語集\nCopy page\n​\nA\n​\nエージェント (Agent)\n\n環境情報に基づいて意思決定やタスク実行ができる自律型AIシステムです。Difyプラットフォームでは、エージェントは大規模言語モデルの理解能力と外部ツールとの対話能力を組み合わせ、情報検索、API呼び出し、コンテンツ生成など、単純なものから複雑なものまでの一連の操作を自動的に完了します。\n\n​\nエージェンティックワークフロー (Agentic Workflow)\n\nAIシステムが複数のステップを通じて自律的に複雑な問題を解決できるタスク編成方法です。例えば、エージェンティックワークフローは、まずユーザーの質問を理解し、次に知識ベースを照会し、計算ツールを呼び出し、最後に情報を統合して完全な回答を生成します。これらはすべて人間の介入なしに行われます。\n\n​\n自動音声認識 (ASR, Automatic Speech Recognition)\n\n人間の音声をテキストに変換する技術で、音声対話アプリケーションの基盤となります。この技術により、ユーザーはタイピングではなく話すことでAIシステムと対話でき、音声アシスタント、会議の文字起こし、アクセシビリティサービスなどのシナリオで広く使用されています。\n\n​\nB\n​\n思考の骨格 (BoT, Backbone of Thought)\n\n大規模言語モデルの推論に主要な構造を提供する構造化された思考フレームワークです。学術論文の概要や決定木の骨格のように、複雑な問題に対処する際にモデルが明確な思考経路を維持するのに役立ちます。\n\n​\nC\n​\nチャンキング (Chunking)\n\n長いテキストを小さなコンテンツブロックに分割する処理技術で、検索システムがより正確に関連情報を見つけることを可能にします。優れたチャンキング戦略は、コンテンツの意味的整合性と言語モデルのコンテキストウィンドウの制限の両方を考慮し、検索と生成の品質を向上させます。\n\n​\n引用と帰属 (Citation and Attribution)\n\nAIシステムが情報源を明確に示すことができる機能で、レスポンスの信頼性と透明性を高めます。システムが知識ベースのコンテンツに基づいて回答を生成する場合、参照されたドキュメント名、ページ番号、URLを自動的に注釈し、ユーザーが情報の出所を理解できるようにします。\n\n​\n思考の連鎖 (CoT, Chain of Thought)\n\n大規模言語モデルがステップバイステップの思考プロセスを表示するように導くプロンプト技術です。例えば、数学の問題を解く場合、モデルははじめに既知の条件をリストアップし、次に推論ステップに従って一つずつ解き、最後に結論に到達します。このプロセス全体が人間の思考に似ています。\n\n​\nD\n​\nドメイン固有言語 (DSL, Domain-Specific Language)\n\n特定のアプリケーションドメイン用に設計されたプログラミング言語または構成形式です。Dify DSLは、YAML形式に基づくアプリケーションエンジニアリングファイル標準で、モデルパラメータ、プロンプト設計、ワークフロー編成など、AIアプリケーションのさまざまな構成を定義するために使用され、非専門的な開発者でも複雑なAIアプリケーションを構築できるようにします。\n\n​\nE\n​\n抽出・変換・読み込み (ETL, Extract, Transform, Load)\n\nデータ処理の古典的なワークフロー：生データを抽出し、分析に適した形式に変換し、ターゲットシステムに読み込みます。AIドキュメント処理では、ETLはPDFからのテキスト抽出、フォーマットのクリーニング、コンテンツの分割、埋め込みベクトルの計算、最終的にベクトルデータベースへの読み込みを含む場合があり、RAGシステムの準備を整えます。\n\n​\nF\n​\n頻度ペナルティ (Frequency Penalty)\n\n頻繁に出現する語彙の生成確率を下げることで出力の多様性を高めるテキスト生成制御パラメータです。値が高いほど、モデルは多様な語彙と表現を使用する傾向があります。値が0の場合、モデルは同じ語彙を再利用することを特に避けません。\n\n​\n関数呼び出し (Function Calling)\n\n大規模言語モデルが特定の関数をいつ呼び出す必要があるかを認識し、必要なパラメータを提供する能力です。例えば、ユーザーが天気について尋ねると、モデルは自動的に天気APIを呼び出し、正しいパラメータ形式（都市、日付）を構築し、APIの返す結果に基づいて応答を生成することができます。\n\n​\nG\n​\n一般的なチャンキングパターン (General Chunking Pattern)\n\n文書を相互に独立したコンテンツブロックに分割するシンプルなテキスト分割戦略です。このパターンは、製品マニュアルや百科事典のエントリなど、構造が明確で段落が比較的独立している文書に適しており、各チャンクはコンテキストに大きく依存することなく独立して理解できます。\n\n​\n思考のグラフ (GoT, Graph of Thought)\n\n思考プロセスをネットワーク構造として表現し、概念間の複雑な関係を捉える方法です。線形の思考の連鎖とは異なり、思考のグラフは分岐、循環、複数経路の思考パターンを表現でき、複数の相互関連する要因を持つ複雑な問題の処理に適しています。\n\n​\nH\n​\nハイブリッド検索 (Hybrid Search)\n\nキーワードマッチングと意味検索の利点を組み合わせ、より包括的な検索結果を提供する検索方法です。例えば、「リンゴの栄養成分」を検索する場合、ハイブリッド検索は「リンゴ」と「栄養」のキーワードを含む文書だけでなく、「果物の健康価値」などの関連する意味概念を議論するコンテンツも見つけることができ、重み付け調整または再ランク付けを通じて最適な結果を選択します。\n\n​\nI\n​\n転置インデックス (Inverted Index)\n\n各単語がどの文書に出現するかを記録する検索エンジンのコアデータ構造です。文書からコンテンツを見つける従来のインデックスとは異なり、転置インデックスは語彙から文書を見つけ、全文検索速度を大幅に向上させます。例えば、「人工知能」という用語のインデックスエントリは、この用語を含むすべての文書IDと位置をリストアップします。\n\n​\nK\n​\nキーワード検索 (Keyword Search)\n\n特定の語彙を含む文書を見つける正確なマッチングに基づく検索方法です。この方法は計算効率が高く、製品モデル、固有名詞、特定のコマンドなど、ユーザーが見つけたい用語を明確に知っているシナリオに適していますが、同義語や関連する概念を使用して表現されたコンテンツを見逃す可能性があります。\n\n​\n知識ベース (Knowledge Base)\n\nAIアプリケーションで構造化された情報を保存し、モデルに専門知識の源を提供するデータベースです。Difyプラットフォームでは、知識ベースはさまざまな文書（PDF、Word、ウェブページなど）を含むことができ、処理されてAI検索に使用され、正確で根拠のある回答を生成するために使用されます。特にドメインエキスパートアプリケーションの構築に適しています。\n\n​\n知識検索 (Knowledge Retrieval)\n\nユーザーの質問に最も関連する情報を知識ベースから見つけるプロセスであり、RAGシステムの重要な構成要素です。効果的な知識検索は、関連するコンテンツを見つけるだけでなく、返される情報量を制御し、モデルを妨げる可能性のある無関係なコンテンツを避けながら、正確で完全な回答を確保するのに十分な背景を提供します。\n\n​\nL\n​\n大規模言語モデル (LLM, Large Language Model)\n\n大量のテキストで訓練され、人間の言語を理解し生成できるAIモデルです。現代のLLM（GPTシリーズ、Claudeなど）は、記事の作成、質問への回答、コードの作成、さらには推論も行うことができます。これらは様々なAIアプリケーションのコアエンジンであり、特に言語理解と生成を必要とするシナリオに適しています。\n\n​\nローカルモデル推論 (Local Model Inference)\n\nクラウドサービスに依存せずに、ユーザー自身のデバイス上でAIモデルを実行するプロセスです。このアプローチは、より良いプライバシー保護（データがローカル環境を離れない）と低いレイテンシー（ネットワーク転送不要）を提供し、機密データの処理やオフライン作業を必要とするシナリオに適していますが、通常はローカルデバイスの計算能力によって制限されます。\n\n​\nM\n​\nサービスとしてのモデル (MaaS, Model-as-a-Service)\n\nプロバイダーがAPIを通じて事前トレーニング済みモデルへのアクセスを提供するクラウドサービスモデルです。ユーザーはモデルのトレーニング、デプロイ、または保守について心配する必要はなく、単にAPIを呼び出して使用料を支払うだけで、AIアプリケーションの開発閾値とインフラコストを大幅に下げます。アイデアの迅速な検証やプロトタイプの構築に適しています。\n\n​\n最大トークン数 (Max_tokens)\n\nモデルが単一の応答で生成する最大文字数を制御するパラメータです。1つのトークンは約4文字または英単語の3/4に相当します。適切な最大トークン数を設定することで、回答の長さを制御し、過度に冗長な出力を避け、必要な情報の完全な表現を確保できます。例えば、簡単な要約は200トークンに設定される場合がありますが、詳細なレポートでは2000トークンが必要になる場合があります。\n\n​\nメモリ (Memory)\n\nAIシステムが過去のインタラクション情報を保存して使用し、複数ターンの会話を一貫して保つ能力です。効果的なメモリメカニズムにより、AIはコンテキスト参照を理解し、ユーザーの好みを記憶し、長期的な目標を追跡できるようになり、これによりパーソナライズされた継続的なユーザーエクスペリエンスを提供し、すでに提供された情報を繰り返し尋ねることを避けます。\n\n​\nメタデータフィルタリング (Metadata Filtering)\n\nドキュメント属性情報（タイトル、作者、日付、分類タグなど）を利用してコンテンツをフィルタリングする技術です。例えば、ユーザーは特定の日付範囲内の技術文書に検索を制限したり、特定の部署のレポートのみを照会したりして、検索前に範囲を絞り込み、検索効率と結果の関連性を向上させることができます。\n\n​\nマルチモーダルモデル (Multimodal Model)\n\nテキスト、画像、音声などの複数種類の入力データを処理できるモデルです。これらのモデルは従来のAIの単一知覚限界を打破し、画像内容の理解、ビデオシーンの分析、音声感情の認識が可能で、より包括的な情報理解の可能性を創出し、クロスメディア理解を必要とする複雑なアプリケーションシナリオに適しています。\n\n​\nマルチツール呼び出し (Multi-tool-call)\n\nモデルが単一のレスポンスで複数の異なるツールを呼び出す能力です。例えば、「北京と上海の明日の天気を比較し、適切な服装を推奨する」というリクエストを処理する場合、モデルは両都市の天気APIを同時に呼び出し、返された結果に基づいて合理的な提案を提供し、複雑なタスクを処理する効率を向上させます。\n\n​\nマルチパス検索 (Multi-path Retrieval)\n\n複数の検索方法を通じて並行して情報を取得する戦略です。例えば、システムはキーワード検索、セマンティックマッチング、知識グラフクエリを同時に使用し、結果をマージしてフィルタリングすることで、情報検索のカバレッジと精度を向上させ、特に複雑または曖昧なユーザークエリの処理に適しています。\n\n​\nP\n​\n親子チャンキング (Parent-Child Chunking)\n\n2レベルのコンテンツブロックを作成する高度なテキスト分割戦略：親ブロックは完全なコンテキストを保持し、子ブロックは正確なマッチングポイントを提供します。システムはまず子ブロックを使用して関連コンテンツの位置を特定し、次に対応する親ブロックを取得して完全な背景を提供し、検索精度とコンテキストの完全性のバランスを取り、研究論文や技術マニュアルなどの複雑な文書の処理に適しています。\n\n​\n存在ペナルティ (Presence Penalty)\n\n言語モデルがコンテンツを繰り返すことを防ぐパラメータ設定です。すでに出現した語彙の生成確率を下げることにより、モデルが新しい表現を探索することを奨励します。パラメータ値が高いほど、モデルが以前に生成したコンテンツを繰り返す可能性が低くなり、AI応答でよく見られる循環的な議論や問題の繰り返し説明を避けるのに役立ちます。\n\n​\n事前定義モデル (Predefined Model)\n\nAIベンダーによってトレーニングされ提供される既製モデルで、ユーザーは自分でトレーニングすることなく直接呼び出すことができます。これらのクローズドソースモデル（GPT-4、Claudeなど）は通常、大規模にトレーニングおよび最適化され、強力で使いやすく、迅速なアプリケーション開発や独立したトレーニングリソースを欠くチームに適しています。\n\n​\nプロンプト (Prompt)\n\nAIモデルに特定の応答を生成するよう導く入力テキストです。よく設計されたプロンプトは出力品質を大幅に向上させ、明確な指示、例の提供、フォーマット要件の設定などの要素を含みます。例えば、異なるプロンプトは同じモデルに学術記事、創造的なストーリー、または技術分析を生成するよう導くことができ、AI出力に影響を与える最も重要な要因の一つとなっています。\n\n​\nQ\n​\nQ&Aモード (Q&A Mode)\n\nドキュメントコンテンツに対して質問-回答のペアを自動生成する特殊なインデックス作成戦略で、「質問から質問」へのマッチングを実現します。ユーザーが質問すると、システムは意味的に類似した事前生成された質問を探し、対応する回答を返します。このモードは特にFAQコンテンツや構造化された知識ポイントに適しており、より正確な質問応答体験を提供します。\n\n​\nR\n​\n検索拡張生成 (RAG, Retrieval-Augmented Generation)\n\n外部知識検索と言語生成を組み合わせた技術アーキテクチャです。システムはまず知識ベースからユーザーの質問に関連する情報を検索し、次にこの情報をコンテキストとして言語モデルに提供し、根拠のある正確な回答を生成します。RAGは言語モデルの限られた知識と幻覚問題を克服し、特に最新または専門的な知識を必要とするアプリケーションシナリオに適しています。\n\n​\n推論と行動 (ReAct, Reasoning and Acting)\n\nモデルが思考と操作の実行を交互に行うことができるAIエージェントフレームワークです。問題解決のプロセスでは、モデルはまず現在の状態を分析し、計画を立て、次に適切なツール（検索エンジン、計算機など）を呼び出し、ツールの返す結果に基づいて次のステップを考え、問題が解決されるまで思考-行動-思考のサイクルを形成します。これは複数のステップと外部ツールを必要とする複雑なタスクに適しています。\n\n​\n再ランキング (ReRank)\n\n予備検索結果に対して二次ソートを行い、最終結果の関連性を向上させる技術です。例えば、システムはまず効率的なアルゴリズムを通じて大量の候補コンテンツを迅速に検索し、次により複雑だが精密なモデルを使用してこれらの結果を再評価し並べ替え、最も関連性の高いコンテンツを前に配置することで、検索効率と結果品質のバランスを取ります。\n\n​\n再ランキングモデル (Rerank Model)\n\n検索結果とクエリの関連性を評価し再順序付けするために特別に設計されたモデルです。予備検索とは異なり、これらのモデルは通常より複雑なアルゴリズムを使用し、より多くの意味要素を考慮し、コンテンツがユーザーの意図にどれだけよく一致するかをより正確に判断できます。例えば、Cohere RerankやBGE Rerankerなどのモデルは検索や推薦システムの結果品質を大幅に向上させることができます。\n\n​\nレスポンス形式 (Response_format)\n\nプレーンテキスト、JSON、HTMLなど、モデル出力の構造タイプの指定です。特定のレスポンス形式を設定することで、AI出力がプログラムで処理しやすくなったり、他のシステムに統合しやすくなったりします。例えば、モデルにJSON形式で回答するよう要求すると、出力が一貫した構造を持つことが保証され、フロントエンドアプリケーションが直接解析して表示しやすくなります。\n\n​\nリバースコーリング (Reverse Calling)\n\nプラグインがプラットフォームと対話するための双方向メカニズムで、プラグインがプラットフォーム機能を積極的に呼び出すことを可能にします。Difyでは、これはサードパーティプラグインがAIから呼び出されるだけでなく、ワークフローのトリガーや他のプラグインの呼び出しなど、Difyのコア機能を返りに使用することもできることを意味し、システムの拡張性と柔軟性を大きく向上させます。\n\n​\n検索テスト (Retrieval Test)\n\n知識ベースの検索効果を検証する機能で、開発者がユーザークエリをシミュレートしシステムの返す結果を評価することを可能にします。このテストは開発者がシステムの検索能力の境界を理解し、見逃し検出、誤検出、関連性の低さなどの潜在的な問題を発見して修正するのに役立ち、RAGシステムを最適化するために不可欠なツールです。\n\n​\nS\n​\nスコア閾値 (Score Threshold)\n\n検索結果をフィルタリングするための類似度閾値で、設定値を超えるスコアのコンテンツのみが返されます。適切な閾値を設定することで、無関係な情報がモデル生成を妨げることを避け、回答の正確性を向上させることができます。例えば、閾値が0.8（1.0満点中）に設定されている場合、高度に関連性の高いコンテンツのみが採用されますが、情報が不完全になる可能性があります。閾値を下げるとより多くのコンテンツが含まれますがノイズが入る可能性があります。\n\n​\nセマンティック検索 (Semantic Search)\n\n単純なキーワードマッチングではなく、テキストの意味の理解とマッチングに基づく検索方法です。ベクトル埋め込み技術を使用してテキストを数学的表現に変換し、クエリとドキュメント間の意味的類似性を計算します。この方法は、表現方法は異なるが意味が似ているコンテンツを見つけ、同義語やコンテキスト関係を理解し、さらには言語横断検索をサポートし、特に複雑または自然言語形式のクエリに適しています。\n\n​\nセッション変数 (Session Variables)\n\n複数ターンの対話コンテキスト情報を保存するメカニズムで、AIがコヒーレントな対話を維持することを可能にします。例えば、システムはユーザーの好み（「簡潔な回答」など）、アイデンティティ情報、または対話履歴状態を記憶し、繰り返しの問い合わせを避け、パーソナライズされた体験を提供します。Difyでは、開発者はこれらの変数を定義および管理し、ユーザーを本当に記憶するアプリケーションを構築することができます。\n\n​\n音声からテキスト変換 (STT, Speech-to-Text)\n\nユーザーの音声入力をテキストデータに変換する技術です。この技術により、ユーザーはタイピングではなく話すことでAIシステムと対話でき、対話の自然さと利便性が向上し、特にモバイルデバイス、運転シナリオ、またはアクセシビリティアプリケーションに適しており、音声アシスタントやリアルタイム文字起こしアプリケーションの基盤となります。\n\n​\nストリームツール呼び出し (Stream-tool-call)\n\nAIシステムが完全な回答が生成されるのを待たずに、応答を生成しながら外部ツールを呼び出すことができるリアルタイム処理モードです。このアプローチは複雑なタスクの応答速度を大幅に向上させ、ユーザー体験をよりスムーズにし、複数のツール呼び出しを必要とする対話シナリオに適しています。\n\n​\nストリーミングレスポンス (Streaming Response)\n\nAIシステムがコンテンツをすべて生成し終わるのを待ってから一度に表示するのではなく、生成されたコンテンツをユーザーにリアルタイムで返す応答メカニズムです。このアプローチは特に長い回答に対するユーザーの待機体験を大幅に改善し、ユーザーは部分的なコンテンツをすぐに見て読み始めることができ、人間の会話における即時フィードバックに似たより自然な対話体験を提供します。\n\n​\nT\n​\n温度 (Temperature)\n\n通常0-1の間で、言語モデル出力のランダム性を制御するパラメータです。温度が低い（0に近い）ほど、モデル出力はより確定的で保守的になり、高確率の語彙を好み、事実に基づく回答に適しています。温度が高い（1に近い）ほど、出力はより多様で創造的になり、創造的な執筆に適しています。例えば、天気予報では0.1の低温度を使用し、物語創作では0.8の高温度を使用する場合があります。\n\n​\nテキスト埋め込み (Text Embedding)\n\nテキストを数値ベクトルに変換するプロセスで、AIシステムが言語を理解し処理することを可能にします。これらのベクトルは語彙と文の意味特徴を捉え、コンピュータがテキスト間の類似性を測定し、関連コンテンツをクラスタリングし、マッチング情報を検索することを可能にします。異なる埋め込みモデル（OpenAIのtext-embedding-ada-002やCohereのembed-multilingualなど）は異なる言語やアプリケーションシナリオ向けに最適化されています。\n\n​\nツール呼び出し (Tool Calling)\n\nAIシステムが外部機能を識別し使用する能力で、モデルの能力境界を大幅に拡張します。例えば、言語モデル自体はリアルタイムデータにアクセスできませんが、天気APIを呼び出すことで現在の天気情報を提供できます。データベース照会ツールを呼び出すことで最新の製品在庫を取得でき、計算機を呼び出すことで複雑な計算を実行でき、AIがトレーニングデータ範囲を超える問題を解決できるようになります。\n\n​\nTopK\n\n検索で返される結果の数を制御するパラメータで、類似度が最も高い上位K個のテキストフラグメントを保持するよう指定します。適切なTopK値の設定はRAGシステムのパフォーマンスに不可欠です：値が小さすぎると重要な情報を失う可能性があり、値が大きすぎるとノイズを招き言語モデルの処理負担を増やす可能性があります。例えば、簡単な質問ではTopK=3で十分かもしれませんが、複雑な質問では十分な背景を得るためにTopK=10が必要かもしれません。\n\n​\n核サンプリング (TopP, Nucleus Sampling)\n\n累積確率が閾値Pに達する最も可能性の高い語彙からのみ次の単語を選択するテキスト生成制御方法です。最高確率の単語を固定選択することや完全にランダムな選択とは異なり、TopPは確定性と創造性のバランスを取ります。例えば、TopP=0.9は、モデルが確率の合計が90%を占める語彙のみを考慮し、低確率のオプションを無視することを意味し、完全に予測可能な出力と過度にランダムなコンテンツの両方を避けます。\n\n​\n思考の木 (ToT, Tree of Thought)\n\n複数の推論経路を探索する思考方法で、モデルが異なる視点から問題を分析することを可能にします。人間の「もし…ならば…」という思考パターンに似ており、思考の木はモデルに複数の可能な思考分岐を生成させ、各分岐の実現可能性を評価し、最適な経路を選択して継続することを可能にします。これは試行錯誤や複数の可能性を考慮する必要がある複雑な問題を解決するのに特に適しています。\n\n​\nテキスト音声変換 (TTS, Text-to-Speech)\n\n書かれたテキストを自然な音声に変換する技術で、AIシステムが音声でユーザーとコミュニケーションすることを可能にします。現代のTTSシステムは人間の品質に近い自然な音声を生成でき、複数の言語、音調、感情表現をサポートし、オーディオブック、ナビゲーションシステム、音声アシスタント、アクセシビリティサービスで広く使用され、異なるシナリオやユーザーにより自然な対話体験を提供します。\n\n​\nV\n​\nベクトルデータベース (Vector Database)\n\nベクトル埋め込みの保存と検索に特化したデータベースシステムで、効率的な意味検索のインフラストラクチャとして機能します。従来のデータベースとは異なり、ベクトルデータベースは高次元ベクトル類似度検索に最適化され、数百万のドキュメントから意味的に類似したコンテンツを迅速に見つけることができます。Pinecone、Milvus、Qdrantなどの一般的なベクトルデータベースは、RAGシステム、推薦エンジン、コンテンツ分析で重要な役割を果たしています。\n\n​\nベクトル検索 (Vector Retrieval)\n\nテキストベクトル埋め込みの類似性に基づく検索方法で、セマンティック検索の技術的中核を形成します。システムはまずユーザークエリをベクトルに変換し、次に事前計算されたドキュメントベクトルで最も類似したコンテンツを見つけます。この方法は深い意味的関係を捉え、表現方法は異なるが意味が似ているコンテンツを見つけ、キーワード検索の限界を克服し、自然言語クエリや概念的な問題の処理に特に適しています。\n\n​\nビジョン機能 (Vision)\n\nマルチモーダルLLMが画像を理解し処理する機能で、モデルがユーザーがアップロードした画像を分析し、テキストと組み合わせた応答を生成できるようにします。例えば、ユーザーは製品写真をアップロードして使用方法を問い合わせたり、メニュー写真をアップロードして翻訳を要求したり、グラフをアップロードしてデータトレンドの分析を依頼したりできます。この機能はAIアプリケーションシナリオを大幅に拡張し、対話をより直感的で多様化します。\n\n​\nW\n​\nワークフロー (Workflow)\n\n複雑なAIアプリケーションを複数の独立したノードに分解し、特定の順序で実行するタスク編成方法です。Difyプラットフォームでは、開発者は視覚的にワークフローを設計し、複数の処理ステップ（ユーザー入力処理、知識検索、マルチモデル連携、条件分岐など）を組み合わせて、複雑なビジネスロジックを処理できるAIアプリケーションを構築し、アプリケーション開発を柔軟かつ直感的にします。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nA\nエージェント (Agent)\nエージェンティックワークフロー (Agentic Workflow)\n自動音声認識 (ASR, Automatic Speech Recognition)\nB\n思考の骨格 (BoT, Backbone of Thought)\nC\nチャンキング (Chunking)\n引用と帰属 (Citation and Attribution)\n思考の連鎖 (CoT, Chain of Thought)\nD\nドメイン固有言語 (DSL, Domain-Specific Language)\nE\n抽出・変換・読み込み (ETL, Extract, Transform, Load)\nF\n頻度ペナルティ (Frequency Penalty)\n関数呼び出し (Function Calling)\nG\n一般的なチャンキングパターン (General Chunking Pattern)\n思考のグラフ (GoT, Graph of Thought)\nH\nハイブリッド検索 (Hybrid Search)\nI\n転置インデックス (Inverted Index)\nK\nキーワード検索 (Keyword Search)\n知識ベース (Knowledge Base)\n知識検索 (Knowledge Retrieval)\nL\n大規模言語モデル (LLM, Large Language Model)\nローカルモデル推論 (Local Model Inference)\nM\nサービスとしてのモデル (MaaS, Model-as-a-Service)\n最大トークン数 (Max_tokens)\nメモリ (Memory)\nメタデータフィルタリング (Metadata Filtering)\nマルチモーダルモデル (Multimodal Model)\nマルチツール呼び出し (Multi-tool-call)\nマルチパス検索 (Multi-path Retrieval)\nP\n親子チャンキング (Parent-Child Chunking)\n存在ペナルティ (Presence Penalty)\n事前定義モデル (Predefined Model)\nプロンプト (Prompt)\nQ\nQ&Aモード (Q&A Mode)\nR\n検索拡張生成 (RAG, Retrieval-Augmented Generation)\n推論と行動 (ReAct, Reasoning and Acting)\n再ランキング (ReRank)\n再ランキングモデル (Rerank Model)\nレスポンス形式 (Response_format)\nリバースコーリング (Reverse Calling)\n検索テスト (Retrieval Test)\nS\nスコア閾値 (Score Threshold)\nセマンティック検索 (Semantic Search)\nセッション変数 (Session Variables)\n音声からテキスト変換 (STT, Speech-to-Text)\nストリームツール呼び出し (Stream-tool-call)\nストリーミングレスポンス (Streaming Response)\nT\n温度 (Temperature)\nテキスト埋め込み (Text Embedding)\nツール呼び出し (Tool Calling)\nTopK\n核サンプリング (TopP, Nucleus Sampling)\n思考の木 (ToT, Tree of Thought)\nテキスト音声変換 (TTS, Text-to-Speech)\nV\nベクトルデータベース (Vector Database)\nベクトル検索 (Vector Retrieval)\nビジョン機能 (Vision)\nW\nワークフロー (Workflow)",
        "error": null
      },
      {
        "link_index": 6,
        "link_text": "クラウドサービス",
        "target_url": "https://docs.dify.ai/ja-jp/getting-started/cloud",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\n入門\nクラウドサービス\nCopy page\n\n注意：Difyは現在ベータテスト段階にあります。ドキュメントと製品に不一致がある場合は、実際の製品体験をご参照ください。\n\nDifyは誰でも手軽にご利用いただけるクラウドサービスです。プランと価格をご確認の上、お客様の要求に最適なプランをお選びください。\n\nまずはSandboxプランからお試しいただけます。クレジットカード不要で200回のOpenAI APIコールを無料で試すことができます。クラウド版のSandboxプランのご利用には、GitHubまたはGoogleアカウント、および有効なOpenAI APIキーが必要です。使用手順は以下の通りです：\n\nDifyクラウドにサインアップし、新しいワークスペースを作成するか、既存のワークスペースに参加します。\nモデルプロバイダーを設定するか、Dify提供のモデルプロバイダーを使えます。\n以上で、アプリケーションを作成できます！\n​\nよくある質問\n\nQ: Difyクラウドを使用する際、私のデータはどのように処理・保存されますか？\n\nA: Difyクラウドを使用すると、ユーザーデータは米国東部地域にあるAWSサーバーに安全に保存されます。これには、積極的に入力したデータとアプリから生成されたデータの両方が含まれます。私たちはデータのセキュリティと完全性を最優先事項としており、クラウドストレージソリューションにおける最高水準の基準に基づき管理されることを確保しています。\n\nQ: APIキーや他の機密情報を保護するためにどのような対策がありますか？\n\nA: Difyでは、APIキーや他の機密情報を保護することの重要性を深く理解しています。これらの情報は保存時に暗号化され、Dify側から閲覧することはできません。アクセスは、正当な所有者であるユーザーご本人のみに限定されます。\n\nQ: Difyクラウドでのアプリの匿名化について説明していただけますか？\n\nA: Difyクラウドでは、プライバシーを確保し、暗号化と復号化のオーバーヘッドを減らすためにアプリのデータを匿名化しています。これは、アプリで使用されるデータが特定可能なユーザーアカウントと直接関連付けられないことを意味します。データを匿名化することで、クラウドサービスのパフォーマンスを維持しながらプライバシーを強化しています。\n\nQ: Difyクラウドから自分のアカウントと関連するすべてのデータを削除するプロセスはどのようになっていますか？\n\nA: アカウントおよび関連データの削除をご希望の場合、アカウント設定ページにアクセスするか、画面右上のアバターをクリックして「アカウント」を選択してください。ページ内に「アカウントを削除」ボタンがありますので、クリックして画面の指示に従ってください。当社はお客様のプライバシーとデータに関する権利を尊重しており、ご依頼に基づき、データ保護規制に従って、システムからお客様に関連するすべてのデータを消去いたします。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nモデルプロバイダーリスト\nコミュニティ版\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nよくある質問",
        "error": null
      },
      {
        "link_index": 7,
        "link_text": "Dify Premium",
        "target_url": "https://docs.dify.ai/ja-jp/getting-started/dify-premium",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\n入門\nDify Premium\nCopy page\n\nプレミアムPremium\n\nDify PremiumはAWS AMI製品であります。これにより、ブランドのカスタマイズが可能で、AWS EC2にワンクリックで展開できます。AWS Marketplaceから購読し、次のようなシナリオに最適です：\n\n中小企業が1つ以上のアプリケーションをサーバーに構築し、データのプライバシーに関心がある場合。\nDify Cloudのサブスクリプションプランに関心があり、しかし、活用事例がプランで提供されるリソースを超える場合。\nDify Enterpriseを組織内で導入する前に、POC検証を行いたい場合。\n​\nセットアップ\n\nDifyを初めて使用する際には、管理者初期化パスワード（EC2インスタンスIDとして設定）を入力し、セットアッププロセスを開始してください。\n\nAMIを展開した後は、EC2コンソールで見つかるインスタンスのパブリックIPを使用してDifyにアクセスします（デフォルトではHTTPポート80を使用します）。\n\n​\nアップグレード\n\nEC2インスタンスで、次のコマンドを実行してください：\n\nCopy\ngit clone https://github.com/langgenius/dify.git /tmp/dify\nmv -f /tmp/dify/docker/* /dify/\nrm -rf /tmp/dify\ndocker-compose down\ndocker-compose pull\ndocker-compose -f docker-compose.yaml -f docker-compose.override.yaml up -d\n\n\nコミュニティ版を v1.0.0 にアップグレードする\n\n​\nカスタマイズ\n\nセルフホスト展開の場合と同様に、EC2インスタンス内の.envファイルの環境変数を必要に応じて変更することができます。その後、以下のコマンドを使用してDifyを再起動してください：\n\nCopy\ndocker-compose down\nocker-compose -f docker-compose.yaml -f docker-compose.override.yaml up -d\n\n​\nカスタマイズ Webアプリのロゴやブランド\n\nこの機能は設定のカスタマイズで有効にすることができます。Powered by Difyを削除を有効にして、独自のロゴをアップロードしてください。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nよくある質問\nDify 教育版\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nセットアップ\nアップグレード\nカスタマイズ\nカスタマイズ Webアプリのロゴやブランド",
        "error": null
      },
      {
        "link_index": 8,
        "link_text": "Dify 教育版",
        "target_url": "https://docs.dify.ai/ja-jp/getting-started/dify-for-education",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\n入門\nDify 教育版\nCopy page\n​\nはじめに\n\nDify教育版は、学生、教師、教育機関に手軽で手頃なAI学習・開発ツールを提供し、AI教育をより身近で普及させることを目指しています。\n\n​\nメリット\n\n学生の方へ：Dify SaaSサブスクリプションサービスを割安な価格で利用でき、より多くの計算リソースを獲得できます。授業の課題、研究プロジェクト、AIアプリケーション開発に役立ちます。\n\n教師の方へ：Difyを教育現場でAI教材として活用し、学生たちがAIアプリケーション開発について深く学べるようサポートします。\n\n教育機関・学校の方へ：チームでAIリソースを簡単に管理でき、教育効率を高め、教育分野におけるAIの可能性をさらに探求できます。\n\n​\n特典\n\n現在のDify教育版特典は、Difyプロフェッショナルプランのサブスクリプションが50%割引になるクーポンです。\n\n今後も学習や授業をサポートするための教育版専用の特典を継続的に提供していく予定です。ご期待ください。\n\n​\n申請方法\n​\n申請資格\n\nDify教育版認証を申請するには、以下の条件をすべて満たす必要があります：\n\n18歳以上であること\n現在、学生、教師、または教育機関の職員であること\n教育用メールアドレスでDifyアカウントを登録していること\n​\n申請手順\nDifyアカウントの作成\n\n教育版認証を申請する前に、教育用メールアドレスでDifyアカウントを登録してください。\n\nDify教育版認証の申請\n\n教育用メールアドレスで登録したDifyアカウントにログインし、右上のユーザーアイコンをクリックして、ドロップダウンメニューから設定を選択します。\n\n設定ページで、請求 > 教育版認証を申請をクリックします。\n\n学校の正式名称を入力します （略称は使用しないでください）。\n\n申請人の身分を選択します。\n\n利用規約に同意するにチェックを入れ、送信をクリックします。\n\n認証が成功すると、Dify教育版専用の割引クーポンが付与されます。\n​\nDify教育認証状況の確認方法\n\n教育認証の申請が成功すると、右上のユーザーアイコンをクリックして、ドロップダウンメニューからサブスクリプション状況を確認できます。サブスクリプション状況がEduと表示されていれば、教育認証が成功しています。\n\n​\nクーポンの使用方法\n​\n概要\n\nDify教育認証が完了すると、教育クーポンが自動的にあなたのDifyアカウントに付与されます。Difyプロフェッショナルプランを購読する際にこのクーポンを使用できます。\n\nクーポン割引：50%\n\nクーポン有効期間：12ヶ月\n\nクーポン使用条件：\n\n有効期限内にクーポンを使用する必要があります。有効期限が過ぎると使用できなくなります。\n教育版認証は年に一度のみ申請可能で、一度に1枚のクーポンしか取得できません。\nクーポンはワークスペースの所有者本人のみ利用可能です。\n​\n使い方\nサブスクリプションページで「Dify プロフェッショナルプラン」を選択：\n月額払いの場合：今すぐ始めるボタンを直接クリックし、決済ページへ進みます。\n年額払いの場合：ページ右上の年額請求スイッチをオンにした後、今すぐ始めるボタンをクリックし決済ページへ進みます。\n支払いページに進むと、クーポンコードが自動的に適用されます。このページでクーポンが有効になっていることを確認し、割引後の金額を確認できます。\n\n注文内容に問題がなければ、お支払い方法を選択してください。\n\nお支払いが完了すると、サブスクリプションの設定が完了となります。\n\nサブスクリプション後、あなたのステータスはPro(Edu)に更新されます。\n\n​\n教育情報の更新方法\n​\nメールアドレスの更新\n\nメールアドレスを変更する必要がある場合は、現在のところ手動対応となっております。<support@dify.ai>までご連絡ください。\n\n​\n学校情報の更新\n\n認証完了後に学校情報を変更したい場合：教育認証が完了した後に学校情報を変更する必要がある場合は、<support@dify.ai>までご連絡ください。\n\n認証期限切れ後の学校情報変更：教育認証の期限が切れた後は、再認証の際に新しい学校情報を入力することができます。\n\n​\nDify教育認証の更新方法\n\n教育認証の期限が切れた場合は、前述のDify教育認証の完了セクションを参照して、再度申請を行ってください。\n\n​\nよくある質問\nDifyを学習の方法は？\n\n公式ドキュメントを参照する：Dify公式ドキュメントで、詳細な使用ガイドをご覧いただけます。\n\nコミュニティに参加する：Dify Discordコミュニティに参加して、開発者と交流し、使用体験を共有しましょう。\n\nDifyプランの料金はいくらですか？\n\nDifyの料金ページで詳細をご確認いただけます。\n\n教育認証を申請できないのは誰ですか？\n\n18歳未満のユーザー。\n\n個人用メールアドレス（Gmailなど）でアカウント登録したユーザー。\n\n教育認証が拒否/取り消された理由と対処法は？\n\n以下の状況では、教育認証の申請が拒否または取り消される可能性があります：\n\n教育認証申請時に利用規約に同意するにチェックを入れなかった\n教育機関のメールアドレスを使用していない\n偽の学校や企業のメールアドレスを使用している\n虚偽の個人情報や学校情報を提供している\n教育特典の不正使用\n\n申請が拒否されたり認証が取り消された場合は、<support@dify.ai>までご連絡ください。\n\n卒業または学校を離れた後も教育認証は有効ですか？\n\n教育認証は教育機関のメールアドレスの状態に直接関連しています。教育メールアドレスが正常に使用できる限り、認証は有効です。\n\n教育メールアドレスが使用できなくなった場合は、<support@dify.ai>までご連絡ください。\n\n教育機関のメールアドレスを持っていない場合、教育認証を申請するにはどうすればよいですか？\n\n現在、Dify教育認証は主に教育機関のメールアドレスによる身分確認を通じて行われています。教育機関のメールアドレスをお持ちでない場合は、誠に申し訳ありませんが、教育認証を申請することはできません。\n\n以前にサブスクリプションを利用していましたが、現在は期限切れです。教育優待クーポンはまだ使用可能ですか？\n\n購読が期限切れの場合でも、アカウントにStripeの支払い情報が登録されている場合、次回の再購読時に教育優待クーポンが自動適用されます。\n\n現在Difyプランを購読中です。教育認証を申請した後、サブスクリプション内容はどうなりますか？\n\nプロフェッショナルプランを購読中の場合、教育優待クーポンは次回の課金周期から自動適用されます。\n\nプロフェッショナルプラン以外を購読中の場合、教育優待クーポンはアカウントに保存され、将来プロフェッショナルプランを選択した際に自動使用されます。\n\n教育認証済みでDifyプロフェッショナルプランを購読中ですが、次回課金開始前に解約した場合はどうなりますか？\n\n現在の課金周期終了時にサブスクリプションが解除され、同時に教育優待クーポンも失効し、再度有効化することはできません。\n\n解約後に教育認証を有効化した場合、割引は適用されますか？\n\n教育優待は保持されますが、以下の点にご注意ください：\n\n現在の購読期間終了後の再購読時にはクーポンが自動適用されます。\n購読期間終了前の更新/延長時には適用されず、割引を利用するには現行プラン終了後の再購入が必要です。\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nDify Premium\nModel configuration\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nはじめに\nメリット\n特典\n申請方法\n申請資格\n申請手順\nDify教育認証状況の確認方法\nクーポンの使用方法\n概要\n使い方\n教育情報の更新方法\nメールアドレスの更新\n学校情報の更新\nDify教育認証の更新方法\nよくある質問",
        "error": null
      },
      {
        "link_index": 9,
        "link_text": "支援を求める",
        "target_url": "https://docs.dify.ai/ja-jp/community/support",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nコミュニティ\n支援を求める\nCopy page\n\nこのドキュメントを読んでも製品の使用に関して疑問や提案がある場合は、以下の方法で支援を求めることができます。私たちのチームとコミュニティは、できる限りのサポートを提供いたします。\n\n​\nコミュニティサポート\n\nDifyのアカウント情報やその他の情報をコミュニティに投稿しないでください。また、サポートスタッフもアカウント情報を要求することはありません。\n\nGithub 上でイシューを提出\nDiscordコミュニティに参加\n​\nお問い合わせ\n\n製品サポート以外のその他の事柄に適用されます。\n\nhello@dify.ai へメールを送信\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nチャットストリームエージェントを使用した Twitter アカウントの分析方法\n貢献者になる\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nコミュニティサポート\nお問い合わせ",
        "error": null
      },
      {
        "link_index": 10,
        "link_text": "貢献者になる",
        "target_url": "https://docs.dify.ai/ja-jp/community/contribution",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nコミュニティ\n貢献者になる\nCopy page\n\nDifyに貢献したいと思っていることには素晴らしいと思います。私たちはあなたの貢献を心待ちにしております。スタッフも資金も限られた新興企業として、私たちはLLMアプリケーションの構築と管理のための最も直感的なワークフローを設計するという野心的な目標を持っています。そのため、コミュニティからのあらゆるサポートは貴重です。\n\n我々の現状を考えると、柔軟かつ迅速に更新する必要がありますが、貢献者がスムーズに貢献できるようにしたいとも考えています。そのために、この貢献ガイドを作成しました。このガイドは、あなたがコードベースに慣れ、貢献者としての活動を迅速に開始できるようにすることを目的としています。\n\nこのガイドは、Dify自体と同様に、常に改善されています。時折プロジェクトの実態よりも遅れることがあるかもしれませんが、ご理解と改善のためのフィードバックを心から歓迎します。\n\nライセンスに関しては、時間を取って短いライセンスと貢献者協定を読んでください。また、コミュニティは行動規範にも従います。\n\n​\n始める前に\n\n既存のイシューを探すか、新しいイシューを作成することができます。イシューは次の2つのカテゴリに分かれます：\n\n​\n機能リクエスト：\n\n新しい機能リクエストを行う場合は、提案する機能の目的を説明し、できるだけ詳細なコンテキストを提供してください。@perzeusssが作成した優れた機能リクエスト助手を使ってドラフトを作成することもできます。ぜひ試してみてください。\n\n既存のイシューから選びたい場合は、その下にコメントを残して意思を示してください。\n\n関連するチームメンバーが関与します。うまくいけば、彼らがコーディングを開始することを承認します。それまでは、変更が提案される可能性があるため、作業を開始しないでください。\n\n提案された機能が属する領域に応じて、異なるチームメンバーと連携する必要があります。以下は、各チームメンバーが現在取り組んでいる分野の概要です：\n\nMember\tScope\n@yeuoly\tArchitecting Agents\n@jyong\tRAG pipeline design\n@GarfieldDai\tBuilding workflow orchestrations\n@iamjoel & @zxhlyh\tMaking our frontend a breeze to use\n@guchenhe & @crazywoola\tDeveloper experience, points of contact for anything\n@takatost\tOverall product direction and architecture\n\n優先順位の判定ルール：\n\nFeature Type\tPriority\nHigh-Priority Features as being labeled by a team member\tHigh Priority\nPopular feature requests from our community feedback board\tMedium Priority\nNon-core features and minor enhancements\tLow Priority\nValuable but not immediate\tFuture-Feature\n​\nその他（例えばバグ報告、パフォーマンス向上、タイポ修正）：\n\nすぐにコーディングを開始してください。\n\n優先順位の判定ルール：\n\nIssue Type\tPriority\nBugs in core functions (cannot login, applications not working, security loopholes)\tCritical\nNon-critical bugs, performance boosts\tMedium Priority\nMinor fixes (typos, confusing but working UI)\tLow Priority\n​\nインストール\n\n以下はDifyを開発用に設定する手順です：\n\n​\n1. リポジトリをフォークする\n​\n2. リポジトリをクローンする\n\nターミナルからフォークしたリポジトリをクローンします：\n\nCopy\ngit clone git@github.com:<github_username>/dify.git\n\n​\n3. 依存関係を確認する\n\nDifyは以下のツールとライブラリに依存しています：\n\nDocker\nDocker Compose\nNode.js v18.x (LTS)\nnpm バージョン 8.x.x もしくは Yarn\nPython バージョン 3.10.x\n​\n4. インストール\n\nDifyはバックエンドとフロントエンドで構成されています。cd api/を使ってバックエンドディレクトリに移動し、次はバックエンドREADMEに従ってインストールして下さい。別のターミナルでcd web/を使ってフロントエンドディレクトリに移動し、そしてフロントエンドREADMEに従ってインストールして下さい。\n\n一般的な問題とトラブルシューティングの手順についてはインストールFAQを参照してください。\n\n​\n5. ブラウザでDifyにアクセスする\n\n設定を確認するため、ブラウザを開きhttp://localhost:3000（デフォルトまたはカスタムURLとポート）にアクセスします。これでDifyが動作しているはずです。\n\n​\n開発\n\nモデルを追加提供する場合は、このガイドを参照してください。\n\nエージェントやワークフローにツールを追加提供する場合は、このガイドを参照してください。\n\n注意点：新しいツールを提供したい場合は、必ずツールの YAML 説明ページに連絡先を残し、ドキュメントDify-docs のコードリポジトリに対応するPRを提出してください。\n\n貢献する部分を迅速に理解できるように、以下にDifyのバックエンドとフロントエンドの簡単な注釈付きアウトラインを示します：\n\n​\nバックエンド\n\nDifyのバックエンドはPythonで書かれており、Flaskフレームワークを使用しています。SQLAlchemyをORMとして使用し、Celeryをタスクキューとして使用しています。認証ロジックはFlask-loginで処理されます。\n\nCopy\n[api/]\n├── constants             // コードベース全体で使用される定数設定。\n├── controllers           // APIルート定義とリクエスト処理ロジック。           \n├── core                  // コアアプリケーションオーケストレーション、モデル統合、ツール。\n├── docker                // Dockerおよびコンテナ化関連の設定。\n├── events                // イベント処理と処理\n├── extensions            // サードパーティフレームワーク/プラットフォームとの拡張機能。\n├── fields                // シリアライズ/マーシャリングのためのフィールド定義。\n├── libs                  // 再利用可能なライブラリとヘルパー。\n├── migrations            // データベース移行のためのスクリプト。\n├── models                // データベースモデルとスキーマ定義。\n├── services              // ビジネスロジックを指定。\n├── storage               // 秘密鍵保管。      \n├── tasks                 // 非同期タスクとバックグラウンドジョブの処理。\n└── tests\n\n​\nフロントエンド\n\nこのWebサイトはNext.jsテンプレートを使用しており、スタイリングにはTailwind CSSを使用しています。React-i18nextを国際化に使用しています。\n\nCopy\n[web/]\n├── app                   // レイアウト、ページ、およびコンポーネント\n│   ├── (commonLayout)    // アプリ全体で使用される共通レイアウト\n│   ├── (shareLayout)     // トークン固有のセッション間で共有されるレイアウト \n│   ├── activate          // アクティベートページ\n│   ├── components        // ページとレイアウトで共有されるコンポーネント\n│   ├── install           // インストールページ\n│   ├── signin            // サインインページ\n│   └── styles            // グローバルに共有されるスタイル\n├── assets                // 静的アセット\n├── bin                   // ビルドステップで実行されるスクリプト\n├── config                // 調整可能な設定とオプション \n├── context               // アプリの異なる部分で使用される共有コンテキスト\n├── dictionaries          // 言語固有の翻訳ファイル \n├── docker                // コンテナ設定\n├── hooks                 // 再利用可能なフック\n├── i18n                  // 国際化設定\n├── models                // データモデルとAPIレスポンスの形状を記述\n├── public                // ファビコンなどのメタアセット\n├── service               // APIアクションの形状を指定\n├── test                  \n├── types                 // 関数パラメータと戻り値の記述\n└── utils                 // 共有ユーティリティ関数\n\n​\nPRを提出する\n\n最後に、私たちのリポジトリにプルリクエスト（PR）を提出する時が来ました。重要な機能の場合、最初に deploy/dev ブランチにマージしてテストを行い、その後 main ブランチにマージします。マージコンフリクトが発生した場合や、プルリクエストの提出方法が分からない場合は、GitHubのプルリクエストチュートリアルを参照してください。\n\nこれで完了です！あなたのPRがマージされると、あなたは私たちのREADMEに貢献者として掲載されます。\n\n​\nヘルプを求める\n\n貢献の過程で困難に直面したり質問がある場合は、関連するGitHubのイシューで質問を提出するか、私たちのDiscordに参加して迅速なコミュニケーションを行ってください。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\n支援を求める\nドキュメントへの貢献\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\n始める前に\n機能リクエスト：\nその他（例えばバグ報告、パフォーマンス向上、タイポ修正）：\nインストール\n1. リポジトリをフォークする\n2. リポジトリをクローンする\n3. 依存関係を確認する\n4. インストール\n5. ブラウザでDifyにアクセスする\n開発\nバックエンド\nフロントエンド\nPRを提出する\nヘルプを求める",
        "error": null
      },
      {
        "link_index": 11,
        "link_text": "ドキュメントへの貢献",
        "target_url": "https://docs.dify.ai/ja-jp/community/docs-contribution",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nコミュニティ\nドキュメントへの貢献\nCopy page\n\nDify のヘルプドキュメントは、オープンソースプロジェクトとして運営されています。どのような形式の貢献も歓迎します。ドキュメントに問題を見つけた場合や、自分で内容を追加したい場合には、GitHub 上で issue を提出するか、もしくは直接 pull request を作成してください。我々は迅速に対応いたします。\n\n​\n貢献の方法\n\nドキュメントの問題は次の2つのカテゴリーに分けられます：\n\nコンテンツ修正\nコンテンツ追加\nベストプラクティス\n​\nコンテンツの誤り\n\nドキュメントを読んでいる際に内容の誤りを見つけたり、一部を修正したい場合は、文書ページの右側にある目次内の “Github に編集” ボタンをクリックしてください。これにより、GitHub のオンラインエディターを使用してファイルを修正できます。その後、修正内容を簡潔に説明した pull request を作成してください。タイトルは Fix: Update xxx の形式を使用してください。リクエストを受け取った後、レビューを行い、問題がなければ修正をマージします。\n\nもちろん、Issues ページにドキュメントのリンクを貼り付け、修正が必要な内容を簡単に説明していただくことも可能です。フィードバックを受け取った後、迅速に対応いたします。\n\n​\nコンテンツの欠落\n\n新しいドキュメントをコードリポジトリに追加したい場合は、以下の手順に従ってください：\n\nリポジトリをフォークする\n\nリポジトリを GitHub アカウントにフォークし、リポジトリをローカルにクローンします:\n\nCopy\ngit clone https://github.com/<your-github-account>/dify-docs.git\n\n\n注: GitHub のオンラインコードエディターを使用して、新しい md ファイルを適切なディレクトリに直接送信することもできます。\n\n関連するドキュメントディレクトリを見つけてファイルを追加する\n\nたとえば、サードパーティツールの使用方法に関するドキュメントを追加したい場合は、/guides/tools/tool-configuration/ ディレクトリに新しい md ファイルを追加してください。\n\npull request を提出する\n\npull request を提供する時、Docs: add xxx のタイトルで説明欄に書いて、文章内容を簡単に記載してください。request を受け取った後、review を行い、問題がなければ merge します。\n\n​\nベストプラクティス\n\nDifyで構築した革新的なアプリケーション事例の共有を大歓迎します！コミュニティメンバーが皆様の実践経験を理解・再現しやすくするため、以下の構成でのコンテンツ作成をお勧めします：\n\nCopy\n1. プロジェクト概要\n   - アプリケーションの活用シーンと解決課題\n   - コア機能と特徴\n   - デモンストレーションと成果\n\n2. システム設計・処理フロー\n\n3. 事前準備（必要な場合）\n   - 必要リソース一覧\n   - ツールと依存関係\n\n4. Dify実装手順（参考）\n   - アプリケーション作成と基本設定\n   - ワークフロー構築の詳細\n   - 主要ノード設定解説\n\n5. FAQ\n\n\n説明用のスクリーンショットを追加される場合は、オンライン画像ホスティングサービスのリンクをご利用ください。\n\n皆様の貴重なナレッジシェアが、Difyコミュニティの発展を支えます！\n\n​\nヘルプを受ける\n\n貢献の過程で困難に直面したり、疑問がある場合は、関連する GitHub の issue に質問を投稿するか、Discord に参加して迅速にコミュニケーションを取ることができます。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\n貢献者になる\nはじめに\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\n貢献の方法\nコンテンツの誤り\nコンテンツの欠落\nベストプラクティス\nヘルプを受ける",
        "error": null
      },
      {
        "link_index": 12,
        "link_text": "はじめに",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/introduction",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nプラグイン\nはじめに\nCopy page\n\nコミュニティーバージョンでプラグイン機能を利用するには、バージョンをv1.0.0にアップデートしてください。\n\n​\nプラグインとは\n\nプラグインとは、開発者がより手軽に機能を拡張できる、サードパーティ製の拡張モジュールです。Difyプラットフォームには、Difyチームやコミュニティによってメンテナンスされた多くのツールがすでに用意されていますが、多様化するニッチなニーズを完全に満たせない場合があります。また、新しいツールをDifyプラットフォームに開発・統合するには、時間と手間がかかることが少なくありません。\n\nそこで、よりアジャイルな開発を可能にするため、Difyのエコシステムをオープンにし、包括的なプラグイン開発SDKを提供することにしました。これにより、すべての開発者が独自のツールを容易に構築し、サードパーティのモデルやツールをシームレスに統合して、アプリケーションの可能性を飛躍的に向上させることができます。\n\n​\nプラグインのメリット\n\n新しいプラグインシステムは、従来のフレームワークの制約を超え、より豊富で強力な拡張機能を提供します。明確に定義されたシナリオに対応するために、5つの異なるプラグインタイプを用意しており、開発者はDifyアプリケーションを自由にカスタマイズし、強化することができます。\n\nさらに、プラグインシステムは共有しやすいように設計されています。Difyマーケットプレイス、GitHub、またはローカルファイルパッケージを通じてプラグインを配布できます。他の開発者は、これらのプラグインを迅速にインストールし、そのメリットを享受できます。\n\nDifyマーケットプレイスは、開発者向けのオープンなエコシステムであり、モデル、ツール、AIエージェント、拡張機能、プラグインバンドルなど、幅広いリソースを提供しています。マーケットプレイスを通じて、サードパーティのサービスを既存のDifyアプリケーションにシームレスに統合し、機能を強化し、Difyコミュニティ全体の発展に貢献できます。\n\n新しいモデルを統合したい場合も、Difyの既存機能を拡張するための専用ツールを追加したい場合も、Dify マーケットプレイスには必要なリソースが揃っています。より多くの開発者の皆様に参加していただき、Difyのエコシステムを共に発展させ、関係者全員に利益をもたらすことを願っています。\n\n​\nプラグインの種類\n\nモデル\n\nこれらのプラグインは、さまざまなAIモデル（主要なLLMプロバイダーやカスタムモデルを含む）を統合し、LLM APIの設定とリクエストを処理します。モデルプラグインの作成の詳細については、クイックスタート：モデルプラグインをご覧ください。\n\nツール\n\nツールとは、Chatflow、Workflow、Agentタイプのアプリケーションから呼び出すことができるサードパーティのサービスのことです。Difyアプリケーションの機能を拡張するためのAPI実装を提供します。たとえば、Google検索プラグインの開発については、クイックスタート：ツールプラグインをご参照ください。\n\nエージェント戦略\n\nエージェント戦略プラグインは、エージェントノード内の推論および意思決定ロジックを定義します。これには、ツール選択、呼び出し、および結果処理などが含まれます。\n\nエージェント戦略プラグインは、エージェントノード内部の推論および意思決定ロジックを定義します。これには、ツールの選択、実行、およびLLMから返された結果の処理ロジックが含まれます。詳細な開発ガイダンスについては、クイックスタート：エージェント戦略プラグインをご参照ください。\n\n拡張機能\n\nよりシンプルなシナリオのエンドポイント機能のみを提供する軽量プラグインで、HTTPサービスを介して迅速な拡張を可能にします。基本的なAPI呼び出しを必要とする簡単な統合に最適です。詳細については、クイックスタート：拡張機能プラグインをご参照ください。\n\nバンドル\n\n「プラグインバンドル」は、複数のプラグインをまとめたものです。バンドルを使用すると、厳選されたプラグインセットを一度にインストールできます。プラグインを1つずつ追加する手間が省けます。プラグインバンドルの作成の詳細については、プラグイン開発：バンドルプラグインをご覧ください。\n\n​\nプラグインの新機能\n\nLLMのマルチモーダル対応を拡張\n\nプラグインを使用すると、LLMがマルチモーダルデータを処理する能力を高めることができます。開発者は、画像編集や動画処理などのタスクを追加できます。トリミングや背景の削除から、ポートレート画像の処理まで、幅広い用途に対応できます。\n\n開発者フレンドリーなデバッグ機能\n\nプラグインシステムは、一般的なIDEとデバッグツールをサポートしています。いくつかの環境変数を設定するだけで、SaaSとして実行されているDifyインスタンスにリモートで接続できます。Difyでプラグインに対して実行した操作は、デバッグのためにローカルランタイムに転送されます。\n\n永続的なデータストレージ\n\nより複雑なユースケースに対応するために、プラグインシステムにはデータ永続性が組み込まれています。\n\nプラグインレベルのデータストレージ: ワークスペースレベルの情報をプラグインと共有して、より高度なカスタム機能を実現できます。\n組み込みのデータ管理: プラグインはデータを確実に保存および管理できるため、複雑なビジネスロジックを容易に実装できます。\n\n便利な双方向通信\n\nプラグインは、Difyのコア機能と双方向に対話できるようになりました。\n\nAIモデルの呼び出し\nツールの使用\nアプリケーションへのアクセス\nナレッジベースとの対話\n関数ノードの呼び出し（質問分類、パラメータ抽出など）\n\nこの双方向メカニズムにより、プラグインは既存のDify機能を活用するだけでなく、スタンドアロンのゲートウェイとしても機能し、アプリケーションのユースケースを拡大します。\n\n強化されたエンドポイントのカスタマイズ機能\n\n既存のDify API（ChatbotやWorkflow APIなど）に加えて、プラグイン内にカスタムAPIを作成できるようになりました。開発者はビジネスロジックをプラグインとしてラップし、Dify マーケットプレイスでホストすることで、データ処理とリクエスト処理のエンドポイントサポートを自動的に得られます。\n\n​\n詳しくはこちら\n\nクイックスタート\n\nプラグインをすばやくインストールして使用するには、以下を参照してください。\n\ninstall-plugins.md\n\ninstall-plugins.md\n\nプラグインの開発を開始するには、以下を参照してください。\n\ndevelop-plugins\n\ndevelop-plugins\n\nプラグインの公開\n\nプラグインをDify Marketplaceで公開するには、必要な情報と利用方法に関するドキュメントを記入してください。その後、プラグインのコードをGitHubリポジトリに提出してください。承認されると、マーケットプレイスに掲載されます。\n\npublish-to-dify-marketplace\n\npublish-to-dify-marketplace\n\n公式のDifyマーケットプレイスに加えて、個人のGitHubリポジトリでプラグインをホストしたり、ファイルとしてパッケージ化して直接共有することもできます。\n\npackage-plugin-file-and-publish.md\n\npackage-plugin-file-and-publish.md\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nドキュメントへの貢献\nQuick start\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nプラグインとは\nプラグインのメリット\nプラグインの種類\nプラグインの新機能\n詳しくはこちら",
        "error": null
      },
      {
        "link_index": 13,
        "link_text": "プラグイン管理方法",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/manage-plugins",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nプラグイン\nプラグイン管理方法\nCopy page\n\nこのガイドは、ワークスペースの所有者や管理者向けに、プラグインの権限を設定し、管理する方法を詳しく説明します。プラグインの権限を管理することで、どのユーザーがプラグインに関連する操作を行えるかを定めることができます。\n\n​\nプラグイン権限の設定\n\nチームの所有者や管理者は、Difyプラットフォームのホームページ右上にある 「プラグイン」 ページから、次のプラグイン権限を設定できます：\n\nプラグインのインストールと管理\n\nこの権限により、誰がプラグインをインストールや管理できるかを決めます。オプションには以下があります：\n\nEveryone（全員）: ワークスペース内の全てのユーザーがプラグインをインストールや管理できる\nAdmins（管理者）: ワークスペースの管理者だけがプラグインをインストールや管理できる\nNo one（無人）: 誰もプラグインをインストールや管理できない\n\nプラグインのデバッグの権限\n\nこの権限により、誰がプラグインのデバッグを行えるかを決めます。オプションには以下があります：\n\nEveryone（全員）: ワークスペース内の全てのユーザーがプラグインをデバッグできる\nAdmins（管理者）: ワークスペースの管理者だけがプラグインをデバッグできる\nNo one（無人）: 誰もプラグインをデバッグできない\n​\nプラグインの更新\n\nDifyプラットフォームの右上にある「プラグイン」ボタンをクリックし、更新が必要なプラグインを選択。その後、プラグインタイトルの隣にある 「アップグレード」 ボタンをクリックしてください。\n\n​\nプラグインの削除方法\n\nDifyプラットフォームの右上にある「プラグイン」ボタンをクリックし、現在ワークスペースにインストールされているプラグイン一覧を表示します。プラグインの詳細ページで、「削除」アイコンまたは「削除」ボタンをクリックして、プラグインを削除してください。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nプラグインのデバッグ方法\nSchema definition\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nプラグイン権限の設定\nプラグインの更新\nプラグインの削除方法",
        "error": null
      },
      {
        "link_index": 14,
        "link_text": "Schema definition",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nTermbase\nスキーマ仕様\nCopy page\nmanifest.md\n\nmanifest.md\n\nendpoint.md\n\nendpoint.md\n\nmodel.md\n\nmodel.md\n\ngeneral-specifications.md\n\ngeneral-specifications.md\n\npersistent-storage.md\n\npersistent-storage.md\n\nreverse-invocation-of-the-dify-service\n\nreverse-invocation-of-the-dify-service\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify",
        "error": null
      },
      {
        "link_index": 15,
        "link_text": "Manifest(マニフェスト)",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/manifest",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nスキーマ仕様\nManifest(マニフェスト)\nCopy page\n\nマニフェストファイル マニフェストファイルとは、プラグインに関する最も基本的な情報を定義するYAML形式のファイルです。プラグイン名、作成者、含まれるツールやモデルなどの情報が含まれます。\n\nこのファイルの形式が正しくないと、プラグインの解析とパッケージング処理は失敗します。\n\n​\nコード例\n\n以下は、マニフェストファイルの簡単な例です。各データ要素の意味と機能については、以下で説明します。他のプラグインコードについては、Githubリポジトリ を参照してください。\n\nCopy\nversion: 0.0.1\ntype: \"plugin\"\nauthor: \"Yeuoly\"\nname: \"neko\"\nlabel:\n  en_US: \"Neko\"\ncreated_at: \"2024-07-12T08:03:44.658609186Z\"\nicon: \"icon.svg\"\nresource:\n  memory: 1048576\n  permission:\n    tool:\n      enabled: true\n    model:\n      enabled: true\n      llm: true\n    endpoint:\n      enabled: true\n    app:\n      enabled: true\n    storage: \n      enabled: true\n      size: 1048576\nplugins:\n  endpoints:\n    - \"provider/neko.yaml\"\nmeta:\n  version: 0.0.1\n  arch:\n    - \"amd64\"\n    - \"arm64\"\n  runner:\n    language: \"python\"\n    version: \"3.11\"\n    entrypoint: \"main\"\n\n​\nバージョン管理\n\nプラグインのバージョンは、マニフェストファイルのversionフィールドで管理されます。バージョン番号はmajor.minor.patchの形式である必要があります。そうでない場合、自動更新が期待どおりに動作しない可能性があります。\n\n​\n構造\nversion (version、required): プラグインのバージョン\ntype (type、required): プラグインの種類。現在はpluginのみをサポートしており、将来的にはbundleをサポート予定\nauthor (string、required): 作成者。マーケットプレイスでは組織名として扱われます\nlabel (label、required): 多言語対応の名前\ncreated_at (RFC3339、required): 作成時間。マーケットプレイスでは現在時刻より後の日時であってはなりません\nicon (アセット、required): アイコンのパス\nresource (object): 必要なリソース設定\nmemory (int64): 最大メモリ使用量。主にSaaS上のAWS Lambdaリソースリクエストに関連し、単位はバイト\npermission (object): 権限設定\ntool (object): ツール呼び出しの権限\nenabled (bool)\nmodel (object): モデル呼び出しの権限\nenabled (bool)\nllm (bool)\ntext_embedding (bool)\nrerank (bool)\ntts (bool)\nspeech2text (bool)\nmoderation (bool)\nnode (object): ノード呼び出しの権限\nenabled (bool)\nendpoint (object): エンドポイント登録の権限\nenabled (bool)\napp (object): アプリ呼び出しの権限\nenabled (bool)\nstorage (object): 永続ストレージの権限\nenabled (bool)\nsize (int64): 最大許容永続メモリサイズ（バイト単位）\nplugins (object、required): プラグインの機能を定義するYAMLファイルのリスト。プラグインパッケージ内の絶対パスで指定\n形式：\ntools (list[string]): 拡張されたツールプロバイダ\nmodels (list[string]): 拡張されたモデルプロバイダ\nendpoints (list[string]): 拡張されたエンドポイントプロバイダ\nagent_strategies (list[string]): 拡張されたエージェント戦略プロバイダ\n制限：\nツールとモデルの両方を同時に拡張することはできません。\n少なくとも1つの拡張が必要です。\nモデルとエンドポイントの両方を同時に拡張することはできません。\n現在、拡張タイプごとに1つのプロバイダのみをサポートしています。\nmeta (object): メタ情報\nversion (version、required): マニフェスト形式のバージョン。初期バージョンは0.0.1\narch (list[string]、required): サポートされるアーキテクチャ。現在はamd64とarm64のみ\nrunner (object、required): ランタイム設定\nlanguage (string): 現在はPythonのみをサポート\nversion (string): 言語バージョン。現在は3.12のみをサポート\nentrypoint (string): プログラムのエントリポイント。Pythonの場合はmainである必要があります。\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nSchema definition\nEndpoint（エンドポイント）\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nコード例\nバージョン管理\n構造",
        "error": null
      },
      {
        "link_index": 16,
        "link_text": "Endpoint（エンドポイント）",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/endpoint",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nスキーマ仕様\nEndpoint（エンドポイント）\nCopy page\n\nこの記事では、プラグイン内のエンドポイントの構造を説明するために、クイックスタート：レインボーキャットプロジェクトを例として取り上げます。完全なプラグインコードは、Githubで確認できます。\n\n​\nグループの定義\n\nEndpointグループは、複数のEndpointをまとめたものです。Difyプラグインで新しいEndpointを作成する際には、以下の設定項目を入力する必要があります。\n\n「Endpoint Name」の他に、グループ構成情報を記述することで、新しいフォーム項目を追加できます。保存すると、同じ構成情報を使用する複数のインターフェースが表示されるようになります。\n\n​\n構造\nsettings (map[string] ProviderConfig): エンドポイントの設定定義\nendpoints (list[string], required): 特定のendpointインターフェース定義を指定します。\nCopy\nsettings:\n  api_key:\n    type: secret-input\n    required: true\n    label:\n      en_US: API key\n      zh_Hans: API key\n      ja_Jp: API key\n      pt_BR: API key\n    placeholder:\n      en_US: Please input your API key\n      zh_Hans: 请输入你的 API key\n      ja_Jp: あなたの API key を入れてください\n      pt_BR: Por favor, insira sua chave API\nendpoints:\n  - endpoints/duck.yaml\n  - endpoints/neko.yaml\n\n​\nインターフェース定義\npath (string): werkzeugのインターフェース標準に従います。\nmethod (string): インターフェースのメソッド。HEAD GET POST PUT DELETE OPTIONSのみをサポートします。\nextra (object): 基本情報以外の設定情報\npython (object)\nsource (string): このインターフェースを実装するソースコード\nCopy\npath: \"/duck/<app_id>\"\nmethod: \"GET\"\nextra:\n  python:\n    source: \"endpoints/duck.py\"\n\n​\nエンドポイントの実装\n\ndify_plugin.Endpointを継承したサブクラスを実装し、_invokeメソッドを実装する必要があります。\n\n入力パラメータ\nr (Request): werkzeugからのリクエストオブジェクト\nvalues (Mapping): パスから解析されたパスパラメータ\nsettings (Mapping): このエンドポイントの設定情報\n戻り値\nwerkzeugからのレスポンスオブジェクト。ストリーミングでの応答をサポートします。\n直接的な文字列の戻り値はサポートしません。\n\nコード例:\n\nCopy\nimport json\nfrom typing import Mapping\nfrom werkzeug import Request, Response\nfrom dify_plugin import Endpoint\n\nclass Duck(Endpoint):\n    def _invoke(self, r: Request, values: Mapping, settings: Mapping) -> Response:\n        \"\"\"\n        Invokes the endpoint with the given request.\n        \"\"\"\n        app_id = values[\"app_id\"]\n        def generator():\n            yield f\"{app_id} <br>\"\n        return Response(generator(), status=200, content_type=\"text/html\")\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nManifest(マニフェスト)\nTool(ツール)\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nグループの定義\n構造\nインターフェース定義\nエンドポイントの実装",
        "error": null
      },
      {
        "link_index": 17,
        "link_text": "Tool(ツール)",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/tool",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nスキーマ仕様\nTool(ツール)\nCopy page\n\n詳細なインターフェースドキュメントを読む前に、クイックスタート：ツール を参照し、Difyプラグインにおけるツールの利用プロセスについて、概要を把握しておいてください。\n\n​\nデータ構造\n​\nメッセージの出力\n\nDifyは、text、links、images、file BLOBs、JSONといった複数のメッセージタイプをサポートしています。様々なインターフェースを通じて、これらの異なるタイプのメッセージを出力できます。\n\nデフォルトでは、ワークフロー内でツールが出力する際には、files、text、jsonという3つの固定の変数が用意されています。これらの変数にデータを設定するには、以下のメソッドを使用します。\n\n例えば、create_image_messageを使用すると、画像を出力できます。また、ツールはワークフロー内で参照しやすいように、カスタムの出力変数もサポートしています。\n\n​\n画像URL\n\n画像のURLを渡すだけで、Difyが自動的に画像をダウンロードし、ユーザーに送信します。\n\nCopy\ndef create_image_message(self, image: str) -> ToolInvokeMessage:\n    pass\n\n​\nリンク\n\nリンクを出力するには、このインターフェースを使用します。\n\nCopy\ndef create_link_message(self, link: str) -> ToolInvokeMessage:\n    pass\n\n​\nテキスト\n\nテキストメッセージを出力するには、このインターフェースを使用します。\n\nCopy\ndef create_text_message(self, text: str) -> ToolInvokeMessage:\n    pass\n\n​\nファイル\n\n生のファイルデータ（画像、音声、動画、PPT、Word、Excelなど）を出力するには、このインターフェースを使用します。\n\nblob: バイト形式の生ファイルデータ\nmeta: ファイルのメタデータです。mime_typeを指定することで、ファイルの種類を明示できます。指定しない場合は、Difyがデフォルトでoctet/streamを使用します。\nCopy\ndef create_blob_message(self, blob: bytes, meta: dict = None) -> ToolInvokeMessage:\n    pass\n\n​\nJSON\n\nフォーマットされたJSONを出力するには、このインターフェースを使用します。通常、ワークフロー内のノード間でデータをやり取りする際に使用されます。多くの大規模言語モデルは、エージェントモードでJSON形式のデータを読み取り、理解できます。\n\nCopy\ndef create_json_message(self, json: dict) -> ToolInvokeMessage:\n    pass\n\n​\n変数\n\nストリーミングではない出力変数を設定するには、このインターフェースを使用します。後から設定された値は、以前の設定値を上書きします。\n\nCopy\ndef create_variable_message(self, variable_name: str, variable_value: Any) -> ToolInvokeMessage:\n    pass\n\n​\nストリーミング変数\n\nテキストをタイプライターのように表示するには、ストリーミング変数を使用します。チャットフローアプリケーションの応答ノードでこの変数を参照すると、テキストがタイプライター効果で表示されます。現在、文字列データのみをサポートしています。\n\nCopy\ndef create_stream_variable_message(\n    self, variable_name: str, variable_value: str\n) -> ToolInvokeMessage:\n\n​\n出力変数の定義\n\nワークフロー内でツールの出力変数を参照するには、事前に出力される可能性のある変数を定義しておく必要があります。Difyプラグインは、json_schema形式での出力変数定義をサポートしています。以下に設定例を示します。\n\nCopy\nidentity:\n  author: author\n  name: tool\n  label:\n    en_US: label\n    zh_Hans: 标签\n    ja_JP: レベル\n    pt_BR: etiqueta\ndescription:\n  human:\n    en_US: description\n    zh_Hans: 描述\n    ja_JP: 説明\n    pt_BR: descrição\n  llm: description\noutput_schema:\n  type: object\n  properties:\n    name:\n      type: string\n\n\nこの例では、ワークフロー内で参照できる name フィールドを含む output_schema を持つシンプルなツールを定義しています。実際に使用するには、ツールの実装コード内で変数を設定する必要があることに注意してください。そうしないと、None が設定されます。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nEndpoint（エンドポイント）\nAgent(エージェント)\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nデータ構造\nメッセージの出力\n画像URL\nリンク\nテキスト\nファイル\nJSON\n変数\nストリーミング変数\n出力変数の定義",
        "error": null
      },
      {
        "link_index": 18,
        "link_text": "Agent(エージェント)",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/agent",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nスキーマ仕様\nAgent(エージェント)\nCopy page\n\nエージェント戦略の概要\n\nエージェント戦略とは、標準的な入力コンテンツと出力形式を定義する拡張可能なテンプレートです。特定のエージェント戦略インターフェースを開発することで、CoT（Chain of Thought：思考の連鎖）、ToT（Tree of Thought：思考の木）、GoT（Graph of Thought：思考のグラフ）、BoT（Backbone of Thought：思考のバックボーン）といった様々なエージェント戦略を実装したり、Semantic Kernel のような複雑な戦略を実現したりできます。\n\n​\nマニフェストへのフィールド追加\n\nプラグインにエージェント戦略を追加するには、manifest.yamlファイルにplugins.agent_strategiesフィールドを追加し、エージェントプロバイダーを定義します。以下にコード例を示します。\n\nversion: 0.0.2\ntype: plugin\nauthor: \"langgenius\"\nname: \"agent\"\nplugins:\n  agent_strategies:\n    - \"provider/agent.yaml\"\n\n\nマニフェストファイル内の関連性のないフィールドは省略されています。詳細なマニフェスト形式については、Manifestを参照してください。\n\n​\nエージェントプロバイダーの定義\n\n基本的なエージェントプロバイダー情報を含むagent.yamlファイルを作成します。\n\nidentity:\n  author: langgenius\n  name: agent\n  label:\n    en_US: Agent\n    zh_Hans: Agent\n    pt_BR: Agent\n  description:\n    en_US: Agent\n    zh_Hans: Agent\n    pt_BR: Agent\n  icon: icon.svg\nstrategies:\n  - strategies/function_calling.yaml\n\n​\nエージェント戦略の定義と実装\n​\n定義\n\nエージェント戦略のコードを定義するために、function_calling.yamlファイルを作成します。\n\nidentity:\n  name: function_calling\n  author: Dify\n  label:\n    en_US: FunctionCalling\n    zh_Hans: FunctionCalling\n    pt_BR: FunctionCalling\ndescription:\n  en_US: Function Calling is a basic strategy for agent, model will use the tools provided to perform the task.\nparameters:\n  - name: model\n    type: model-selector\n    scope: tool-call&llm\n    required: true\n    label:\n      en_US: Model\n  - name: tools\n    type: array[tools]\n    required: true\n    label:\n      en_US: Tools list\n  - name: query\n    type: string\n    required: true\n    label:\n      en_US: Query\n  - name: max_iterations\n    type: number\n    required: false\n    default: 5\n    label:\n      en_US: Max Iterations\n    max: 50\n    min: 1\nextra:\n  python:\n    source: strategies/function_calling.py\n\n\nこのコード形式はToolの標準形式に似ており、最も基本的なエージェント戦略を実装するために、model、tools、query、max_iterationsの4つのパラメーターを定義しています。これにより、ユーザーは以下のことが可能になります。\n\n使用するモデルを選択する\n利用するツールを選択する\n最大反復回数を設定する\nエージェントの実行を開始するためのクエリを入力する\n\nこれらのパラメーターはすべて連携して、エージェントがタスクを処理し、選択されたツールやモデルとどのように対話するかを定義します。\n\n​\n機能実装\n\nパラメーターの取得\n\n前述の4つのパラメーターに基づき、モデルタイプのパラメーターはmodel-selector、ツールタイプのパラメーターは特別なarray[tools]です。取得したパラメーターは、SDKに組み込まれているAgentModelConfigとlist[ToolEntity]を使用して変換できます。\n\nfrom dify_plugin.interfaces.agent import AgentModelConfig, AgentStrategy, ToolEntity\n\nclass FunctionCallingParams(BaseModel):\n    query: str\n    model: AgentModelConfig\n    tools: list[ToolEntity] | None\n    maximum_iterations: int = 3\n    \n class FunctionCallingAgentStrategy(AgentStrategy):\n    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:\n        \"\"\"\n        Run FunctionCall agent application\n        \"\"\"\n        fc_params = FunctionCallingParams(**parameters)\n\n\nモデルの呼び出し\n\n特定モデルの呼び出しは、エージェントプラグインの不可欠な機能です。SDKのsession.model.invoke()関数を使用してモデルを呼び出します。必要な入力パラメーターはモデルから取得できます。\n\nモデルを呼び出すメソッドの例：\n\ndef invoke(\n        self,\n        model_config: LLMModelConfig,\n        prompt_messages: list[PromptMessage],\n        tools: list[PromptMessageTool] | None = None,\n        stop: list[str] | None = None,\n        stream: bool = True,\n    ) -> Generator[LLMResultChunk, None, None] | LLMResult:\n\n\nモデル情報（model_config）、プロンプト情報（prompt_messages）、ツール情報（tools）を渡す必要があります。prompt_messagesパラメーターは以下のコード例を参照できますが、tool_messagesには特定の変換が必要です。\n\nモデル呼び出しのコード例を参照してください。\n\nfrom collections.abc import Generator\nfrom typing import Any\n\nfrom pydantic import BaseModel\n\nfrom dify_plugin.entities.agent import AgentInvokeMessage\nfrom dify_plugin.entities.model.llm import LLMModelConfig\nfrom dify_plugin.entities.model.message import (\n    PromptMessageTool,\n    SystemPromptMessage,\n    UserPromptMessage,\n)\nfrom dify_plugin.entities.tool import ToolParameter\nfrom dify_plugin.interfaces.agent import AgentModelConfig, AgentStrategy, ToolEntity\n\nclass FunctionCallingParams(BaseModel):\n    query: str\n    instruction: str | None\n    model: AgentModelConfig\n    tools: list[ToolEntity] | None\n    maximum_iterations: int = 3\n\nclass FunctionCallingAgentStrategy(AgentStrategy):\n    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:\n        \"\"\"\n        Run FunctionCall agent application\n        \"\"\"\n        # init params\n        fc_params = FunctionCallingParams(**parameters)\n        query = fc_params.query\n        model = fc_params.model\n        stop = fc_params.model.completion_params.get(\"stop\", []) if fc_params.model.completion_params else []\n        prompt_messages = [\n            SystemPromptMessage(content=\"your system prompt message\"),\n            UserPromptMessage(content=query),\n        ]\n        tools = fc_params.tools\n        prompt_messages_tools = self._init_prompt_tools(tools)\n\n        # invoke llm\n        chunks = self.session.model.llm.invoke(\n            model_config=LLMModelConfig(**model.model_dump(mode=\"json\")),\n            prompt_messages=prompt_messages,\n            stream=True,\n            stop=stop,\n            tools=prompt_messages_tools,\n        )\n\n    def _init_prompt_tools(self, tools: list[ToolEntity] | None) -> list[PromptMessageTool]:\n        \"\"\"\n        Init tools\n        \"\"\"\n\n        prompt_messages_tools = []\n        for tool in tools or []:\n            try:\n                prompt_tool = self._convert_tool_to_prompt_message_tool(tool)\n            except Exception:\n                # api tool may be deleted\n                continue\n\n            # save prompt tool\n            prompt_messages_tools.append(prompt_tool)\n\n        return prompt_messages_tools\n\n    def _convert_tool_to_prompt_message_tool(self, tool: ToolEntity) -> PromptMessageTool:\n        \"\"\"\n        convert tool to prompt message tool\n        \"\"\"\n        message_tool = PromptMessageTool(\n            name=tool.identity.name,\n            description=tool.description.llm if tool.description else \"\",\n            parameters={\n                \"type\": \"object\",\n                \"properties\": {},\n                \"required\": [],\n            },\n        )\n\n        parameters = tool.parameters\n        for parameter in parameters:\n            if parameter.form != ToolParameter.ToolParameterForm.LLM:\n                continue\n\n            parameter_type = parameter.type\n            if parameter.type in {\n                ToolParameter.ToolParameterType.FILE,\n                ToolParameter.ToolParameterType.FILES,\n            }:\n                continue\n            enum = []\n            if parameter.type == ToolParameter.ToolParameterType.SELECT:\n                enum = [option.value for option in parameter.options] if parameter.options else []\n\n            message_tool.parameters[\"properties\"][parameter.name] = {\n                \"type\": parameter_type,\n                \"description\": parameter.llm_description or \"\",\n            }\n\n            if len(enum) > 0:\n                message_tool.parameters[\"properties\"][parameter.name][\"enum\"] = enum\n\n            if parameter.required:\n                message_tool.parameters[\"required\"].append(parameter.name)\n\n        return message_tool\n\n\nツールの呼び出し\n\nツールの呼び出しも、エージェントプラグインの重要な機能です。ツールを呼び出すには、self.session.tool.invoke()を使用します。\n\nツールを呼び出すメソッドの例：\n\ndef invoke(\n        self,\n        provider_type: ToolProviderType,\n        provider: str,\n        tool_name: str,\n        parameters: dict[str, Any],\n    ) -> Generator[ToolInvokeMessage, None, None]\n\n\n必要なパラメーターには、provider_type、provider、tool_name、parametersが含まれます。通常、tool_nameとparametersは関数呼び出し中にLLMによって生成されます。\n\nツールを呼び出すコード例：\n\nfrom dify_plugin.entities.tool import ToolProviderType\n\nclass FunctionCallingAgentStrategy(AgentStrategy):\n    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:\n        \"\"\"\n        Run FunctionCall agent application\n        \"\"\"\n        fc_params = FunctionCallingParams(**parameters)\n        \n        # tool_call_name と tool_call_args パラメータはLLMの出力から取得されます。\n        tool_instances = {tool.identity.name: tool for tool in fc_params.tools} if fc_params.tools else {}\n        tool_instance = tool_instances[tool_call_name]\n        tool_invoke_responses = self.session.tool.invoke(\n            provider_type=ToolProviderType.BUILT_IN,\n            provider=tool_instance.identity.provider,\n            tool_name=tool_instance.identity.name,\n            # デフォルト値を追加\n            parameters={**tool_instance.runtime_parameters, **tool_call_args},\n        )\n\n\nself.session.tool.invoke()関数の出力はジェネレーターであり、ストリーム解析が必要です。\n\n解析については、以下の関数を参照してください。\n\nimport json\nfrom collections.abc import Generator\nfrom typing import cast\n\nfrom dify_plugin.entities.agent import AgentInvokeMessage\nfrom dify_plugin.entities.tool import ToolInvokeMessage\n\ndef parse_invoke_response(tool_invoke_responses: Generator[AgentInvokeMessage]) -> str:\n    result = \"\"\n    for response in tool_invoke_responses:\n        if response.type == ToolInvokeMessage.MessageType.TEXT:\n            result += cast(ToolInvokeMessage.TextMessage, response.message).text\n        elif response.type == ToolInvokeMessage.MessageType.LINK:\n            result += (\n                f\"result link: {cast(ToolInvokeMessage.TextMessage, response.message).text}.\"\n                + \" please tell user to check it.\"\n            )\n        elif response.type in {\n            ToolInvokeMessage.MessageType.IMAGE_LINK,\n            ToolInvokeMessage.MessageType.IMAGE,\n        }:\n            result += (\n                \"image has been created and sent to user already, \"\n                + \"you do not need to create it, just tell the user to check it now.\"\n            )\n        elif response.type == ToolInvokeMessage.MessageType.JSON:\n            text = json.dumps(cast(ToolInvokeMessage.JsonMessage, response.message).json_object, ensure_ascii=False)\n            result += f\"tool response: {text}.\"\n        else:\n            result += f\"tool response: {response.message!r}.\"\n    return result\n\n\nログ\n\nエージェントの思考プロセスを表示するために、通常のメッセージの戻り値に加えて、専用のインターフェースを使用して、エージェントの思考プロセス全体をツリー構造で表示できます。\n\nログの作成\n\nこのインターフェースは、ログツリー内のノードを表すAgentLogMessageを作成して返します。\n親が渡された場合、このノードに親ノードがあることを示します。\nデフォルトのステータスは「Success」です。ただし、タスク実行プロセスをより適切に表示したい場合は、最初にステータスを「start」に設定して「進行中」のログを表示し、タスク完了後にログステータスを「Success」に更新できます。これにより、ユーザーは最初から最後までプロセス全体を明確に把握できます。\nラベルは、ユーザーに表示されるログタイトルとして使用されます。\ndef create_log_message(\n    self,\n    label: str,\n    data: Mapping[str, Any],\n    status: AgentInvokeMessage.LogMessage.LogStatus = AgentInvokeMessage.LogMessage.LogStatus.SUCCESS,\n    parent: AgentInvokeMessage | None = None,\n) -> AgentInvokeMessage\n\n\nログの完了\n\n以前に初期ステータスとして「start」を設定した場合、ログ完了エンドポイントを使用してステータスを変更できます。\n\ndef finish_log_message(\n    self,\n    log: AgentInvokeMessage,\n    status: AgentInvokeMessage.LogMessage.LogStatus = AgentInvokeMessage.LogMessage.LogStatus.SUCCESS,\n    error: Optional[str] = None,\n) -> AgentInvokeMessage\n\n\n実装例\n\nこの例では、簡単な2段階の実行プロセスを示します。最初に「考え中」の状態のログを出力し、次に実際のタスク処理を完了します。\n\nclass FunctionCallingAgentStrategy(AgentStrategy):\n    def _invoke(self, parameters: dict[str, Any]) -> Generator[AgentInvokeMessage]:\n        thinking_log = self.create_log_message(\n            data={\"Query\": parameters.get(\"query\")},\n            label=\"Thinking\",\n            status=AgentInvokeMessage.LogMessage.LogStatus.START,\n        )\n\n        yield thinking_log\n\n        llm_response = self.session.model.llm.invoke(\n            model_config=LLMModelConfig(\n                provider=\"openai\",\n                model=\"gpt-4o-mini\",\n                mode=\"chat\",\n                completion_params={},\n            ),\n            prompt_messages=[\n                SystemPromptMessage(content=\"you are a helpful assistant\"),\n                UserPromptMessage(content=parameters.get(\"query\")),\n            ],\n            stream=False,\n            tools=[],\n        )\n\n        thinking_log = self.finish_log_message(log=thinking_log)\n        yield thinking_log\n        yield self.create_text_message(text=llm_response.message.content)\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nTool(ツール)\nModel\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nマニフェストへのフィールド追加\nエージェントプロバイダーの定義\nエージェント戦略の定義と実装\n定義\n機能実装",
        "error": null
      },
      {
        "link_index": 19,
        "link_text": "Model",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/model",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nTermbase\nModel(モデル)\nCopy page\n\nモデルインターフェースには以下の内容が含まれます：\n\nモデル設計ルール.md\n\nモデル設計ルール.md\n\nモデルスキーマ.md\n\nモデルスキーマ.md\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify",
        "error": null
      },
      {
        "link_index": 20,
        "link_text": "モデル設計規則",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/model/model-designing-rules",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\nModel\nモデル設計規則\nモデルスキーマ\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nModel\nモデル設計規則\nCopy page\nモデルプロバイダーのルールは、Provider エンティティに基づいています。\nモデルルールは、AIModelEntity エンティティに基づいています。\n\n以下のすべてのエンティティは Pydantic BaseModel をベースにしており、entities モジュール内で対応するエンティティを見つけることができます。\n\n​\nProvider（プロバイダ）\nprovider (string) プロバイダー識別子。例：openai\nlabel (object) プロバイダーの表示名。多言語対応で、英語（en_US）と中国語（zh_Hans）の2言語を設定できます。\nzh_Hans (string) [optional] 中国語のラベル名。zh_Hans が設定されていない場合は、デフォルトで en_US が使用されます。\nen_US (string) 英語のラベル名\ndescription (object) [optional] プロバイダーの説明。多言語対応。\nzh_Hans (string) [optional] 中国語の説明\nen_US (string) 英語の説明\nicon_small (string) [optional] プロバイダーの小さなアイコン。対応するプロバイダーの実装ディレクトリ下の _assets ディレクトリに保存されます。英語と中国語の扱い方は label と同様です。\nzh_Hans (string) [optional] 中国語のアイコン\nen_US (string) 英語のアイコン\nicon_large (string) [optional] プロバイダーの大きなアイコン。対応するプロバイダーの実装ディレクトリ下の _assets ディレクトリに保存されます。英語と中国語の扱い方は label と同様です。\nzh_Hans (string) [optional] 中国語のアイコン\nen_US (string) 英語のアイコン\nbackground (string) [optional] 背景色のカラーコード。例：#FFFFFF。値が設定されていない場合は、フロントエンドのデフォルト色が使用されます。\nhelp (object) [optional] ヘルプ情報\ntitle (object) ヘルプタイトル。多言語対応。\nzh_Hans (string) [optional] 中国語のタイトル\nen_US (string) 英語のタイトル\nurl (object) ヘルプリンク。多言語対応。\nzh_Hans (string) [optional] 中国語のリンク\nen_US (string) 英語のリンク\nsupported_model_types (array[ModelType]) サポートされているモデルタイプ\nconfigurate_methods (array[ConfigurateMethod]) 設定方法\nprovider_credential_schema ([ProviderCredentialSchema]) プロバイダーの認証情報スキーマ（プロバイダーの資格情報仕様）\nmodel_credential_schema ([ModelCredentialSchema]) モデルの認証情報スキーマ（モデルの資格情報仕様）\n​\nAIModelEntity（AIモデルエンティティ）\nmodel (string) モデル識別子。例：gpt-3.5-turbo\nlabel (object) [optional] モデルの表示名。多言語対応で、英語（en_US）と中国語（zh_Hans）の2言語を設定できます。\nzh_Hans (string) [optional] 中国語のラベル名\nen_US (string) 英語のラベル名\nmodel_type ([ModelType](#ModelType)) モデルタイプ\nfeatures (array[[ModelFeature](#ModelFeature)]) [optional] サポートされている機能リスト\nmodel_properties (object) モデルのプロパティ\nmode ([LLMMode](#LLMMode)) モード（モデルタイプ llm で利用可能）\ncontext_size (int) コンテキストサイズ（モデルタイプ llm、text-embedding で利用可能）\nmax_chunks (int) 最大チャンク数（モデルタイプ text-embedding、moderation で利用可能）\nfile_upload_limit (int) ファイルの最大アップロード制限（単位：MB）。（モデルタイプ speech2text で利用可能）\nsupported_file_extensions (string) サポートされているファイル拡張子形式。例：mp3、mp4（モデルタイプ speech2text の場合）\ndefault_voice (string) デフォルトのボイス。必須：alloy,echo,fable,onyx,nova,shimmer（モデルタイプ tts で利用可能）\nvoices (list) 選択可能なボイスリスト。\nmode (string) ボイスモデル。（モデルタイプ tts で利用可能）\nname (string) ボイスモデルの表示名。（モデルタイプ tts で利用可能）\nlanguage (string) ボイスモデルがサポートする言語。（モデルタイプ tts で利用可能）\nword_limit (int) 1回の変換における文字数制限。デフォルトでは段落ごとに区切られます。（モデルタイプ tts で利用可能）\naudio_type (string) サポートされているオーディオファイルの拡張子形式。例：mp3、wav（モデルタイプ tts で利用可能）\nmax_workers (int) テキストからオーディオへの変換をサポートする同時実行タスク数。（モデルタイプ tts で利用可能）\nmax_characters_per_chunk (int) 1チャンクあたりの最大文字数（モデルタイプ moderation で利用可能）\nparameter_rules (array[ParameterRule]) [optional] モデル呼び出しパラメータのルール\npricing ([PriceConfig]) [optional] 価格情報\ndeprecated (bool) 非推奨かどうか。非推奨の場合、モデルリストには表示されなくなりますが、すでに設定済みのものは引き続き使用できます。デフォルトは False です。\n​\nModelType（モデルタイプ）\nllm テキスト生成モデル\ntext-embedding テキスト埋め込みモデル\nrerank Rerank モデル\nspeech2text 音声テキスト変換\ntts テキスト音声変換\nmoderation 審査\n​\nConfigurateMethod（構成方法）\npredefined-model 既定モデル\n\nユーザーは、統一されたプロバイダーの認証情報を設定するだけで、プロバイダーの既定モデルを利用できます。\n\ncustomizable-model カスタムモデル\n\nユーザーは、各モデルの認証情報設定を個別に追加する必要があります。\n\nfetch-from-remote リモートから取得\n\npredefined-model の設定方法と同様に、統一されたプロバイダーの認証情報を設定するだけで済みます。モデルは認証情報を通じてプロバイダーから取得されます。\n\n​\nModelFeature（モデル機能）\nagent-thought エージェントの推論。通常、70B を超えるモデルには思考連鎖能力があります。\nvision ビジョン、つまり画像理解。\ntool-call ツール呼び出し\nmulti-tool-call 複数ツール呼び出し\nstream-tool-call ストリームツール呼び出し\n​\nFetchFrom（入手先）\npredefined-model 既定モデル\nfetch-from-remote リモートモデル\n​\nLLMMode（LLMモード）\ncompletion テキスト補完\nchat 対話\n​\nParameterRule（パラメータールール）\nname (string) モデルを呼び出す際の実際のパラメータ名\nuse_template (string) [optional] テンプレートを使用\n\nデフォルトでは、5つの変数設定テンプレートが用意されています。\n\ntemperature\ntop_p\nfrequency_penalty\npresence_penalty\nmax_tokens\n\nuse_template でテンプレート変数名を直接設定すると、entities.defaults.PARAMETER_RULE_TEMPLATE のデフォルト設定が使用され、name と use_template 以外のすべてのパラメータを設定する必要はありません。追加の設定パラメータを設定した場合、デフォルト設定が上書きされます。openai/llm/gpt-3.5-turbo.yaml を参照してください。\n\nlabel (object) [optional] ラベル。多言語対応。\nzh_Hans (string) [optional] 中国語のラベル名\nen_US (string) 英語のラベル名\ntype (string) [optional] パラメータのタイプ\nint 整数\nfloat 浮動小数点数\nstring 文字列\nboolean ブール型\nhelp (string) [optional] ヘルプ情報\nzh_Hans (string) [optional] 中国語のヘルプ情報\nen_US (string) 英語のヘルプ情報\nrequired (bool) 必須かどうか。デフォルトは False です。\ndefault (int/float/string/bool) [optional] デフォルト値\nmin (int/float) [optional] 最小値。数値型のみ適用。\nmax (int/float) [optional] 最大値。数値型のみ適用。\nprecision (int) [optional] 精度。小数点以下の桁数。数値型のみ適用。\noptions (array[string]) [optional] ドロップダウンの選択肢。type が string の場合にのみ適用。設定しない、または null の場合は選択肢を制限しません。\n​\nPriceConfig（価格設定）\ninput (float) 入力単価。つまり、Prompt の単価。\noutput (float) 出力単価。つまり、返される内容の単価。\nunit (float) 価格単位。例：1M トークン単位で価格設定する場合、単価に対応するトークン数は 0.000001 になります。\ncurrency (string) 通貨単位\n​\nProviderCredentialSchema（プロバイダー資格情報スキーマ）\ncredential_form_schemas (array[CredentialFormSchema]) 資格情報フォームの仕様\n​\nModelCredentialSchema（モデル認証情報スキーマ）\nmodel (object) モデル識別子。変数名はデフォルトで model です。\nlabel (object) モデルフォーム項目の表示名\nen_US (string) 英語\nzh_Hans (string) [optional] 中国語\nplaceholder (object) モデルのプレースホルダー\nen_US (string) 英語\nzh_Hans (string) [optional] 中国語\ncredential_form_schemas (array[CredentialFormSchema]) 資格情報フォームの仕様\n​\nCredentialFormSchema（資格情報フォームスキーマ）\nvariable (string) フォーム項目の変数名\nlabel (object) フォーム項目のラベル名\nen_US (string) 英語\nzh_Hans (string) [optional] 中国語\ntype ([FormType](#FormType)) フォーム項目のタイプ\nrequired (bool) 必須かどうか\ndefault (string) デフォルト値\noptions (array[FormOption]) フォーム項目が select または radio の場合の専用属性。ドロップダウンの内容を定義します。\nplaceholder (object) フォーム項目が text-input の場合の専用属性。フォーム項目のプレースホルダー。\nen_US (string) 英語\nzh_Hans (string) [optional] 中国語\nmax_length (int) フォーム項目が text-input の場合の専用属性。入力の最大長を定義します。0 は制限なし。\nshow_on (array[FormShowOnObject]) 他のフォーム項目の値が条件を満たす場合に表示します。空の場合は常に表示します。\n​\nFormType（フォームタイプ）\ntext-input テキスト入力コンポーネント\nsecret-input パスワード入力コンポーネント\nselect 単一選択ドロップダウン\nradio ラジオコンポーネント\nswitch スイッチコンポーネント。true と false のみをサポート。\n​\nFormOption（フォームオプション）\nlabel (object) ラベル\nen_US (string) 英語\nzh_Hans (string) [optional] 中国語\nvalue (string) ドロップダウンの選択肢の値\nshow_on (array[FormShowOnObject]) 他のフォーム項目の値が条件を満たす場合に表示します。空の場合は常に表示します。\n​\nFormShowOnObject（フォーム表示オブジェクト）\nvariable (string) 他のフォーム項目の変数名\nvalue (string) 他のフォーム項目の値\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nModel\nモデルスキーマ\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nProvider（プロバイダ）\nAIModelEntity（AIモデルエンティティ）\nModelType（モデルタイプ）\nConfigurateMethod（構成方法）\nModelFeature（モデル機能）\nFetchFrom（入手先）\nLLMMode（LLMモード）\nParameterRule（パラメータールール）\nPriceConfig（価格設定）\nProviderCredentialSchema（プロバイダー資格情報スキーマ）\nModelCredentialSchema（モデル認証情報スキーマ）\nCredentialFormSchema（資格情報フォームスキーマ）\nFormType（フォームタイプ）\nFormOption（フォームオプション）\nFormShowOnObject（フォーム表示オブジェクト）",
        "error": null
      },
      {
        "link_index": 21,
        "link_text": "モデルスキーマ",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/model/model-schema",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\nModel\nモデル設計規則\nモデルスキーマ\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nModel\nモデルスキーマ\nCopy page\n\nここでは、プロバイダーと各モデルタイプが実装する必要があるインターフェースメソッドとパラメータについて説明します。\n\n​\nモデルプロバイダー\n\n__base.model_provider.ModelProvider 基底クラスを継承し、以下のインターフェースを実装します。\n\nCopy\ndef validate_provider_credentials(self, credentials: dict) -> None:\n    \"\"\"\n    Validate provider credentials\n    You can choose any validate_credentials method of model type or implement validate method by yourself,\n    such as: get model list api\n\n    if validate failed, raise exception\n\n    :param credentials: provider credentials, credentials form defined in `provider_credential_schema`.\n    \"\"\"\n\ncredentials (object): 認証情報\n\n認証情報のパラメータは、サプライヤーの YAML 設定ファイルの provider_credential_schemaで定義され、api_keyなどが渡されます。検証に失敗した場合は、errors.validate.CredentialsValidateFailedErrorエラーを発生させてください。注: プリ定義モデルはこのインターフェースを完全に実装する必要があります。カスタムモデルサプライヤーは、以下のような簡単な実装で十分です。\n\nCopy\nclass XinferenceProvider(Provider):\n    def validate_provider_credentials(self, credentials: dict) -> None:\n        pass\n\n​\nモデル\n\nモデルは5つの異なるモデルタイプに分類され、異なるモデルタイプは異なる基底クラスを継承し、実装する必要があるメソッドも異なります。\n\n​\n共通インターフェース\n\nすべてのモデルは、以下の2つのメソッドを共通して実装する必要があります。\n\nモデル認証情報の検証\n\nサプライヤーの認証情報検証と同様に、ここでは個々のモデルに対して検証を行います。\n\nCopy\ndef validate_credentials(self, model: str, credentials: dict) -> None:\n    \"\"\"\n    Validate model credentials\n\n    :param model: model name\n    :param credentials: model credentials\n    :return:\n    \"\"\"\n\n\nパラメータ:\n\nmodel (string): モデル名\ncredentials (object): 認証情報\n\n認証情報のパラメータは、サプライヤーの YAML 設定ファイルのprovider_credential_schemaまたはmodel_credential_schemaで定義され、api_keyなどが渡されます。検証に失敗した場合は、errors.validate.CredentialsValidateFailedErrorエラーを発生させてください。\n\n呼び出しエラーのマッピング\n\nモデルの呼び出し中に例外が発生した場合、Dify が異なるエラーに対して適切な後続処理を実行できるように、Runtime で定義されたInvokeErrorタイプにマッピングする必要があります。Runtime Errors:\n\nInvokeConnectionError: 呼び出し接続エラー\nInvokeServerUnavailableError: 呼び出しサービスが利用不可\nInvokeRateLimitError: 呼び出しがレート制限に達した\nInvokeAuthorizationError: 呼び出し認証失敗\nInvokeBadRequestError: 呼び出しパラメータエラー\nCopy\n@property\ndef _invoke_error_mapping(self) -> dict[type[InvokeError], list[type[Exception]]]:\n    \"\"\"\n    Map model invoke error to unified error\n    The key is the error type thrown to the caller\n    The value is the error type thrown by the model,\n    which needs to be converted into a unified error type for the caller.\n\n    :return: Invoke error mapping\n    \"\"\"\n\n\n対応するエラーを直接発生させ、以下のように定義することもできます。これにより、後続の呼び出しでInvokeConnectionErrorなどの例外を直接発生させることができます。\n\nはい、以下に修正後の翻訳を示します。\n\n​\nLLM\n\n__base.large_language_model.LargeLanguageModel 基底クラスを継承し、以下のインターフェースを実装します：\n\nLLM呼び出し\n\nLLMを呼び出すためのコアメソッドを実装します。ストリーミングと同期の両方の戻り値をサポートします。\n\nCopy\ndef _invoke(self, model: str, credentials: dict,\n            prompt_messages: list[PromptMessage], model_parameters: dict,\n            tools: Optional[list[PromptMessageTool]] = None, stop: Optional[list[str]] = None,\n            stream: bool = True, user: Optional[str] = None) \\\n        -> Union[LLMResult, Generator]:\n    \"\"\"\n    Invoke large language model\n\n    :param model: model name\n    :param credentials: model credentials\n    :param prompt_messages: prompt messages\n    :param model_parameters: model parameters\n    :param tools: tools for tool calling\n    :param stop: stop words\n    :param stream: is stream response\n    :param user: unique user id\n    :return: full response or stream response chunk generator result\n    \"\"\"\n\nパラメータ：\nmodel (string) モデル名\ncredentials (object) クレデンシャル\n\nクレデンシャルのパラメータは、ベンダーのYAML構成ファイルの provider_credential_schema または model_credential_schema で定義され、api_key などが渡されます。\n\nprompt_messages (array[PromptMessage]) プロンプト一覧\n\nモデルが Completion タイプの場合、リストにはUserPromptMessage 要素を1つだけ渡します。モデルが Chat タイプの場合、メッセージに応じてSystemPromptMessage、UserPromptMessage、AssistantPromptMessage、ToolPromptMessage 要素のリストを渡す必要があります。\n\n- model_parameters (object) モデルパラメータ。モデルパラメータは、モデルのYAML構成の parameter_rules で定義されます。\n\n- tools (array[PromptMessageTool]) [optional] ツール一覧。function calling における function と同等です。つまり、ツール呼び出しのためのツール一覧を渡します。\n\n- stop (array[string]) [optional] 停止シーケンス。モデルの出力は、停止シーケンスで定義された文字列の手前で停止します。\n\n- stream (bool) ストリーミング出力かどうか。デフォルトは True です。ストリーミング出力は Generator[LLMResultChunk] を返し、非ストリーミング出力は LLMResult を返します。\n\n- user (string) [optional] ユーザーの一意の識別子。ベンダーが不正行為を監視および検出するのに役立ちます。\n\n戻り値\n\nストリーミング出力は Generator[LLMResultChunk] を返し、非ストリーミング出力は LLMResult を返します。\n\n入力トークンの事前計算\n\nモデルがトークン数の事前計算インターフェースを提供していない場合は、直接0を返します。\n\nCopy\ndef get_num_tokens(self, model: str, credentials: dict, prompt_messages: list[PromptMessage],\n                   tools: Optional[list[PromptMessageTool]] = None) -> int:\n    \"\"\"\n    Get number of tokens for given prompt messages\n\n    :param model: model name\n    :param credentials: model credentials\n    :param prompt_messages: prompt messages\n    :param tools: tools for tool calling\n    :return:\n    \"\"\"\n\n\nパラメータの説明は上記の「LLM呼び出し」を参照してください。このインターフェースは、対応する model に応じて適切な tokenizer を選択して計算する必要があります。対応するモデルが tokenizer を提供していない場合は、AIModel 基底クラスの _get_num_tokens_by_gpt2(text: str) メソッドを使用して計算できます。\n\nカスタマイズ可能なモデルスキーマの取得 [オプション]\nCopy\ndef get_customizable_model_schema(self, model: str, credentials: dict) -> Optional[AIModelEntity]:\n    \"\"\"\n    Get customizable model schema\n\n    :param model: model name\n    :param credentials: model credentials\n    :return: model schema\n    \"\"\"\n\n\nベンダーがカスタムLLMの追加をサポートしている場合、このメソッドを実装してカスタムモデルがモデルスキーマを取得できるようにできます。デフォルトでは None を返します。\n\nOpenAI ベンダーのほとんどのファインチューニングモデルでは、ファインチューニングモデルの名前（例：gpt-3.5-turbo-1106）からその基底クラスモデルを取得し、基底クラスモデルの事前定義されたパラメータルールを返すことができます。具体的な実装については、OpenAI を参照してください。\n\n​\nTextEmbedding\n\n__base.text_embedding_model.TextEmbeddingModel 基底クラスを継承し、以下のインターフェースを実装します。\n\nEmbedding呼び出し\nCopy\ndef _invoke(self, model: str, credentials: dict,\n            texts: list[str], user: Optional[str] = None) \\\n        -> TextEmbeddingResult:\n    \"\"\"\n    Invoke large language model\n\n    :param model: model name\n    :param credentials: model credentials\n    :param texts: texts to embed\n    :param user: unique user id\n    :return: embeddings result\n    \"\"\"\n\nパラメータ：\n\n\n- model (string) モデル名\n\n\n- credentials (object) クレデンシャル\n\nクレデンシャルのパラメータは、ベンダーのYAML構成ファイルの provider_credential_schema または model_credential_schema で定義され、api_key などが渡されます。\n\n\n- texts (array[string]) テキスト一覧。バッチ処理が可能です。\n\n\n- user (string) [optional] ユーザーの一意の識別子。\nベンダーが不正行為を監視および検出するのに役立ちます。\n\n戻り値：\n\nTextEmbeddingResult エンティティ。\n\nトークンの事前計算\nCopy\ndef get_num_tokens(self, model: str, credentials: dict, texts: list[str]) -> int:\n    \"\"\"\n    Get number of tokens for given prompt messages\n\n    :param model: model name\n    :param credentials: model credentials\n    :param texts: texts to embed\n    :return:\n    \"\"\"\n\n\nパラメータの説明は上記の「Embedding呼び出し」を参照してください。\n\n上記の LargeLanguageModel と同様に、このインターフェースは対応する model に応じて適切な tokenizer を選択して計算する必要があります。対応するモデルが tokenizer を提供していない場合は、AIModel 基底クラスの _get_num_tokens_by_gpt2(text: str) メソッドを使用して計算できます。\n\n​\nRerank\n\n__base.rerank_model.RerankModel 基底クラスを継承し、以下のインターフェースを実装します。\n\nrerank呼び出し\nCopy\ndef _invoke(self, model: str, credentials: dict,\n            query: str, docs: list[str], score_threshold: Optional[float] = None, top_n: Optional[int] = None,\n            user: Optional[str] = None) \\\n        -> RerankResult:\n    \"\"\"\n    Invoke rerank model\n\n    :param model: model name\n    :param credentials: model credentials\n    :param query: search query\n    :param docs: docs for reranking\n    :param score_threshold: score threshold\n    :param top_n: top n\n    :param user: unique user id\n    :return: rerank result\n    \"\"\"\n\nパラメータ：\n\n\n- model (string) モデル名\n- credentials (object) クレデンシャル\nクレデンシャルのパラメータは、ベンダーのYAML構成ファイルの provider_credential_schema または model_credential_schema で定義され、api_key などが渡されます。\n- query (string) 検索クエリ\n- docs (array[string]) 並べ替え対象のテキストリスト\n- score_threshold (float) [optional] スコア閾値\n- top_n (int) [optional] 上位n件のテキストを取得\n- user (string) [optional] ユーザーの一意の識別子\nベンダーが不正行為を監視および検出するのに役立ちます。\n\n戻り値：\n\nRerankResult エンティティ。\n\n​\nSpeech2text(音声テキスト変換)\n\n\n__base.speech2text_model.Speech2TextModel 基底クラスを継承\n\nInvoke呼び出し\nCopy\ndef _invoke(self, model: str, credentials: dict,\n            file: IO[bytes], user: Optional[str] = None) \\\n        -> str:\n    \"\"\"\n    Invoke large language model\n\n    :param model: model name\n    :param credentials: model credentials\n    :param file: audio file\n    :param user: unique user id\n    :return: text for given audio file\n    \"\"\"        \n\nパラメータ：\n\n\n- model (string) モデル名\n- credentials (object) クレデンシャル\nクレデンシャルのパラメータは、ベンダーのYAML構成ファイルの provider_credential_schema または model_credential_schema で定義され、api_key などが渡されます。\n- file (File) ファイルストリーム\n- user (string) [optional] ユーザーの一意の識別子\nベンダーが不正行為を監視および検出するのに役立ちます。\n\n戻り値：\n\n音声変換された文字列。\n\nはい、以下に修正後の翻訳を示します。直訳の問題点を踏まえ、より自然で分かりやすい日本語になるように調整しました。\n\n​\nText2speech (テキスト音声変換)\n\n__base.text2speech_model.Text2SpeechModel を継承し、以下のインターフェースを実装します。\n\nInvoke (呼び出し)\nCopy\ndef _invoke(self, model: str, credentials: dict, content_text: str, streaming: bool, user: Optional[str] = None):\n    \"\"\"\n    Invoke large language model\n\n    :param model: model name\n    :param credentials: model credentials\n    :param content_text: text content to be translated\n    :param streaming: output is streaming\n    :param user: unique user id\n    :return: translated audio file\n    \"\"\"        \n\n\nパラメータ：\n\nmodel (string): モデル名\ncredentials (object): 認証情報\n認証情報のパラメータは、ベンダーの YAML 設定ファイルの provider_credential_schema または model_credential_schema で定義され、api_key などが渡されます。\ncontent_text (string): 変換するテキストコンテンツ\nstreaming (bool): ストリーミング出力を行うかどうか\nuser (string) [オプション]: ユーザーの一意な識別子\nベンダーが不正利用を監視・検出するのに役立ちます。\n\n戻り値：\n\nテキスト変換後の音声ストリーム。\n\n​\nModeration (モデレーション)\n\n__base.moderation_model.ModerationModel を継承し、以下のインターフェースを実装します。\n\nInvoke (呼び出し)\nCopy\ndef _invoke(self, model: str, credentials: dict,\n            text: str, user: Optional[str] = None) \\\n        -> bool:\n    \"\"\"\n    Invoke large language model\n\n    :param model: model name\n    :param credentials: model credentials\n    :param text: text to moderate\n    :param user: unique user id\n    :return: false if text is safe, true otherwise\n    \"\"\"\n\n\nパラメータ：\n\nmodel (string): モデル名\ncredentials (object): 認証情報\n認証情報のパラメータは、ベンダーの YAML 設定ファイルの provider_credential_schema または model_credential_schema で定義され、api_key などが渡されます。\ntext (string): テキストコンテンツ\nuser (string) [オプション]: ユーザーの一意な識別子\nベンダーが不正利用を監視・検出するのに役立ちます。\n\n戻り値：\n\n入力テキストが安全な場合は False、そうでない場合は True を返します。\n\n​\nEntity(エンティティ)\n​\nPromptMessageRole (プロンプトメッセージの役割)\n\nメッセージの役割を定義する列挙型です。\n\nCopy\nclass PromptMessageRole(Enum):\n    \"\"\"\n    Enum class for prompt message.\n    \"\"\"\n    SYSTEM = \"system\"\n    USER = \"user\"\n    ASSISTANT = \"assistant\"\n    TOOL = \"tool\"\n\n​\nPromptMessageContentType (プロンプトメッセージのコンテンツタイプ)\n\nメッセージコンテンツのタイプを定義する列挙型です。テキストと画像の2種類があります。\n\nCopy\nclass PromptMessageContentType(Enum):\n    \"\"\"\n    Enum class for prompt message content type.\n    \"\"\"\n    TEXT = 'text'\n    IMAGE = 'image'\n\n​\nPromptMessageContent (プロンプトメッセージのコンテンツ)\n\nメッセージコンテンツの基底クラスです。パラメータ定義のみに用いられ、直接の初期化はできません。\n\nCopy\nclass PromptMessageContent(BaseModel):\n    \"\"\"\n    Model class for prompt message content.\n    \"\"\"\n    type: PromptMessageContentType\n    data: str  # コンテンツデータ\n\n\n現在、テキストと画像の2種類のタイプがサポートされており、テキストと複数の画像を同時に渡すことができます。それぞれ TextPromptMessageContent および ImagePromptMessageContent を初期化して渡す必要があります。\n\n​\nTextPromptMessageContent\nCopy\nclass TextPromptMessageContent(PromptMessageContent):\n    \"\"\"\n    テキストプロンプトメッセージのコンテンツを定義するモデルクラスです。\n    \"\"\"\n    type: PromptMessageContentType = PromptMessageContentType.TEXT\n\n\nテキストと画像を同時に送信する場合、テキストはこのエンティティを content リストの一部として構成する必要があります。\n\n​\nImagePromptMessageContent\nCopy\nclass ImagePromptMessageContent(PromptMessageContent):\n    \"\"\"\n    Model class for image prompt message content.\n    \"\"\"\n    class DETAIL(Enum):\n        LOW = 'low'\n        HIGH = 'high'\n\n    type: PromptMessageContentType = PromptMessageContentType.IMAGE\n    detail: DETAIL = DETAIL.LOW  # 解像度\n\n\n画像とテキストを同時に送信する場合、画像はこのエンティティを content リストの一部として構成する必要があります。\ndata には、画像の url または base64 エンコードされた文字列を指定できます。\n\n​\nPromptMessage\n\nすべての Role メッセージの基底クラスで、パラメータ定義のみに使用され、インスタンス化はできません。\n\nCopy\nclass PromptMessage(ABC, BaseModel):\n    \"\"\"\n    Model class for prompt message.\n    \"\"\"\n    role: PromptMessageRole  # メッセージの役割\n    content: Optional[str | list[PromptMessageContent]] = None  # 文字列またはコンテンツリストのいずれかを指定できます。コンテンツリストはマルチモーダルに対応するためのもので、詳細は PromptMessageContent の説明を参照してください。\n    name: Optional[str] = None  # 名前（オプション）\n\n​\nUserPromptMessage\n\nユーザーメッセージを表す UserMessage のメッセージボディです。\n\nCopy\nclass UserPromptMessage(PromptMessage):\n    \"\"\"\n    Model class for user prompt message.\n    \"\"\"\n    role: PromptMessageRole = PromptMessageRole.USER\n\n​\nAssistantPromptMessage\n\nモデルからの応答メッセージを表し、通常は few-shots やチャット履歴の入力に使用されます。\n\nCopy\nclass AssistantPromptMessage(PromptMessage):\n    \"\"\"\n    Model class for assistant prompt message.\n    \"\"\"\n    class ToolCall(BaseModel):\n        \"\"\"\n        Model class for assistant prompt message tool call.\n        \"\"\"\n        class ToolCallFunction(BaseModel):\n            \"\"\"\n            Model class for assistant prompt message tool call function.\n            \"\"\"\n            name: str  # ツールの名前\n            arguments: str  # ツールの引数\n\n        id: str  # ツールID。OpenAI のツール呼び出しでのみ有効で、ツール呼び出しの一意なIDです。同じツールを複数回呼び出すことができます。\n        type: str  # デフォルトは function\n        function: ToolCallFunction  # ツール呼び出し情報\n\n    role: PromptMessageRole = PromptMessageRole.ASSISTANT\n    tool_calls: list[ToolCall] = []  # モデルが応答したツール呼び出しの結果です（tools が渡され、モデルがツールを呼び出す必要があると判断した場合のみ返されます）。\n\n\ntool_calls は、モデルに tools が渡された後、モデルから返されるツール呼び出しのリストです。\n\n​\nSystemPromptMessage\n\nシステムメッセージを表し、通常はモデルにシステム命令を設定するために使用されます。\n\nCopy\nclass SystemPromptMessage(PromptMessage):\n    \"\"\"\n    Model class for system prompt message.\n    \"\"\"\n    role: PromptMessageRole = PromptMessageRole.SYSTEM\n\n​\nToolPromptMessage\n\nツールメッセージを表し、ツールの実行結果をモデルに渡して、次の計画を立てるために使用されます。\n\nCopy\nclass ToolPromptMessage(PromptMessage):\n    \"\"\"\n    Model class for tool prompt message.\n    \"\"\"\n    role: PromptMessageRole = PromptMessageRole.TOOL\n    tool_call_id: str  # ツール呼び出しID。OpenAI のツール呼び出しをサポートしない場合は、ツール名を渡すこともできます。\n\n\n基底クラスの content にはツールの実行結果を渡します。\n\n​\nPromptMessageTool\nCopy\nclass PromptMessageTool(BaseModel):\n    \"\"\"\n    Model class for prompt message tool.\n    \"\"\"\n    name: str  # ツール名\n    description: str  # ツールの説明\n    parameters: dict  # ツールパラメータ（辞書形式）\n\n​\nLLMResult\nCopy\nclass LLMResult(BaseModel):\n    \"\"\"\n    Model class for llm result.\n    \"\"\"\n    model: str  # 使用モデル\n    prompt_messages: list[PromptMessage]  # プロンプトメッセージリスト\n    message: AssistantPromptMessage  # 返信メッセージ\n    usage: LLMUsage  # トークン及び費用情報\n    system_fingerprint: Optional[str] = None  # リクエスト指紋（OpenAIの定義に準拠）\n\n​\nLLMResultChunkDelta\n\nストリーミング結果の各イテレーションにおける差分エンティティ\n\nCopy\nclass LLMResultChunkDelta(BaseModel):\n    \"\"\"\n    Model class for llm result chunk delta.\n    \"\"\"\n    index: int  # 順番\n    message: AssistantPromptMessage  # 返信メッセージ\n    usage: Optional[LLMUsage] = None  # トークン及び費用情報（最後のチャンクのみ）\n    finish_reason: Optional[str] = None  # 終了理由（最後のチャンクのみ）\n\n​\nLLMResultChunk\n\nストリーミング結果の各イテレーションエンティティ\n\nCopy\nclass LLMResultChunk(BaseModel):\n    \"\"\"\n    Model class for llm result chunk.\n    \"\"\"\n    model: str  # 使用モデル\n    prompt_messages: list[PromptMessage]  # プロンプトメッセージリスト\n    system_fingerprint: Optional[str] = None  # リクエスト指紋（OpenAIの定義に準拠）\n    delta: LLMResultChunkDelta  # 各イテレーションで変化する内容\n\n​\nLLMUsage\nCopy\nclass LLMUsage(ModelUsage):\n    \"\"\"\n    Model class for llm usage.\n    \"\"\"\n    prompt_tokens: int  # プロンプト使用トークン数\n    prompt_unit_price: Decimal  # プロンプト単価\n    prompt_price_unit: Decimal  # プロンプト価格単位（単価が適用されるトークン数）\n    prompt_price: Decimal  # プロンプト料金\n    completion_tokens: int  # 回答使用トークン数\n    completion_unit_price: Decimal  # 回答単価\n    completion_price_unit: Decimal  # 回答価格単位（単価が適用されるトークン数）\n    completion_price: Decimal  # 回答料金\n    total_tokens: int  # 総使用トークン数\n    total_price: Decimal  # 総料金\n    currency: str  # 通貨単位\n    latency: float  # リクエスト処理時間（秒）\n\n​\nTextEmbeddingResult\nCopy\nclass TextEmbeddingResult(BaseModel):\n    \"\"\"\n    Model class for text embedding result.\n    \"\"\"\n    model: str  # 使用モデル\n    embeddings: list[list[float]]  # 埋め込みベクトルリスト（テキストに対応）\n    usage: EmbeddingUsage  # 使用情報\n\n​\nEmbeddingUsage\nCopy\nclass EmbeddingUsage(ModelUsage):\n    \"\"\"\n    Model class for embedding usage.\n    \"\"\"\n    tokens: int  # 使用トークン数\n    total_tokens: int  # 総使用トークン数\n    unit_price: Decimal  # 単価\n    price_unit: Decimal  # 価格単位（単価が適用されるトークン数）\n    total_price: Decimal  # 総料金\n    currency: str  # 通貨単位\n    latency: float  # リクエスト処理時間（秒）\n\n​\nRerankResult\nCopy\nclass RerankResult(BaseModel):\n    \"\"\"\n    Model class for rerank result.\n    \"\"\"\n    model: str  # 使用モデル\n    docs: list[RerankDocument]  # リランク後のドキュメントリスト\n\n​\nRerankDocument\nCopy\nclass RerankDocument(BaseModel):\n    \"\"\"\n    Model class for rerank document.\n    \"\"\"\n    index: int  # 元の順番\n    text: str  # ドキュメントテキスト\n    score: float  # スコア\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nモデル設計規則\n一般的な標準仕様\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nモデルプロバイダー\nモデル\n共通インターフェース\nLLM\nTextEmbedding\nRerank\nSpeech2text(音声テキスト変換)\nText2speech (テキスト音声変換)\nModeration (モデレーション)\nEntity(エンティティ)\nPromptMessageRole (プロンプトメッセージの役割)\nPromptMessageContentType (プロンプトメッセージのコンテンツタイプ)\nPromptMessageContent (プロンプトメッセージのコンテンツ)\nTextPromptMessageContent\nImagePromptMessageContent\nPromptMessage\nUserPromptMessage\nAssistantPromptMessage\nSystemPromptMessage\nToolPromptMessage\nPromptMessageTool\nLLMResult\nLLMResultChunkDelta\nLLMResultChunk\nLLMUsage\nTextEmbeddingResult\nEmbeddingUsage\nRerankResult\nRerankDocument",
        "error": null
      },
      {
        "link_index": 22,
        "link_text": "一般的な標準仕様",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/general-specifications",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nスキーマ仕様\n一般的な標準仕様\nCopy page\n\n本文では、プラグイン開発における共通構造について簡単に説明します。\n\n​\nパス仕様\n\nマニフェストまたは任意のyamlファイルでファイルパスを指定する場合、ファイルタイプに基づいて以下の2つのルールに従ってください：\n\n画像や動画などのマルチメディアファイル（例：プラグインのicon）の場合、プラグインのルートディレクトリの下の_assetsフォルダに配置します。\n.pyや.yamlなどの通常のテキストファイルの場合、プラグインプロジェクト内の絶対パスを使用します。\n​\n共通構造\n\nプラグインを定義する際、ツール、モデル、インターフェース間で共有できるデータ構造があります。以下がこれらの共有構造です。\n\n​\nI18nObject\n\nI18nObjectは、IETF BCP 47標準に準拠した国際化構造で、現在4つの言語をサポートしています：\n\nen_US\nzh_Hans\nja_Jp\npt_BR\n​\nProviderConfig\n\nProviderConfigは、ToolとEndpointの両方に適用可能な共通プロバイダーフォーム構造です。\n\nname (string): フォーム項目名\nlabel (I18nObject, 必須): IETF BCP 47に準拠\ntype (provider_config_type, 必須): フォームタイプ\nscope (provider_config_scope): オプション範囲、typeにより異なる\nrequired (bool): 空にできない\ndefault (any): デフォルト値、基本タイプfloat int stringのみサポート\noptions (list[provider_config_option]): オプション、typeがselectの場合のみ使用\nhelper (object): ヘルプドキュメントリンクラベル、IETF BCP 47に準拠\nurl (string): ヘルプドキュメントリンク\nplaceholder (object): IETF BCP 47に準拠\n​\nProviderConfigOption(object)\nvalue(string, 必須)：値\nlabel(object, 必須)：IETF BCP 47に準拠\n​\nProviderConfigType(string)\nsecret-input (string)：設定情報が暗号化される\ntext-input(string)：プレーンテキスト\nselect(string)：ドロップダウンボックス\nboolean(bool)：スイッチ\nmodel-selector(object)：プロバイダー名、モデル名、モデルパラメータなどを含むモデル設定情報\napp-selector(object)：アプリID\ntool-selector(object)：ツールプロバイダー、名前、パラメータなどを含むツール設定情報\ndataset-selector(string)：TBD\n​\nProviderConfigScope(string)\ntypeがmodel-selectorの場合\nall\nllm\ntext-embedding\nrerank\ntts\nspeech2text\nmoderation\nvision\ntypeがapp-selectorの場合\nall\nchat\nworkflow\ncompletion\ntypeがtool-selectorの場合\nall\nplugin\napi\nworkflow\n​\nModelConfig\nprovider (string): プラグインIDを含むプロバイダー名、形式はlanggenius/openai/openai\nmodel (string): 具体的なモデル名\nmodel_type (enum): モデルタイプの列挙、このドキュメントを参照\n​\nNodeResponse\ninputs (dict): ノードに最終的に入力される変数\noutputs (dict): ノード出力結果\nprocess_data (dict): ノード実行中に生成されたデータ\n​\nToolSelector\nprovider_id (string): ツールプロバイダー名\ntool_name (string): ツール名\ntool_description (string): ツールの説明\ntool_configuration (dict[str, Any]): ツール設定情報\ntool_parameters (dict[str, dict]): LLM推論が必要なパラメータ\nname (string): パラメータ名\ntype (string): パラメータタイプ\nrequired (bool): 必須かどうか\ndescription (string): パラメータの説明\ndefault (any): デフォルト値\noptions (list[string]): 利用可能なオプション\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nモデルスキーマ\n永続化されたストレージ\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nパス仕様\n共通構造\nI18nObject\nProviderConfig\nProviderConfigOption(object)\nProviderConfigType(string)\nProviderConfigScope(string)\nModelConfig\nNodeResponse\nToolSelector",
        "error": null
      },
      {
        "link_index": 23,
        "link_text": "永続化されたストレージ",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/persistent-storage",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nスキーマ仕様\n永続化されたストレージ\nCopy page\n\nプラグイン内のToolとEndpointを個別に見ると、ほとんどの場合、単一のラウンドの対話、つまりリクエストを送信してデータを返し、タスクが終了するだけであることがわかります。\n\n長期的なデータの保存が必要な場合、例えば永続的なメモリを実装する場合、プラグインには永続的なストレージ機能が必要です。永続ストレージメカニズムにより、プラグインは同じWorkspace内でデータを永続的に保存する機能を持つことができます。現在はKVデータベースを提供してストレージのニーズを満たしており、将来的には実際の使用状況に基づいて、より柔軟で強力なストレージインターフェースを導入する可能性があります。\n\n​\nストレージキー\n​\nエントリーポイント\nCopy\n    self.session.storage\n\n​\nエンドポイント\nCopy\n    def set(self, key: str, val: bytes) -> None:\n        pass\n\n\nbytesが渡されることに注意してください。これにより、実際にファイルを保存することができます。\n\n​\nキーの取得\n​\nエントリーポイント\nCopy\n    self.session.storage\n\n​\nエンドポイント\nCopy\n    def get(self, key: str) -> bytes:\n        pass\n\n​\nキーの削除\n​\nエントリーポイント\nCopy\n    self.session.storage\n\n​\nエンドポイント\nCopy\n    def delete(self, key: str) -> None:\n        pass\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\n一般的な標準仕様\nReverse invocation of the dify service\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nストレージキー\nエントリーポイント\nエンドポイント\nキーの取得\nエントリーポイント\nエンドポイント\nキーの削除\nエントリーポイント\nエンドポイント",
        "error": null
      },
      {
        "link_index": 24,
        "link_text": "Reverse invocation of the dify service",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/reverse-invocation-of-the-dify-service",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nTermbase\nDifyサービスへのバックコール\nCopy page\n\nプラグインは、Difyメインプラットフォーム内の特定のサービスを自由に呼び出し、プラグインの機能を拡張できます。\n\n​\n呼び出し可能なDifyモジュール\n\nApp\n\nプラグインは、Difyプラットフォーム内のAppデータにアクセスできます。\n\nModel\n\nプラグインは、Difyプラットフォーム内のLLM機能をバックコールできます。これには、プラットフォーム内のすべてのモデルタイプと機能（TTS、Rerankなど）が含まれます。\n\nTool\n\nプラグインは、Difyプラットフォーム内の他のツールタイプのプラグインを呼び出すことができます。\n\nNode\n\nプラグインは、Difyプラットフォーム内の特定のChatflow/Workflowアプリケーション内のノードを呼び出すことができます。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\n呼び出し可能なDifyモジュール",
        "error": null
      },
      {
        "link_index": 25,
        "link_text": "アプリ",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/reverse-invocation-of-the-dify-service/app",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nReverse invocation of the dify service\nアプリ\nモデル\nツール\nノード\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nDifyサービスの逆呼び出し\nアプリ\nCopy page\n\nリバース呼び出しとは、プラグインがDify内のAppデータにアクセスできることを意味します。このモジュールは、ストリーミングと非ストリーミングの両方のAppコールをサポートしています。\n\n​\nエンドポイントタイプ：\nChatbot/Agent/Chatflowタイプのアプリケーションは、すべてチャットタイプのアプリケーションであり、同じ入力パラメータと出力パラメータを持つため、統一的にチャットインターフェースとして扱うことができます。\nWorkflowアプリケーションは、独立したワークフローインターフェースを占有します。\nCompletion（テキスト生成）アプリケーションは、独立したCompletionエンドポイントを占有します。\n\n注意：プラグインは、プラグインと同じWorkspace内のAppにのみアクセスできます。\n\n​\nチャットインターフェースのリクエスト エントリーポイント\n​\nエントリーポイント\nCopy\nself.session.app.chat\n\n​\nエンドポイント仕様\nCopy\ndef invoke(\n    self,\n    app_id: str,\n    inputs: dict,\n    response_mode: Literal[\"streaming\", \"blocking\"],\n    conversation_id: str,\n    files: list,\n) -> Generator[dict, None, None] | dict:\n    pass\n\n\nresponse_modeがstreamingの場合、インターフェースはGenerator[dict]を返し、それ以外の場合はdictを返します。具体的なインターフェースフィールドについては、ServiceApiの戻り値を参照してください。\n\n​\n例\n\nEndpoint内でチャットタイプのAppをリクエストし、結果を直接返すことができます：\n\nCopy\nimport json\nfrom typing import Mapping\nfrom werkzeug import Request, Response\nfrom dify_plugin import Endpoint\n\nclass Duck(Endpoint):\n    def _invoke(self, r: Request, values: Mapping, settings: Mapping) -> Response:\n        \"\"\"\n        与えられたリクエストでエンドポイントを呼び出します。\n        \"\"\"\n        app_id = values[\"app_id\"]\n        def generator():\n            response = self.session.app.workflow.invoke(\n                app_id=app_id, inputs={}, response_mode=\"streaming\", files=[]\n            )\n            for data in response:\n                yield f\"{json.dumps(data)} <br>\"\n        return Response(generator(), status=200, content_type=\"text/html\")\n\n\nワークフローエンドポイント エントリーポイント\n\n​\nエントリー\nCopy\nself.session.app.workflow\n\n​\nエンドポイント仕様\nCopy\ndef invoke(\n    self,\n    app_id: str,\n    inputs: dict,\n    response_mode: Literal[\"streaming\", \"blocking\"],\n    files: list,\n) -> Generator[dict, None, None] | dict:\n    pass\n\n​\nCompletionエンドポイントのリクエスト\n​\nエントリー\nCopy\nself.session.app.completion\n\n\nエンドポイント仕様\n\nCopy\ndef invoke(\n    self,\n    app_id: str,\n    inputs: dict,\n    response_mode: Literal[\"streaming\", \"blocking\"],\n    files: list,\n) -> Generator[dict, None, None] | dict:\n    pass\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nReverse invocation of the dify service\nモデル\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nエンドポイントタイプ：\nチャットインターフェースのリクエスト エントリーポイント\nエントリーポイント\nエンドポイント仕様\n例\nエントリー\nエンドポイント仕様\nCompletionエンドポイントのリクエスト\nエントリー",
        "error": null
      },
      {
        "link_index": 26,
        "link_text": "モデル",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/reverse-invocation-of-the-dify-service/model",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nReverse invocation of the dify service\nアプリ\nモデル\nツール\nノード\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nDifyサービスの逆呼び出し\nモデル\nCopy page\n\nリバースモデルリクエストとは、プラグインがDify内のLLM機能に対してリバースリクエストを行う能力を指し、TTS、Rerankなど、プラットフォーム上のすべてのモデルタイプと機能が含まれます。\n\nモデルのリクエストには、ModelConfigタイプのパラメータを渡す必要があることに注意してください。その構造は共通仕様定義で参照でき、この構造は異なるタイプのモデルで若干の違いがあります。\n\n例えば、LLMタイプのモデルの場合、completion_paramsとmodeパラメータを含める必要があります。この構造は手動で構築するか、model-selectorタイプのパラメータまたは設定を使用することができます。\n\n​\nLLMのリクエスト\n​\nエントリー\nCopy\nself.session.model.llm\n\n​\nエンドポイント：\nCopy\ndef invoke(\n    self,\n    model_config: LLMModelConfig,\n    prompt_messages: list[PromptMessage],\n    tools: list[PromptMessageTool] | None = None,\n    stop: list[str] | None = None,\n    stream: bool = True,\n) -> Generator[LLMResultChunk, None, None] | LLMResult:\n    pass\n\n\n注意：リクエストするモデルにtool_call機能がない場合、ここで渡されるツールは効果を持ちません。\n\n​\n例\n\nツールでOpenAIのgpt-4o-miniモデルをリクエストする場合は、以下のサンプルコードを参照してください：\n\nCopy\nfrom collections.abc import Generator\nfrom typing import Any\n\nfrom dify_plugin import Tool\nfrom dify_plugin.entities.model.llm import LLMModelConfig\nfrom dify_plugin.entities.tool import ToolInvokeMessage\nfrom dify_plugin.entities.model.message import SystemPromptMessage, UserPromptMessage\n\nclass LLMTool(Tool):\n    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage]:\n        response = self.session.model.llm.invoke(\n            model_config=LLMModelConfig(\n                provider='openai',\n                model='gpt-4o-mini',\n                mode='chat',\n                completion_params={}\n            ),\n            prompt_messages=[\n                SystemPromptMessage(\n                    content='you are a helpful assistant'\n                ),\n                UserPromptMessage(\n                    content=tool_parameters.get('query')\n                )\n            ],\n            stream=True\n        )\n\n        for chunk in response:\n            if chunk.delta.message:\n                assert isinstance(chunk.delta.message.content, str)\n                yield self.create_text_message(text=chunk.delta.message.content)\n\n\nコードではtool_parametersからqueryパラメータが渡されていることに注意してください。\n\n​\nベストプラクティス\n\nLLMModelConfigを手動で構築することは推奨されません。代わりに、UIでユーザーが希望のモデルを選択できるようにします。この場合、以下の設定に従ってmodelパラメータを追加することでツールのパラメータリストを変更できます：\n\nCopy\nidentity:\n  name: llm\n  author: Dify\n  label:\n    en_US: LLM\n    zh_Hans: LLM\n    pt_BR: LLM\ndescription:\n  human:\n    en_US: A tool for invoking a large language model\n    zh_Hans: 用于调用大型语言模型的工具\n    pt_BR: A tool for invoking a large language model\n  llm: A tool for invoking a large language model\nparameters:\n  - name: prompt\n    type: string\n    required: true\n    label:\n      en_US: Prompt string\n      zh_Hans: 提示字符串\n      pt_BR: Prompt string\n    human_description:\n      en_US: used for searching\n      zh_Hans: 用于搜索网页内容\n      pt_BR: used for searching\n    llm_description: key words for searching\n    form: llm\n  - name: model\n    type: model-selector\n    scope: llm\n    required: true\n    label:\n      en_US: Model\n      zh_Hans: 使用的模型\n      pt_BR: Model\n    human_description:\n      en_US: Model\n      zh_Hans: 使用的模型\n      pt_BR: Model\n    llm_description: which Model to invoke\n    form: form\nextra:\n  python:\n    source: tools/llm.py\n\n\nこの例では、モデルのスコープがllmとして指定されているため、ユーザーはllmタイプのパラメータのみを選択できることに注意してください。これにより、上記の例のコードを以下のように変更できます：\n\nCopy\nfrom collections.abc import Generator\nfrom typing import Any\n\nfrom dify_plugin import Tool\nfrom dify_plugin.entities.model.llm import LLMModelConfig\nfrom dify_plugin.entities.tool import ToolInvokeMessage\nfrom dify_plugin.entities.model.message import SystemPromptMessage, UserPromptMessage\n\nclass LLMTool(Tool):\n    def _invoke(self, tool_parameters: dict[str, Any]) -> Generator[ToolInvokeMessage]:\n        response = self.session.model.llm.invoke(\n            model_config=tool_parameters.get('model'),\n            prompt_messages=[\n                SystemPromptMessage(\n                    content='you are a helpful assistant'\n                ),\n                UserPromptMessage(\n                    content=tool_parameters.get('query')\n                )\n            ],\n            stream=True\n        )\n\n        for chunk in response:\n            if chunk.delta.message:\n                assert isinstance(chunk.delta.message.content, str)\n                yield self.create_text_message(text=chunk.delta.message.content)\n\n​\n要約のリクエスト\n\nこのエンドポイントを使用してテキストを要約することができます。現在のワークスペースのシステムモデルを使用してテキストを要約します。\n\nエントリー：\n\nCopy\nself.session.model.summary\n\n\nエンドポイント：\n\ntext: 要約するテキスト\ninstruction: 追加の指示。要約のスタイルをカスタマイズできます\nCopy\ndef invoke(\n    self, text: str, instruction: str,\n) -> str:\n\n\nテキスト埋め込みのリクエスト\n\nエントリー\n\nCopy\nself.session.model.text_embedding\n\n\nエンドポイント\n\nCopy\ndef invoke(\n    self, model_config: TextEmbeddingResult, texts: list[str]\n) -> TextEmbeddingResult:\n    pass\n\n​\nRerankのリクエスト\n​\nエントリー\nCopy\nself.session.model.rerank\n\n​\nエンドポイント\nCopy\ndef invoke(\n    self, model_config: RerankModelConfig, docs: list[str], query: str\n) -> RerankResult:\n    pass\n\n​\nTTSのリクエスト\n​\nエントリー\nCopy\nself.session.model.tts\n\n​\nエンドポイント\nCopy\ndef invoke(\n    self, model_config: TTSModelConfig, content_text: str\n) -> Generator[bytes, None, None]:\n    pass\n\n\n注意：TTSエンドポイントが返すバイトストリームはmp3オーディオバイトストリームで、各イテレーションで完全なオーディオを返します。より高度な処理タスクを実行したい場合は、適切なライブラリを選択してください。\n\n​\n音声認識のリクエスト\n\nエントリー：\n\nCopy\nself.session.model.speech2text\n\n\nエンドポイント：\n\nCopy\ndef invoke(\n    self, model_config: Speech2TextModelConfig, file: IO[bytes]\n) -> str:\n    pass\n\n\nここで、fileはmp3エンコードされたオーディオファイルです。\n\n​\nモデレーションのリクエスト\n\nエントリー：\n\nCopy\nself.session.model.moderation\n\n\nエンドポイント：\n\nCopy\ndef invoke(self, model_config: ModerationModelConfig, text: str) -> bool:\n    pass\n\n\nこのエンドポイントがtrueを返す場合、textに機密コンテンツが含まれていることを示します。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nアプリ\nツール\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nLLMのリクエスト\nエントリー\nエンドポイント：\n例\nベストプラクティス\n要約のリクエスト\nRerankのリクエスト\nエントリー\nエンドポイント\nTTSのリクエスト\nエントリー\nエンドポイント\n音声認識のリクエスト\nモデレーションのリクエスト",
        "error": null
      },
      {
        "link_index": 27,
        "link_text": "ツール",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/reverse-invocation-of-the-dify-service/tool",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nReverse invocation of the dify service\nアプリ\nモデル\nツール\nノード\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nDifyサービスの逆呼び出し\nツール\nCopy page\n\n以下のようなシナリオに遭遇した場合：\n\nツールタイププラグインが機能を実装したが、期待を満たしておらずデータの再処理が必要な場合\nタスクがWebクローリングを必要とし、クローリングサービスの選択に柔軟性が必要な場合\n複数のツールの戻り値を組み合わせる必要があるが、Workflowアプリケーションでの処理が困難な場合\n\nこれらの場合、プラグイン内の他の実装済みツールをリクエストする必要があります。これらのツールは、マーケットプレイスのツールプラグイン、自作のWorkflow as Tool、またはカスタムツールである可能性があります。\n\n上記の要件は、プラグインのself.session.toolフィールドを使用することで達成できます。\n\n​\nインストール済みツールのリクエスト\n\nプラグインが現在のWorkspaceにインストールされている様々なツール（他のツールタイププラグインを含む）をリクエストすることができます。\n\nエントリー：\n\nCopy\nself.session.tool\n\n\nエンドポイント：\n\nCopy\ndef invoke_builtin_tool(\n    self, provider: str, tool_name: str, parameters: dict[str, Any]\n) -> Generator[ToolInvokeMessage, None, None]:\n    pass\n\n\nここで、providerはプラグインIDとツールプロバイダー名を組み合わせたもので、langgenius/google/googleのような形式です。tool_nameは具体的なツール名、parametersはそのツールに渡すパラメータです。\n\n​\nWorkflow as Toolのリクエスト\n\nWorkflow as Toolの詳細については、このドキュメントを参照してください。\n\nエントリー：\n\nCopy\nself.session.tool\n\n\nエンドポイント：\n\nCopy\ndef invoke_workflow_tool(\n    self, provider: str, tool_name: str, parameters: dict[str, Any]\n) -> Generator[ToolInvokeMessage, None, None]:\n    pass\n\n\nここで、providerはツールのID、tool_nameはツール作成時に必要となります。\n\n​\nカスタムツールのリクエスト\n\nエントリー：\n\nCopy\nself.session.tool\n\n\nエンドポイント：\n\nCopy\ndef invoke_api_tool(\n    self, provider: str, tool_name: str, parameters: dict[str, Any]\n) -> Generator[ToolInvokeMessage, None, None]:\n    pass\n\n\nここで、providerはツールのID、tool_nameはOpenAPIのoperation_idです。存在しない場合は、Difyによって自動生成されたtool_nameで、ツール管理ページで確認できます。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nモデル\nノード\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nインストール済みツールのリクエスト\nWorkflow as Toolのリクエスト\nカスタムツールのリクエスト",
        "error": null
      },
      {
        "link_index": 28,
        "link_text": "ノード",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/reverse-invocation-of-the-dify-service/node",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nSchema definition\nManifest(マニフェスト)\nEndpoint（エンドポイント）\nTool(ツール)\nAgent(エージェント)\nModel\n一般的な標準仕様\n永続化されたストレージ\nDifyサービスの逆呼び出し\nReverse invocation of the dify service\nアプリ\nモデル\nツール\nノード\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nDifyサービスの逆呼び出し\nノード\nCopy page\n\nリバースノードリクエストとは、プラグインがDifyのChatflow/Workflowアプリケーション内の特定のノードにアクセスする能力を指します。\n\nWorkflowのParameterExtractorとQuestionClassifierノードは、複雑なPromptとコードロジックをカプセル化しており、LLMを通じたハードコーディングでは解決が困難な多くのタスクを実行できます。プラグインはこれら2つのノードをリクエストすることができます。\n\n​\nパラメータ抽出ノードのリクエスト\n​\nエントリー\nCopy\nself.session.workflow_node.parameter_extractor\n\n​\nエンドポイント\nCopy\ndef invoke(\n    self,\n    parameters: list[ParameterConfig],\n    model: ModelConfig,\n    query: str,\n    instruction: str = \"\",\n) -> NodeResponse\n    pass\n\n\nここで、parametersは抽出するパラメータのリスト、modelはLLMModelConfig仕様に従い、queryはパラメータ抽出のソーステキスト、instructionはLLMへの追加指示を含み、NodeResponse構造はドキュメントで参照できます。\n\n​\n例\n\n会話から人の名前を抽出したい場合は、以下のコードを参照してください：\n\nCopy\nfrom collections.abc import Generator\nfrom dify_plugin.entities.tool import ToolInvokeMessage\nfrom dify_plugin import Tool\nfrom dify_plugin.entities.workflow_node import ModelConfig, ParameterConfig\n\nclass ParameterExtractorTool(Tool):\n    def _invoke(\n        self, tool_parameters: dict\n    ) -> Generator[ToolInvokeMessage, None, None]:\n        response = self.session.workflow_node.parameter_extractor.invoke(\n            parameters=[\n                ParameterConfig(\n                    name=\"name\",\n                    description=\"name of the person\",\n                    required=True,\n                    type=\"string\",\n                )\n            ],\n            model=ModelConfig(\n                provider=\"langgenius/openai/openai\",\n                name=\"gpt-4o-mini\",\n                completion_params={},\n            ),\n            query=\"My name is John Doe\",\n            instruction=\"Extract the name of the person\",\n        )\n        yield self.create_text_message(response.outputs[\"name\"])\n\n​\n質問分類ノードのリクエスト\n​\nエントリー\nCopy\nself.session.workflow_node.question_classifier\n\n​\nエンドポイント\nCopy\ndef invoke(\n    self,\n    classes: list[ClassConfig],\n    model: ModelConfig,\n    query: str,\n    instruction: str = \"\",\n) -> NodeResponse:\n    pass\n\n\nこのエンドポイントのパラメータはParameterExtractorと一致しており、最終結果はNodeResponse.outputs['class_name']に格納されます。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nツール\nBest practice\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nパラメータ抽出ノードのリクエスト\nエントリー\nエンドポイント\n例\n質問分類ノードのリクエスト\nエントリー\nエンドポイント",
        "error": null
      },
      {
        "link_index": 29,
        "link_text": "よくある質問",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/faq",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nプラグイン\nよくある質問\nCopy page\n​\nプラグインのインストール時にアップロードが失敗する場合の対処方法は？\n\nエラー詳細：PluginDaemonBadRequestError: plugin_unique_identifier is not valid というエラーメッセージが表示されます。\n\n解決方法：プラグインプロジェクトの manifest.yaml ファイルと /provider パス配下の .yaml ファイルの author フィールドを GitHub ID に変更してください。\n\nプラグインのパッケージングコマンドを再実行し、新しいプラグインパッケージをインストールしてください。\n\n​\nプラグインインストール時のエラーの対処方法\n\n問題: plugin verification has been enabled, and the plugin you want to install has a bad signature というエラーメッセージが表示された場合、どのように対処すればよいですか？\n\n解決方法: /docker/.env 設定ファイルの末尾に以下の行を追加してください：\nFORCE_VERIFYING_SIGNATURE=false.\n\nDify サービスを再起動するには、以下のコマンドを実行してください：\n\nCopy\ncd docker\ndocker compose down\ndocker compose up -d\n\n\nこのフィールドを追加すると、Dify プラットフォームは Dify Marketplace にリストされていない（つまり、未検証の）すべてのプラグインのインストールを許可します。\n\nただし、安全性を考慮して、未知のソースから提供されるプラグインは、テスト環境またはサンドボックス環境でまずインストールし、安全性を確認した後、本番環境にデプロイしてください。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\n第三者署名検証のためにプラグインに署名する\nSandbox\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\nプラグインのインストール時にアップロードが失敗する場合の対処方法は？\nプラグインインストール時のエラーの対処方法",
        "error": null
      },
      {
        "link_index": 30,
        "link_text": "ライセンス",
        "target_url": "https://docs.dify.ai/ja-jp/policies/open-source",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\n日本語\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nドキュメント\n用語ベース\n入門\nDifyへようこそ\nクラウドサービス\nDify コミュニティ版\nDify Premium\nDify 教育版\nマニュアル\nモデル\nアプリ・オーケストレーション\nワークフロー\nナレッジベース\nアプリ公開\nアノテーション\nモニタリング\n拡張\nコラボレーション\n管理\nハンドオン工房\n初級編\n中級編\nコミュニティ\n支援を求める\n貢献者になる\nドキュメントへの貢献\nプラグイン\nはじめに\nクイックスタート\nプラグイン管理方法\nスキーマ仕様\nベストプラクティス\nプラグインの公開\nよくある質問\n開発\nバックエンド\nモデルの統合\n移行\nもっと読む\n活用事例\nさらに読む\n常见问题\nポリシー\nライセンス\nユーザ規約\nポリシー\nライセンス\nCopy page\n\nDifyのコミュニティエディションは、追加条件付きのApache 2.0ベースのライセンスの下でオープンソース化されています。詳細についてはLICENSEファイルをご参照ください。\n\nライセンスに関する質問や問題がございましたら、business@dify.aiまでお問い合わせください。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nプラグイン\nAgreement\nx\ngithub\nlinkedin\nPowered by Mintlify",
        "error": null
      },
      {
        "link_index": 31,
        "link_text": "​",
        "target_url": "https://docs.dify.ai/ja-jp/plugins/schema-definition/reverse-invocation-of-the-dify-service/README#%E5%91%BC%E3%81%B3%E5%87%BA%E3%81%97%E5%8F%AF%E8%83%BD%E3%81%AAdify%E3%83%A2%E3%82%B8%E3%83%A5%E3%83%BC%E3%83%AB",
        "extract_target": "body",
        "extracted_data": "Dify Docs home page\nEnglish\nSearch or ask...\nCtrl K\nBlog\nDify.AI\nDocumentation\nPlugin Development\nTermbase\nTermbase\nDifyサービスへのバックコール\nCopy page\n\nプラグインは、Difyメインプラットフォーム内の特定のサービスを自由に呼び出し、プラグインの機能を拡張できます。\n\n​\n呼び出し可能なDifyモジュール\n\nApp\n\nプラグインは、Difyプラットフォーム内のAppデータにアクセスできます。\n\nModel\n\nプラグインは、Difyプラットフォーム内のLLM機能をバックコールできます。これには、プラットフォーム内のすべてのモデルタイプと機能（TTS、Rerankなど）が含まれます。\n\nTool\n\nプラグインは、Difyプラットフォーム内の他のツールタイプのプラグインを呼び出すことができます。\n\nNode\n\nプラグインは、Difyプラットフォーム内の特定のChatflow/Workflowアプリケーション内のノードを呼び出すことができます。\n\nこのページを編集する\n\n直接貢献することでドキュメントの改善にご協力ください\n\n問題を報告する\n\nエラーを見つけたり提案がありますか？お知らせください\n\nWas this page helpful?\n\nYes\nNo\nx\ngithub\nlinkedin\nPowered by Mintlify\nOn this page\n呼び出し可能なDifyモジュール",
        "error": null
      },
      {
        "link_index": 36,
        "link_text": "このページを編集する直接貢献することでドキュメントの改善にご協力ください",
        "target_url": "https://github.com/langgenius/dify-docs-mintlify/edit/main/ja-jp/plugins/schema-definition/reverse-invocation-of-the-dify-service/README.mdx",
        "extract_target": "body",
        "extracted_data": "Skip to content\nSign in to GitHub\nUsername or email address\nPassword\nForgot password?\nPassword login alternatives\n\nNew to GitHub? Create an account\n\nTerms\nPrivacy\nDocs\nContact GitHub Support\nManage cookies\nDo not share my personal information",
        "error": null
      },
      {
        "link_index": 37,
        "link_text": "問題を報告するエラーを見つけたり提案がありますか？お知らせください",
        "target_url": "https://github.com/langgenius/dify-docs-mintlify/issues/new?title=ドキュメントの問題%3A%20&body=%23%23%20問題の説明%0A%3C%21--%20発見した問題について簡単に説明してください%20--%3E%0A%0A%23%23%20ページリンク%0Ahttps%3A%2F%2Fgithub.com%2Flanggenius%2Fdify-docs-mintlify%2Fblob%2Fmain%2Fja-jp/plugins/schema-definition/reverse-invocation-of-the-dify-service%2FREADME.mdx%0A%0A%23%23%20提案される変更%0A%3C%21--%20特定の変更案がある場合は、ここで説明してください%20--%3E%0A%0A%3C%21--%20ドキュメントの品質向上にご協力いただきありがとうございます！%20--%3E",
        "extract_target": "body",
        "extracted_data": "Skip to content\nSign in to GitHub\nUsername or email address\nPassword\nForgot password?\nPassword login alternatives\n\nNew to GitHub? Create an account\n\nTerms\nPrivacy\nDocs\nContact GitHub Support\nManage cookies\nDo not share my personal information",
        "error": null
      },
      {
        "link_index": 38,
        "link_text": "x",
        "target_url": "https://x.com/dify_ai",
        "extract_target": "body",
        "extracted_data": "「いま」起きていることを見つけよう\nXなら、「いま」起きていることをいち早くチェックできます。\nログイン\nアカウント作成\nプロフィール\n新しいポストを表示\nXを使ってみよう\n今すぐ登録して、タイムラインをカスタマイズしましょう。\nGoogle で登録\nAppleのアカウントで登録\nアカウントを作成\nアカウントを登録することにより、利用規約とプライバシーポリシー（Cookieの使用を含む）に同意したとみなされます。\n利用規約\n |\nプライバシーポリシー\n |\nCookieのポリシー\n |\nアクセシビリティ\n |\n広告情報\n |\nもっと見る\n© 2025 X Corp.",
        "error": null
      },
      {
        "link_index": 39,
        "link_text": "github",
        "target_url": "https://github.com/langgenius/dify-docs-mintlify",
        "extract_target": "body",
        "extracted_data": "Skip to content\nNavigation Menu\nProduct\nSolutions\nResources\nOpen Source\nEnterprise\nPricing\nSign in\nSign up\nlanggenius\n/\ndify-docs-mintlify\nPublic\nNotifications\nFork 18\n Star 7\nCode\nIssues\n3\nPull requests\n4\nActions\nProjects\nSecurity\nInsights\nlanggenius/dify-docs-mintlify\n main\nBranches\nTags\nCode\nFolders and files\nName\tLast commit message\tLast commit date\n\nLatest commit\n \nHistory\n136 Commits\n\n\nen\n\t\n \n\t\n \n\n\nja-jp\n\t\n \n\t\n \n\n\nlogo\n\t\n \n\t\n \n\n\noutput\n\t\n \n\t\n \n\n\nplugin_dev_en\n\t\n \n\t\n \n\n\nplugin_dev_zh\n\t\n \n\t\n \n\n\nscripts\n\t\n \n\t\n \n\n\ntools\n\t\n \n\t\n \n\n\nzh-hans\n\t\n \n\t\n \n\n\n.DS_Store\n\t\n \n\t\n \n\n\nLICENSE\n\t\n \n\t\n \n\n\nREADME.md\n\t\n \n\t\n \n\n\nconversion.log\n\t\n \n\t\n \n\n\ndevelopment.mdx\n\t\n \n\t\n \n\n\ndify-logo.png\n\t\n \n\t\n \n\n\ndocs-3.21.json\n\t\n \n\t\n \n\n\ndocs.json\n\t\n \n\t\n \n\n\nfavicon.svg\n\t\n \n\t\n \n\n\ngoogle364c33c65ea1639f.html\n\t\n \n\t\n \n\n\nintroduction.mdx\n\t\n \n\t\n \n\n\ninvalid_links_report.md\n\t\n \n\t\n \n\n\nlink_validator.py\n\t\n \n\t\n \n\n\nquickstart.mdx\n\t\n \n\t\n \n\n\nrobots.txt\n\t\n \n\t\n \n\n\nsmart_link_fixer.py\n\t\n \n\t\n \n\n\nzh-hans.md\n\t\n \n\t\n \nRepository files navigation\nREADME\nCode of conduct\nCC-BY-4.0 license\n📘 Dify Documentation (Mintlify Edition)\n\nWelcome to the documentation repository for Dify.\n\nWe warmly welcome your contributions — whether it’s proofreading, fixing typos, or submitting new content. Please feel free to open issues or PRs if you find anything that could be improved!\n\n⸻\n\n🚀 Project Overview\n\nThis project uses the Mintlify Kit to build and serve modern, developer-friendly documentation.\n\n⸻\n\n🛠️ Local Development\n\nTo preview and develop documentation locally:\n\nInstall the Mintlify CLI\nnpm i -g mintlify\nStart local development\n\nRun this command at the root of your project (where docs.json is located):\n\nmintlify dev\n\n⸻\n\n🙌 Contributing\n\nYour help in reviewing, editing, and expanding the documentation is truly appreciated.\n\n📝 Contribution Workflow\n\nFork this repository to your own GitHub account.\n\nCreate a new branch based on the main branch.\n\nStart the local development server following the steps above to preview your changes live.\n\nMake your edits or write new content in the appropriate file under the content/ directory.\n\nSubmit a Pull Request (PR) after verifying your changes:\n\n• If you’ve added new pages or sections, don’t forget to update docs.json to include them in the sidebar navigation. • We welcome tri-lingual contributions (English, Simplified Chinese, Japanese) — contribute in one or more languages if possible.\n\nPlease submit PRs to this repository instead of the legacy one: 📘 https://github.com/langgenius/dify-docs\n\nThanks again for being part of Dify’s documentation journey!\n\n⸻\n\n📄 License\n\nThe Dify product documentation in the assets, content, and data folders are licensed under a CC-BY license.\n\nAbout\ndocs.dify.ai\nResources\n Readme\nLicense\n CC-BY-4.0 license\nCode of conduct\n Code of conduct\n Activity\n Custom properties\nStars\n 7 stars\nWatchers\n 11 watching\nForks\n 18 forks\nReport repository\n\n\nReleases\nNo releases published\n\n\nPackages\nNo packages published\n\n\n\nContributors\n8\n\n\nLanguages\nMDX\n93.7%\n \nPython\n6.3%\nFooter\n© 2025 GitHub, Inc.\nFooter navigation\nTerms\nPrivacy\nSecurity\nStatus\nDocs\nContact\nManage cookies\nDo not share my personal information",
        "error": null
      },
      {
        "link_index": 40,
        "link_text": "linkedin",
        "target_url": "https://www.linkedin.com/company/langgenius",
        "extract_target": "body",
        "extracted_data": "メインコンテンツにスキップ\nLinkedIn\n記事\nユーザー\nラーニング\n求人\nゲーム\nダウンロード\nメンバー登録\nサインイン\nDify\n技術・情報・インターネット\nMIDDLETOWN、DE3,276人のフォロワー\nDify is an open-source LLM app development platform. Orchestrate LLM apps from agents to complex AI workflows.\nフォローする\n  \n\n51人すべての社員を表示\n\n概要\n\n\n              Dify.AI is an LLM application development platform. It integrates the concepts of Backend as a Service and LLMOps.\n          \n\nウェブサイト\nhttps://dify.ai\n業種\n技術・情報・インターネット\n会社規模\n社員 11 - 50名\n本社\nMIDDLETOWN、DE\n種類\n共同経営\n創立\n2023\n専門分野\nAI、LLM、RAG、LLMOps\n製品\nDify\nDify\nSaaS管理ソフトウェア\n\nAn Open-Source Assistants API and GPTs alternative. Dify.AI is an LLM application development platform. It integrates the concepts of Backend as a Service and LLMOps and orchestrates LLM apps from agents to complex AI workflows with an RAG engine.\n\n場所\nプライマリ\n\nMIDDLETOWN、DE、19709、US\n\n道順を表示\nDifyの社員\nLuyu Zhang\nFounder&CEO of Dify.AI, Democratization of AI\nJia (Jake) Xie\nearly-stage venture capital investor\nLi Zheng\nSenior Developer Relations Manager\nJakob Morgan\nLicensed Independent Adjuster | Swift & Fair Claims Resolution | CAT & Daily Claims\n全社員を表示\nアップデート\nDify\n\n3,276人のフォロワー\n\n6日前\n\nDify 🤝 Palo Alto Networks\n\nWe’re excited to announce that the Palo Alto Networks PANW AI Runtime Security plugin is now live in the Dify Marketplace!\n\nAdd enterprise-grade protection to every Dify Workflow, Agent, and Chatflow with a single click. Stop prompt injection, data leaks, malicious links, denial of service attempts, and more while keeping your AI apps fast and reliable.\n\n🛡️ Try the plugin on Marketplace: https://lnkd.in/gQrM59w9\n\nRead the blog: https://lnkd.in/g5NXcYFV\n\n#Dify #PaloAltoNetworks #AISecurity #Plugins\n\n10\nいいね！\nコメント\nシェア\nDify\n\n3,276人のフォロワー\n\n1週間前\n\n🛍️ Build E-commerce AI Agents with Dify! \n\nTransform your e-commerce workflow by automating key tasks with AI. This video shows beginners how to use Dify to create intelligent agents that can:\n\n1) Answer customer queries directly from your knowledge base.\n2) Automate tasks like product searching or order placement using APIs.\n\nThis step-by-step guide covers: \n🔹 Dify.AI basics \n🔹 Building both agent types\n🔹 Integrating agents into your web apps\n\nPerfect for anyone curious about AI agents for business. Dive in and start building: https://lnkd.in/gruAYw96\n\n29\n1件のコメント\nいいね！\nコメント\nシェア\n\nDifyさんが再投稿しました\n\nCEC\n\n160人のフォロワー\n\n1週間前\n\nYesterday, we hosted the Anthropic x New York University Student Founders Meetup!\n\nWe had a great time introducing Claude for NYU Students, hearing lightning pitches from NYU founders, and connecting with so many inspiring builders.\n\nA special thanks to Dify for the amazing demonstration of Claude's use case. Huge thanks to the NYU community for the amazing support, and hope you’re enjoying the Anthropic merch!\n\nJust in case you missed it:\n 👉 Unlock $1/Month Claude Pro for 3 months with your NYU email: https://lnkd.in/e3WZ8AQX\n\n#ClaudeAI #Anthropic #NYU #StudentFounders #AIForStudents  #CampusLife #FinalsSeason\n\n+5\n5\nいいね！\nコメント\nシェア\nDify\n\n3,276人のフォロワー\n\n1週間前  編集済み\n\n🎮 Tutorial: Building a Context-Aware AI Chatbot with Dify & InfraNodus GraphRAG\n\nMoving beyond basic RAG, this tutorial demonstrates using the structural relationships within your data (via knowledge graphs) to provide enhanced context to the LLM.\n\nLearn how to: \n1) Set up a Dify workflow \n2) Integrate the Infranodus GraphRAG API \n3) Augment prompts with contextual graph data \n4) Achieve significantly more precise and relevant chatbot responses\n\nUnlock the potential of your knowledge base and create truly intelligent AI assistants.\n\nSee how it's done: https://lnkd.in/g-HPQvQv\n\n#GraphRAG #Dify #AI #Chatbot\n\n…さらに表示\nHow to Build a Context-Aware AI Chatbot with InfraNodus and Dify\nhttps://www.youtube.com/\n15\nいいね！\nコメント\nシェア\nDify\n\n3,276人のフォロワー\n\n1週間前\n\nWe're excited to announce that Dify will be exhibiting at the AWS Summit Japan 2025!\nJoin us at Makuhari Messe from June 25th to 26th. You can register for the event using the link below. We look forward to connecting with you there!\n\nhttps://lnkd.in/e_dXkS-D\n\n14\nいいね！\nコメント\nシェア\nDify\n\n3,276人のフォロワー\n\n1週間前\n\n🎉 Recap of Japan IT Week Spring 2025 Panel Discussion\n\nOn April 23rd, LangGenius General Manager, Marudan Kiji, PhD, joined Shunsuke Kiriyama (NTT Data) and Yutaka Yoshida (Toyota Boshoku) for a panel on the \"Arrival of the AI Agent Era\" at Japan IT Week Spring, focusing on Dify/Tsunagi AI's role in Japan's Enterprise DX.\n\nMarudan Kiji, PhD shared insights on aspects such as:\n1) Global AI agent trends and the impact on knowledge management and breaking down information silos.\n2) Dify’s “easy-to-use” approach, enabling fast development and cost savings from PoC to implementation.\n3) Collaboration with partners and users is key to solving real-world challenges.\n4) The vision for “next-gen Dify/TsunagiAI,” intuitive even for new employees.\n\nThanks were extended to the Japan IT Week team, NTT DATA, TOYOTA BOSHOKU CORP./トヨタ紡織株式会社, and attendees. LangGenius remains committed to advancing AI-driven DX in Japan through Dify. \n\n\n19\n1件のコメント\nいいね！\nコメント\nシェア\n\nDifyさんが再投稿しました\n\nMarudan Kiji, PhD\n\nCTO，GenAI/Robotic, Ex-Honda R&D, CO-Founder\n\n1週間前  編集済み\n\nI recently concluded our panel discussion at #JapanITWeek Spring 2025 on the \"Arrival of the AI Agent Era\" with Kiriyama-san from #NTTData and Yoshida-san from #ToyotaBoshoku. We highlighted Dify/Tsunagi AI's crucial role in driving Japan's Enterprise DX.\n\nFrom my perspective, a key aspect was Dify/Tsunagi AI's potential to leverage corporate knowledge and break down information silos through the Progress AI Agent concept, aligning with global AI agent trends. I stressed how Dify's core philosophy of \"making AI easily accessible to everyone\" enables significant cost and development time reductions by providing a consistent environment from PoC to implementation. The panel also touched upon the importance of the horizontal deployment of targeted AI use cases that solve specific on-site challenges, requiring strong collaboration and trust with partners. Furthermore, I emphasized Dify/Tsunagi AI's value in clarifying AI applications and their real-world impact.\n \nLooking ahead, LangGenius is focused on the next-gen Dify designed for even greater user intuitiveness, which will be easily used even by new employees, further empowering everyone to solve their challenges. And yes, we're \"open to various GTM strategies!\"\n\n Looking forward to the continued advancements in AI-driven DX for Japanese enterprises.\n\n #Dify #tsunagiAI #AIAgent #LangGenius\n\nDify\n\n3,276人のフォロワー\n\n3週間前  編集済み\n\n🎉 We’re pleased to announce our participation in Japan IT Week Spring 2025 on April 23, 2025, starting at 10:00 AM (GMT+9).  \n\nJoin Marudan Kiji, PhD, General Manager, Japan at LangGenius, as he speaks at the event. At 2:00 PM, he will lead a panel discussion on “Driving Japan’s DX Strategy with Dify,” featuring Shunsuke kiriya from NTT DATA and Yutaka Yoshida from TOYOTA BOSHOKU CORP./トヨタ紡織株式会社.\n\nKey topics include:  \n\n1) Customized AI success stories for Japan’s manufacturing and finance sectors  \n2) The latest trends in AI, from autonomous agents to citizen development  \n3) Low-code strategies for cost efficiency and operational excellence led by non-IT teams\n\nThis session is ideal for professionals focused on AI-driven digital transformation and enterprise innovation.  \n\nFor more details and registration, visit the Japan IT Week website: https://lnkd.in/en7_qbk3\n\n#JapanITWeek #DigitalTransformation #AI #EnterpriseInnovation\n\n12\n1件のコメント\nいいね！\nコメント\nシェア\nDify\n\n3,276人のフォロワー\n\n1週間前\n\n✨ Dify v1.3.0 is LIVE! Featuring Structured Outputs with JSON Schema Editor & More!\n\nTired of unpredictable LLM outputs? Our Structured Outputs feature now comes with a built-in JSON Schema Editor directly in the LLM Node.\n\nThis is a game-changer for ensuring your models return data in reliable, predictable JSON formats. Design your schema once and get consistently structured results, making data handling and API interaction easier.\n\n📺 See how it works: https://lnkd.in/gD8w_3gC\n\n🔧 More Enhancements in v1.3.0:\n\n1) Plugin Update Notifications: Clear UI indicators let you know when new plugin versions are available.\n\n2) Smart Token Counting: New default rules and customization options for better cost management.\n\n3) Workflow Image Export: Easily share your workflows as image files (e.g., PNG).\n\n4) Enhanced Developer Experience: Upgraded from poetry to uv for significantly faster development workflows.\n\nDive into all the details in the full changelog: https://lnkd.in/gfXyDcWs\n\n21\n1件のコメント\nいいね！\nコメント\nシェア\nDify\n\n3,276人のフォロワー\n\n1週間前\n\n[Special Seminar Co-hosted with AWS] Dify Enterprise on AWS – Mastering AI Implementation for Enterprises\n \n🎙️ Featuring Guest Speakers: Kakaku.com, Inc., DNP, Mitsukoshi Isetan\n🗓 Date: Friday, May 23, 2025\n⏰ Time: 15:00–16:30 (Doors open at 14:30)\n📍 Venue: Amazon Japan G.K. Meguro Alcazar Tower\n(3-1-1 Kami-Osaki, Shinagawa-ku, Tokyo)\n\n🚀 Objective\n Discover how Dify Enterprise, an enterprise-grade AI platform, seamlessly integrates with AWS to deliver high-security infrastructure and flexible customization. Learn actionable strategies for enterprise DX through real-world case studies, including large-scale data processing and advanced permission management.\nIdeal for IT leaders and technical teams optimizing AI infrastructure.\n\n▼ Apply Now (Lottery-based registration, deadline: May 13)\n https://lnkd.in/gKykybNq\n\n #Dify #AWS #EnterpriseAI #GenerativeAI #DigitalTransformation\n\n\n25\nいいね！\nコメント\nシェア\nDify\n\n3,276人のフォロワー\n\n2週間前\n\n🧠 New: Workflow Agents now have Memory!\n\nEnable the new Memory toggle for your Agent node so it can recall conversation context. Adjust the Window Size to control how much it remembers for more coherent, context-aware responses. \n\nDocs: https://lnkd.in/g9SVkKFh\n\nThis applies to developers creating custom agent strategy plugins. You can also implement memory for these plugins. Use the history-messages feature, found within the plugin's YAML configuration file.\n\nDocs: https://lnkd.in/gD3zzR7B\n\n#AI #Workflow #Agent #Memory #PluginDevelopment\n\n…さらに表示\n38\n3件のコメント\nいいね！\nコメント\nシェア\n類似するページ\nn8n\n\nソフトウェア開発\n\nBerlin、BE\n\nFlowiseAI (YC S23)\n\nソフトウェア開発\n\nSan Francisco、California\n\nRelevance AI\n\nソフトウェア開発\n\nSurry Hills、New South Wales\n\nwordware (YC S24)\n\n技術・情報・インターネット\n\n類似するページをさらに表示 \n求人を参照\n科学者に関連する求人\n48,969件の募集中の求人\nモバイルエンジニアに関連する求人\n8,544件の募集中の求人\nCFOに関連する求人\n17,590件の募集中の求人\nエンジニアに関連する求人\n555,845件の募集中の求人\nアカウントマネージャーに関連する求人\n121,519件の募集中の求人\nプロダクトデザイナーに関連する求人\n45,389件の募集中の求人\nPython開発者に関連する求人\n46,642件の募集中の求人\nディレクターに関連する求人\n1,220,357件の募集中の求人\nデータサイエンティストに関連する求人\n264,158件の募集中の求人\nサポートに関連する求人\n114,327件の募集中の求人\nこれに類似する求人を表示 \n資金調達\nDify  合計1ラウンド\n\n最終ラウンド\n\nSeed  2023年7月1日\nCrunchbaseで詳しい情報を表示\nその他の検索 \nLinkedIn\n© 2025\n会社概要\nアクセシビリティ\n利用規約\nプライバシーポリシー\nCookieポリシー\n著作権ポリシー\nブランドポリシー\nゲスト向け管理ページ\nコミュニティガイドライン\n言語\nサインインしてDifyの知り合いを見つけましょう\nサインイン\n\nまたは\n\n初めてご利用ですか? 今すぐ登録\n\n登録またはサインインするために [続行] をクリックすることにより、LinkedInの利用規約、プライバシーポリシー、Cookieポリシーに同意したものとみなされます。",
        "error": null
      },
      {
        "link_index": 41,
        "link_text": "Powered by Mintlify",
        "target_url": "https://mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=referral&utm_source=docs.dify.ai",
        "extract_target": "body",
        "extracted_data": "Documentation\nResources\nRequest Preview\nCareers\nPricing\nLogin\nGet a demo\nSign up\n\nPowered by Mintlify\n\nYour documentation can look that nice too.\nTry for free\n\nWant to try it on for style? Submit a link to your documentation and we’ll share a preview of how it’d look on Mintlify.\n\nPowering experiences\nfrom next-gen startups to enterprises\nOur customers\nBuilt for modern teams\n\nCrafted with customizability and collaboration in mind. Designed to impress.\n\nBeautiful out of the box\nBuilt for collaboration\nDesigned for conversion\nThe documentation you want, available today\nGet started\nGet a demo\n\nDocumentation\n\nGetting Started\nComponents\nAPI playground\nPricing\n\nResources\n\nCustomers\nEnterprise\nRequest Preview\nIntegrations\nGuides\nTemplates\nWall of Love\n\nCompany\n\nCareers\nBlog\nSecurity\n\nLegal\n\nPrivacy Policy\nTerms of Service\nResponsible Disclosure\nAll systems normal\n© 2025 Mintlify, Inc.",
        "error": null
      }
    ],
    "errors": []
  }
]